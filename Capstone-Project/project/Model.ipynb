{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model development\n",
    "Notebook overview:\n",
    "- create benchmark model\n",
    "- error metrics\n",
    "- create and test data loader\n",
    "- train\n",
    "- evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nasdaq_train = pd.read_csv(os.path.join(data_dir,'nasdaq_export','train.csv'), index_col=0, header=None)\n",
    "nasdaq_test = pd.read_csv(os.path.join(data_dir,'nasdaq_export','test.csv'), index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "eurusd_train = pd.read_csv(os.path.join(data_dir,'eurusd_export','train.csv'), index_col=0, header=None)\n",
    "eurusd_test = pd.read_csv(os.path.join(data_dir,'eurusd_export','test.csv'), index_col=0, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark\n",
    "Because the benchmark model is very simple and needed only in this notebook, I will define it here. Simple Moving Average forecasting implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MA_regressor:\n",
    "    def __init__(self, N=5):\n",
    "        self.N = N\n",
    "    \n",
    "    def forward(self, price):\n",
    "        return price[-self.N:].sum() / self.N\n",
    "    \n",
    "    def predict(self, data, steps=10):\n",
    "        predictions = np.zeros((len(data),steps))\n",
    "        for i in range(0,len(data)):\n",
    "            d = data[i][:,3]\n",
    "            for j in range(0,steps):\n",
    "                predictions[i][j] = self.forward(np.append(d, predictions[i][:j]))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample, steps = 30, 1\n",
    "benchmark = MA_regressor(2)\n",
    "y = benchmark.predict([nasdaq_train.iloc[:sample].values], steps)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7faca6868128>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.xticks(rotation='vertical')\n",
    "plt.plot(nasdaq_train.iloc[:sample+steps,3])\n",
    "# Reconstruct index\n",
    "y_series = nasdaq_train.iloc[sample-1:sample+steps,3].copy()\n",
    "y_series.iloc[1:] = y\n",
    "plt.plot(y_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "The sample prediction is not successfull at all, we need some metric to optimize it.\n",
    "\n",
    "Because this is an regression problem, we need a loss function describing how far we are from the correct answer.\n",
    "I propose an $MSE$ metric with a sum reduction:\n",
    "\n",
    "\\begin{equation}\n",
    "MSE = \\frac{1}{2} \\left( y - \\hat{y} \\right)^2\n",
    "\\end{equation}\n",
    "\n",
    "It will allow us to compute a gradient that moves towards a better solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_mse(y_hat, y):\n",
    "    mse = 0.0\n",
    "    for a,b in zip(y_hat, y):\n",
    "        mse += 0.5 * (a - b)**2\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing our benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.49384614327831"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = nasdaq_train.iloc[sample:sample+steps,3].values\n",
    "loss_mse(target, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(in_data, target, w=1):\n",
    "    loss = [[], []]\n",
    "    for i in range(2, 90):\n",
    "        benchmark = MA_regressor(i)\n",
    "        y = benchmark.predict([in_data.values], 10)[0]\n",
    "        loss[0].append(i)\n",
    "        loss[1].append(loss_mse(target, y) / w)\n",
    "    return np.array(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0d000a0668>]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample = 100\n",
    "tests = 500\n",
    "\n",
    "loss = test(nasdaq_train.iloc[:sample], nasdaq_train.iloc[sample:sample+steps,3].values, w=tests)\n",
    "for offset in range(1,tests,2):\n",
    "    loss[1] += test(nasdaq_train.iloc[offset:offset+sample],\n",
    "                 nasdaq_train.iloc[offset+sample:offset+sample+steps,3].values, w=tests)[1]\n",
    "\n",
    "plt.plot(*loss, 'x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best benchmark model\n",
    "It is clear that the lowest value of `N = 2` gives the best results over half of the NASDAQ train dataset.\n",
    "\n",
    "Let's save it as our final benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = MA_regressor(N=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM model\n",
    "Great, now that we know what the performance of our benchmark is, we can start developing a better solution.\n",
    "Inside `model/model.py` I have created 2 similar LSTM Regression classes:\n",
    "- LSTMRegeressor - which uses convolution to normalize the data,\n",
    "- LSTMBatchRegressor - which normalizes the data with trainable 1-D Batch Normalization layer.\n",
    "\n",
    "I will train both of them and compare the results.\n",
    "\n",
    "## Data Loader\n",
    "Before we start we need to create a data loader for our problem.\n",
    "The best approach is to use a sliding window over the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlidingWindowDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, window_size):\n",
    "        super().__init__()\n",
    "        self.timeseries = data\n",
    "        self.window = window_size\n",
    "        self.length = len(self.timeseries)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.length - self.window + 1\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        if type(index) is slice:\n",
    "            start = 0\n",
    "            stop = self.length - self.window\n",
    "            step = 1\n",
    "            if index.start is not None:\n",
    "                start = index.start\n",
    "            if index.stop is not None:\n",
    "                stop = index.stop\n",
    "            if index.step is not None:\n",
    "                step = index.step\n",
    "            return np.array([self.timeseries[i:i+self.window] for i in range(start,stop,step)])\n",
    "        else:\n",
    "            last = index + self.window\n",
    "            if index < 0 or last > self.length:\n",
    "                raise IndexError\n",
    "            return self.timeseries[index:last]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = SlidingWindowDataset(nasdaq_test.values, 5)\n",
    "ds_loader = torch.utils.data.DataLoader(ds, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 5, 9]),\n",
       " tensor([[[ 6.5735e+03,  6.5867e+03,  6.3046e+03,  6.3330e+03,  1.0000e+00,\n",
       "            7.2584e+03,  7.4221e+03, -1.9542e+02,  5.0000e+01],\n",
       "          [ 6.2785e+03,  6.3552e+03,  6.1902e+03,  6.1929e+03,  3.0000e+00,\n",
       "            7.2264e+03,  7.3989e+03, -1.4007e+02,  4.2857e+01],\n",
       "          [ 6.2579e+03,  6.5555e+03,  6.2143e+03,  6.5544e+03,  2.0000e+00,\n",
       "            7.2062e+03,  7.3729e+03,  3.6144e+02,  3.5714e+01],\n",
       "          [ 6.4572e+03,  6.5830e+03,  6.3370e+03,  6.5795e+03,  1.0000e+00,\n",
       "            7.1874e+03,  7.3521e+03,  2.5130e+01,  4.2857e+01],\n",
       "          [ 6.6168e+03,  6.6842e+03,  6.5292e+03,  6.5845e+03,  1.0000e+00,\n",
       "            7.1693e+03,  7.3333e+03,  5.0298e+00,  4.2857e+01]],\n",
       " \n",
       "         [[ 6.2785e+03,  6.3552e+03,  6.1902e+03,  6.1929e+03,  3.0000e+00,\n",
       "            7.2264e+03,  7.3989e+03, -1.4007e+02,  4.2857e+01],\n",
       "          [ 6.2579e+03,  6.5555e+03,  6.2143e+03,  6.5544e+03,  2.0000e+00,\n",
       "            7.2062e+03,  7.3729e+03,  3.6144e+02,  3.5714e+01],\n",
       "          [ 6.4572e+03,  6.5830e+03,  6.3370e+03,  6.5795e+03,  1.0000e+00,\n",
       "            7.1874e+03,  7.3521e+03,  2.5130e+01,  4.2857e+01],\n",
       "          [ 6.6168e+03,  6.6842e+03,  6.5292e+03,  6.5845e+03,  1.0000e+00,\n",
       "            7.1693e+03,  7.3333e+03,  5.0298e+00,  4.2857e+01],\n",
       "          [ 6.6495e+03,  6.6600e+03,  6.5701e+03,  6.6353e+03,  3.0000e+00,\n",
       "            7.1533e+03,  7.3137e+03,  5.0760e+01,  5.0000e+01]],\n",
       " \n",
       "         [[ 6.2579e+03,  6.5555e+03,  6.2143e+03,  6.5544e+03,  2.0000e+00,\n",
       "            7.2062e+03,  7.3729e+03,  3.6144e+02,  3.5714e+01],\n",
       "          [ 6.4572e+03,  6.5830e+03,  6.3370e+03,  6.5795e+03,  1.0000e+00,\n",
       "            7.1874e+03,  7.3521e+03,  2.5130e+01,  4.2857e+01],\n",
       "          [ 6.6168e+03,  6.6842e+03,  6.5292e+03,  6.5845e+03,  1.0000e+00,\n",
       "            7.1693e+03,  7.3333e+03,  5.0298e+00,  4.2857e+01],\n",
       "          [ 6.6495e+03,  6.6600e+03,  6.5701e+03,  6.6353e+03,  3.0000e+00,\n",
       "            7.1533e+03,  7.3137e+03,  5.0760e+01,  5.0000e+01],\n",
       "          [ 6.5069e+03,  6.6937e+03,  6.5069e+03,  6.6659e+03,  2.0000e+00,\n",
       "            7.1387e+03,  7.2950e+03,  3.0660e+01,  5.0000e+01]],\n",
       " \n",
       "         [[ 6.4572e+03,  6.5830e+03,  6.3370e+03,  6.5795e+03,  1.0000e+00,\n",
       "            7.1874e+03,  7.3521e+03,  2.5130e+01,  4.2857e+01],\n",
       "          [ 6.6168e+03,  6.6842e+03,  6.5292e+03,  6.5845e+03,  1.0000e+00,\n",
       "            7.1693e+03,  7.3333e+03,  5.0298e+00,  4.2857e+01],\n",
       "          [ 6.6495e+03,  6.6600e+03,  6.5701e+03,  6.6353e+03,  3.0000e+00,\n",
       "            7.1533e+03,  7.3137e+03,  5.0760e+01,  5.0000e+01],\n",
       "          [ 6.5069e+03,  6.6937e+03,  6.5069e+03,  6.6659e+03,  2.0000e+00,\n",
       "            7.1387e+03,  7.2950e+03,  3.0660e+01,  5.0000e+01],\n",
       "          [ 6.5848e+03,  6.6002e+03,  6.4571e+03,  6.4635e+03,  1.0000e+00,\n",
       "            7.1184e+03,  7.2755e+03, -2.0244e+02,  5.0000e+01]]],\n",
       "        dtype=torch.float64))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = next(iter(ds_loader))\n",
    "sample.shape, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uploading data\n",
    "We need to store our input files on S3 server.\n",
    "\n",
    "**The S3 location will be needed later to download correct `meta.csv` file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/stock_forecasting'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nasdaq_export': 's3://sagemaker-us-east-1-236375122127/sagemaker/stock_forecasting/nasdaq_export',\n",
       " 'eurusd_export': 's3://sagemaker-us-east-1-236375122127/sagemaker/stock_forecasting/eurusd_export'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data = {}\n",
    "for directory in ['nasdaq_export', 'eurusd_export']:\n",
    "    in_data.update({directory: sagemaker_session.upload_data(path=os.path.join(data_dir,directory), bucket=bucket, key_prefix=os.path.join(prefix,directory))})\n",
    "in_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "Before we run training job let's make sure that everything works as expected.\n",
    "Here is a good place to test some different parameters as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model.model as mdl\n",
    "import model.train as trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loader(batch_size, sliding_window, dataframe):\n",
    "    train_ds = mdl.SlidingWindowDataset(dataframe.values, sliding_window)\n",
    "    return torch.utils.data.DataLoader(train_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = 30\n",
    "outputs = 1\n",
    "\n",
    "model = mdl.LSTMRegressor(input_size=inputs, input_channels=9, c_filters=3, c_kernel_size=3, lstm_layers=2, lstm_hidden=1, dropout=0.4, output_size=outputs)\n",
    "model = model.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.MSELoss(reduction='sum')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = get_data_loader(16, inputs+outputs, nasdaq_train)\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.return_types.min(\n",
      "values=tensor([[-3.6056, -2.9427, -2.4004, -1.9485, -1.5661, -1.2383, -2.8104, -2.0357,\n",
      "         -1.9959, -2.0604, -2.1770, -1.4605, -1.4015, -1.1331, -1.0805, -1.2456,\n",
      "         -0.9456, -0.8791, -0.7736, -0.6450, -0.6296, -0.5064, -0.5064, -0.5064,\n",
      "         -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,  0.8461],\n",
      "        [-2.9427, -2.4004, -1.9485, -1.5661, -1.2383, -2.8104, -2.0357, -1.9959,\n",
      "         -2.0604, -2.1770, -1.4605, -1.4015, -1.1331, -1.0805, -1.2456, -0.9456,\n",
      "         -0.8791, -0.7736, -0.6450, -0.6296, -0.5064, -0.5064, -0.5064, -0.0999,\n",
      "         -0.5064, -0.5064, -0.5064, -0.9353,  0.8461, -1.0446],\n",
      "        [-2.4004, -1.9485, -1.5661, -1.2383, -2.8104, -2.0357, -1.9959, -2.0604,\n",
      "         -2.1770, -1.4605, -1.4015, -1.1331, -1.0805, -1.2456, -0.9456, -0.8791,\n",
      "         -0.7736, -0.6450, -0.6296, -0.5064, -0.5064, -0.5064, -0.0999, -0.5064,\n",
      "         -0.5064, -0.5064, -0.9353,  0.8461, -1.0446, -0.6053],\n",
      "        [-1.9485, -1.5661, -1.2383, -2.8104, -2.0357, -1.9959, -2.0604, -2.1770,\n",
      "         -1.4605, -1.4015, -1.1331, -1.0805, -1.2456, -0.9456, -0.8791, -0.7736,\n",
      "         -0.6450, -0.6296, -0.5064, -0.5064, -0.5064, -0.0999, -0.5064, -0.5064,\n",
      "         -0.5064, -0.9353,  0.8461, -1.0446, -0.6053, -0.5064],\n",
      "        [-1.5661, -1.2383, -2.8104, -2.0357, -1.9959, -2.0604, -2.1770, -1.4605,\n",
      "         -1.4015, -1.1331, -1.0805, -1.2456, -0.9456, -0.8791, -0.7736, -0.6450,\n",
      "         -0.6296, -0.5064, -0.5064, -0.5064, -0.0999, -0.5064, -0.5064, -0.5064,\n",
      "         -0.9353,  0.8461, -1.0446, -0.6053, -0.5064, -1.8197],\n",
      "        [-1.2383, -2.8104, -2.0357, -1.9959, -2.0604, -2.1770, -1.4605, -1.4015,\n",
      "         -1.1331, -1.0805, -1.2456, -0.9456, -0.8791, -0.7736, -0.6450, -0.6296,\n",
      "         -0.5064, -0.5064, -0.5064, -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,\n",
      "          0.8461, -1.0446, -0.6053, -0.5064, -1.8197, -0.0208],\n",
      "        [-2.8104, -2.0357, -1.9959, -2.0604, -2.1770, -1.4605, -1.4015, -1.1331,\n",
      "         -1.0805, -1.2456, -0.9456, -0.8791, -0.7736, -0.6450, -0.6296, -0.5064,\n",
      "         -0.5064, -0.5064, -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,  0.8461,\n",
      "         -1.0446, -0.6053, -0.5064, -1.8197, -0.0208, -2.5939],\n",
      "        [-2.0357, -1.9959, -2.0604, -2.1770, -1.4605, -1.4015, -1.1331, -1.0805,\n",
      "         -1.2456, -0.9456, -0.8791, -0.7736, -0.6450, -0.6296, -0.5064, -0.5064,\n",
      "         -0.5064, -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,  0.8461, -1.0446,\n",
      "         -0.6053, -0.5064, -1.8197, -0.0208, -2.5939, -0.6296],\n",
      "        [-1.9959, -2.0604, -2.1770, -1.4605, -1.4015, -1.1331, -1.0805, -1.2456,\n",
      "         -0.9456, -0.8791, -0.7736, -0.6450, -0.6296, -0.5064, -0.5064, -0.5064,\n",
      "         -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,  0.8461, -1.0446, -0.6053,\n",
      "         -0.5064, -1.8197, -0.0208, -2.5939, -0.6296, -1.2383],\n",
      "        [-2.0604, -2.1770, -1.4605, -1.4015, -1.1331, -1.0805, -1.2456, -0.9456,\n",
      "         -0.8791, -0.7736, -0.6450, -0.6296, -0.5064, -0.5064, -0.5064, -0.0999,\n",
      "         -0.5064, -0.5064, -0.5064, -0.9353,  0.8461, -1.0446, -0.6053, -0.5064,\n",
      "         -1.8197, -0.0208, -2.5939, -0.6296, -1.2383, -1.2383],\n",
      "        [-2.1770, -1.4605, -1.4015, -1.1331, -1.0805, -1.2456, -0.9456, -0.8791,\n",
      "         -0.7736, -0.6450, -0.6296, -0.5064, -0.5064, -0.5064, -0.0999, -0.5064,\n",
      "         -0.5064, -0.5064, -0.9353,  0.8461, -1.0446, -0.6053, -0.5064, -1.8197,\n",
      "         -0.0208, -2.5939, -0.6296, -1.2383, -1.2383, -1.8470],\n",
      "        [-1.4605, -1.4015, -1.1331, -1.0805, -1.2456, -0.9456, -0.8791, -0.7736,\n",
      "         -0.6450, -0.6296, -0.5064, -0.5064, -0.5064, -0.0999, -0.5064, -0.5064,\n",
      "         -0.5064, -0.9353,  0.8461, -1.0446, -0.6053, -0.5064, -1.8197, -0.0208,\n",
      "         -2.5939, -0.6296, -1.2383, -1.2383, -1.8470, -1.8470],\n",
      "        [-1.4015, -1.1331, -1.0805, -1.2456, -0.9456, -0.8791, -0.7736, -0.6450,\n",
      "         -0.6296, -0.5064, -0.5064, -0.5064, -0.0999, -0.5064, -0.5064, -0.5064,\n",
      "         -0.9353,  0.8461, -1.0446, -0.6053, -0.5064, -1.8197, -0.0208, -2.5939,\n",
      "         -0.6296, -1.2383, -1.2383, -1.8470, -1.8470, -1.2383],\n",
      "        [-1.1331, -1.0805, -1.2456, -0.9456, -0.8791, -0.7736, -0.6450, -0.6296,\n",
      "         -0.5064, -0.5064, -0.5064, -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,\n",
      "          0.8461, -1.0446, -0.6053, -0.5064, -1.8197, -0.0208, -2.5939, -0.6296,\n",
      "         -1.2383, -1.2383, -1.8470, -1.8470, -1.2383, -1.2383],\n",
      "        [-1.0805, -1.2456, -0.9456, -0.8791, -0.7736, -0.6450, -0.6296, -0.5064,\n",
      "         -0.5064, -0.5064, -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,  0.8461,\n",
      "         -1.0446, -0.6053, -0.5064, -1.8197, -0.0208, -2.5939, -0.6296, -1.2383,\n",
      "         -1.2383, -1.8470, -1.8470, -1.2383, -1.2383, -0.6296],\n",
      "        [-1.2456, -0.9456, -0.8791, -0.7736, -0.6450, -0.6296, -0.5064, -0.5064,\n",
      "         -0.5064, -0.0999, -0.5064, -0.5064, -0.5064, -0.9353,  0.8461, -1.0446,\n",
      "         -0.6053, -0.5064, -1.8197, -0.0208, -2.5939, -0.6296, -1.2383, -1.2383,\n",
      "         -1.8470, -1.8470, -1.2383, -1.2383, -0.6296, -0.6818]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[8, 8, 8, 8, 8, 8, 7, 3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4,\n",
      "         7, 4, 4, 4, 7, 6],\n",
      "        [8, 8, 8, 8, 8, 7, 3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7,\n",
      "         4, 4, 4, 7, 6, 7],\n",
      "        [8, 8, 8, 8, 7, 3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4,\n",
      "         4, 4, 7, 6, 7, 7],\n",
      "        [8, 8, 8, 7, 3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4,\n",
      "         4, 7, 6, 7, 7, 4],\n",
      "        [8, 8, 7, 3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4,\n",
      "         7, 6, 7, 7, 4, 7],\n",
      "        [8, 7, 3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7,\n",
      "         6, 7, 7, 4, 7, 8],\n",
      "        [7, 3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6,\n",
      "         7, 7, 4, 7, 8, 7],\n",
      "        [3, 2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7,\n",
      "         7, 4, 7, 8, 7, 8],\n",
      "        [2, 3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7,\n",
      "         4, 7, 8, 7, 8, 8],\n",
      "        [3, 2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7, 4,\n",
      "         7, 8, 7, 8, 8, 8],\n",
      "        [2, 0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7, 4, 7,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [0, 0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7, 4, 7, 8,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [0, 0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7, 4, 7, 8, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [0, 3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7, 4, 7, 8, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [3, 3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7, 4, 7, 8, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [3, 5, 5, 5, 5, 8, 4, 4, 4, 7, 4, 4, 4, 7, 6, 7, 7, 4, 7, 8, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.3594, -3.0113, -2.7871, -2.6209, -2.4302, -2.2466, -2.0680, -1.8840,\n",
      "         -1.6837, -1.4906, -1.3108, -1.1326, -0.9792, -0.7949, -0.7492, -0.5004,\n",
      "         -0.5004, -1.4542, -0.1575, -2.1584, -1.7320, -1.5020, -1.3544, -1.4991,\n",
      "         -1.4991, -0.9048, -0.9048, -0.5004, -0.4192, -0.5004],\n",
      "        [-3.0113, -2.7871, -2.6209, -2.4302, -2.2466, -2.0680, -1.8840, -1.6837,\n",
      "         -1.4906, -1.3108, -1.1326, -0.9792, -0.7949, -0.7492, -0.5004, -0.5004,\n",
      "         -1.4542, -0.1575, -2.1584, -1.7320, -1.5020, -1.3544, -1.4991, -1.4991,\n",
      "         -0.9048, -0.9048, -0.5004, -0.4192, -0.5004, -3.0786],\n",
      "        [-2.7871, -2.6209, -2.4302, -2.2466, -2.0680, -1.8840, -1.6837, -1.4906,\n",
      "         -1.3108, -1.1326, -0.9792, -0.7949, -0.7492, -0.5004, -0.5004, -1.4542,\n",
      "         -0.1575, -2.1584, -1.7320, -1.5020, -1.3544, -1.4991, -1.4991, -0.9048,\n",
      "         -0.9048, -0.5004, -0.4192, -0.5004, -3.0786, -1.8389],\n",
      "        [-2.6209, -2.4302, -2.2466, -2.0680, -1.8840, -1.6837, -1.4906, -1.3108,\n",
      "         -1.1326, -0.9792, -0.7949, -0.7492, -0.5004, -0.5004, -1.4542, -0.1575,\n",
      "         -2.1584, -1.7320, -1.5020, -1.3544, -1.4991, -1.4991, -0.9048, -0.9048,\n",
      "         -0.5004, -0.4192, -0.5004, -3.0786, -1.8389, -1.3221],\n",
      "        [-2.4302, -2.2466, -2.0680, -1.8840, -1.6837, -1.4906, -1.3108, -1.1326,\n",
      "         -0.9792, -0.7949, -0.7492, -0.5004, -0.5004, -1.4542, -0.1575, -2.1584,\n",
      "         -1.7320, -1.5020, -1.3544, -1.4991, -1.4991, -0.9048, -0.9048, -0.5004,\n",
      "         -0.4192, -0.5004, -3.0786, -1.8389, -1.3221, -0.9048],\n",
      "        [-2.2466, -2.0680, -1.8840, -1.6837, -1.4906, -1.3108, -1.1326, -0.9792,\n",
      "         -0.7949, -0.7492, -0.5004, -0.5004, -1.4542, -0.1575, -2.1584, -1.7320,\n",
      "         -1.5020, -1.3544, -1.4991, -1.4991, -0.9048, -0.9048, -0.5004, -0.4192,\n",
      "         -0.5004, -3.0786, -1.8389, -1.3221, -0.9048, -1.2244],\n",
      "        [-2.0680, -1.8840, -1.6837, -1.4906, -1.3108, -1.1326, -0.9792, -0.7949,\n",
      "         -0.7492, -0.5004, -0.5004, -1.4542, -0.1575, -2.1584, -1.7320, -1.5020,\n",
      "         -1.3544, -1.4991, -1.4991, -0.9048, -0.9048, -0.5004, -0.4192, -0.5004,\n",
      "         -3.0786, -1.8389, -1.3221, -0.9048, -1.2244, -1.3249],\n",
      "        [-1.8840, -1.6837, -1.4906, -1.3108, -1.1326, -0.9792, -0.7949, -0.7492,\n",
      "         -0.5004, -0.5004, -1.4542, -0.1575, -2.1584, -1.7320, -1.5020, -1.3544,\n",
      "         -1.4991, -1.4991, -0.9048, -0.9048, -0.5004, -0.4192, -0.5004, -3.0786,\n",
      "         -1.8389, -1.3221, -0.9048, -1.2244, -1.3249, -1.1584],\n",
      "        [-1.6837, -1.4906, -1.3108, -1.1326, -0.9792, -0.7949, -0.7492, -0.5004,\n",
      "         -0.5004, -1.4542, -0.1575, -2.1584, -1.7320, -1.5020, -1.3544, -1.4991,\n",
      "         -1.4991, -0.9048, -0.9048, -0.5004, -0.4192, -0.5004, -3.0786, -1.8389,\n",
      "         -1.3221, -0.9048, -1.2244, -1.3249, -1.1584, -1.4659],\n",
      "        [-1.4906, -1.3108, -1.1326, -0.9792, -0.7949, -0.7492, -0.5004, -0.5004,\n",
      "         -1.4542, -0.1575, -2.1584, -1.7320, -1.5020, -1.3544, -1.4991, -1.4991,\n",
      "         -0.9048, -0.9048, -0.5004, -0.4192, -0.5004, -3.0786, -1.8389, -1.3221,\n",
      "         -0.9048, -1.2244, -1.3249, -1.1584, -1.4659, -0.5553],\n",
      "        [-1.3108, -1.1326, -0.9792, -0.7949, -0.7492, -0.5004, -0.5004, -1.4542,\n",
      "         -0.1575, -2.1584, -1.7320, -1.5020, -1.3544, -1.4991, -1.4991, -0.9048,\n",
      "         -0.9048, -0.5004, -0.4192, -0.5004, -3.0786, -1.8389, -1.3221, -0.9048,\n",
      "         -1.2244, -1.3249, -1.1584, -1.4659, -0.5553, -0.9048],\n",
      "        [-1.1326, -0.9792, -0.7949, -0.7492, -0.5004, -0.5004, -1.4542, -0.1575,\n",
      "         -2.1584, -1.7320, -1.5020, -1.3544, -1.4991, -1.4991, -0.9048, -0.9048,\n",
      "         -0.5004, -0.4192, -0.5004, -3.0786, -1.8389, -1.3221, -0.9048, -1.2244,\n",
      "         -1.3249, -1.1584, -1.4659, -0.5553, -0.9048, -0.9048],\n",
      "        [-0.9792, -0.7949, -0.7492, -0.5004, -0.5004, -1.4542, -0.1575, -2.1584,\n",
      "         -1.7320, -1.5020, -1.3544, -1.4991, -1.4991, -0.9048, -0.9048, -0.5004,\n",
      "         -0.4192, -0.5004, -3.0786, -1.8389, -1.3221, -0.9048, -1.2244, -1.3249,\n",
      "         -1.1584, -1.4659, -0.5553, -0.9048, -0.9048, -0.9048],\n",
      "        [-0.7949, -0.7492, -0.5004, -0.5004, -1.4542, -0.1575, -2.1584, -1.7320,\n",
      "         -1.5020, -1.3544, -1.4991, -1.4991, -0.9048, -0.9048, -0.5004, -0.4192,\n",
      "         -0.5004, -3.0786, -1.8389, -1.3221, -0.9048, -1.2244, -1.3249, -1.1584,\n",
      "         -1.4659, -0.5553, -0.9048, -0.9048, -0.9048, -0.9048],\n",
      "        [-0.7492, -0.5004, -0.5004, -1.4542, -0.1575, -2.1584, -1.7320, -1.5020,\n",
      "         -1.3544, -1.4991, -1.4991, -0.9048, -0.9048, -0.5004, -0.4192, -0.5004,\n",
      "         -3.0786, -1.8389, -1.3221, -0.9048, -1.2244, -1.3249, -1.1584, -1.4659,\n",
      "         -0.5553, -0.9048, -0.9048, -0.9048, -0.9048, -0.9048],\n",
      "        [-0.5004, -0.5004, -1.4542, -0.1575, -2.1584, -1.7320, -1.5020, -1.3544,\n",
      "         -1.4991, -1.4991, -0.9048, -0.9048, -0.5004, -0.4192, -0.5004, -3.0786,\n",
      "         -1.8389, -1.3221, -0.9048, -1.2244, -1.3249, -1.1584, -1.4659, -0.5553,\n",
      "         -0.9048, -0.9048, -0.9048, -0.9048, -0.9048, -0.9048]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[1, 1, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8,\n",
      "         8, 8, 8, 4, 7, 4],\n",
      "        [1, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8,\n",
      "         8, 8, 4, 7, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8,\n",
      "         8, 4, 7, 4, 7, 0],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8,\n",
      "         4, 7, 4, 7, 0, 0],\n",
      "        [6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4,\n",
      "         7, 4, 7, 0, 0, 8],\n",
      "        [6, 6, 6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7,\n",
      "         4, 7, 0, 0, 8, 7],\n",
      "        [6, 6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4,\n",
      "         7, 0, 0, 8, 7, 2],\n",
      "        [6, 6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7,\n",
      "         0, 0, 8, 7, 2, 1],\n",
      "        [6, 6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0,\n",
      "         0, 8, 7, 2, 1, 0],\n",
      "        [6, 5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0, 0,\n",
      "         8, 7, 2, 1, 0, 3],\n",
      "        [5, 5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0, 0, 8,\n",
      "         7, 2, 1, 0, 3, 8],\n",
      "        [5, 5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0, 0, 8, 7,\n",
      "         2, 1, 0, 3, 8, 8],\n",
      "        [5, 5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0, 0, 8, 7, 2,\n",
      "         1, 0, 3, 8, 8, 8],\n",
      "        [5, 7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0, 0, 8, 7, 2, 1,\n",
      "         0, 3, 8, 8, 8, 8],\n",
      "        [7, 4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0, 0, 8, 7, 2, 1, 0,\n",
      "         3, 8, 8, 8, 8, 8],\n",
      "        [4, 4, 7, 1, 7, 3, 0, 2, 8, 8, 8, 8, 4, 7, 4, 7, 0, 0, 8, 7, 2, 1, 0, 3,\n",
      "         8, 8, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.2573, -2.1247, -1.9803, -2.1009, -1.8848, -1.7990, -1.7383, -2.0342,\n",
      "         -2.0342, -1.3273, -1.1547, -0.9516, -0.8032, -0.6720, -2.9833, -1.9093,\n",
      "         -1.4738, -0.7023, -1.2053, -1.4684, -1.4201, -1.5950, -0.8469, -0.7023,\n",
      "         -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.4983],\n",
      "        [-2.1247, -1.9803, -2.1009, -1.8848, -1.7990, -1.7383, -2.0342, -2.0342,\n",
      "         -1.3273, -1.1547, -0.9516, -0.8032, -0.6720, -2.9833, -1.9093, -1.4738,\n",
      "         -0.7023, -1.2053, -1.4684, -1.4201, -1.5950, -0.8469, -0.7023, -0.7023,\n",
      "         -0.7023, -0.7023, -0.7023, -0.7023, -0.4983, -1.9354],\n",
      "        [-1.9803, -2.1009, -1.8848, -1.7990, -1.7383, -2.0342, -2.0342, -1.3273,\n",
      "         -1.1547, -0.9516, -0.8032, -0.6720, -2.9833, -1.9093, -1.4738, -0.7023,\n",
      "         -1.2053, -1.4684, -1.4201, -1.5950, -0.8469, -0.7023, -0.7023, -0.7023,\n",
      "         -0.7023, -0.7023, -0.7023, -0.4983, -1.9354, -0.7023],\n",
      "        [-2.1009, -1.8848, -1.7990, -1.7383, -2.0342, -2.0342, -1.3273, -1.1547,\n",
      "         -0.9516, -0.8032, -0.6720, -2.9833, -1.9093, -1.4738, -0.7023, -1.2053,\n",
      "         -1.4684, -1.4201, -1.5950, -0.8469, -0.7023, -0.7023, -0.7023, -0.7023,\n",
      "         -0.7023, -0.7023, -0.4983, -1.9354, -0.7023, -0.7023],\n",
      "        [-1.8848, -1.7990, -1.7383, -2.0342, -2.0342, -1.3273, -1.1547, -0.9516,\n",
      "         -0.8032, -0.6720, -2.9833, -1.9093, -1.4738, -0.7023, -1.2053, -1.4684,\n",
      "         -1.4201, -1.5950, -0.8469, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023,\n",
      "         -0.7023, -0.4983, -1.9354, -0.7023, -0.7023, -0.4983],\n",
      "        [-1.7990, -1.7383, -2.0342, -2.0342, -1.3273, -1.1547, -0.9516, -0.8032,\n",
      "         -0.6720, -2.9833, -1.9093, -1.4738, -0.7023, -1.2053, -1.4684, -1.4201,\n",
      "         -1.5950, -0.8469, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023,\n",
      "         -0.4983, -1.9354, -0.7023, -0.7023, -0.4983, -0.4983],\n",
      "        [-1.7383, -2.0342, -2.0342, -1.3273, -1.1547, -0.9516, -0.8032, -0.6720,\n",
      "         -2.9833, -1.9093, -1.4738, -0.7023, -1.2053, -1.4684, -1.4201, -1.5950,\n",
      "         -0.8469, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.4983,\n",
      "         -1.9354, -0.7023, -0.7023, -0.4983, -0.4983, -0.4983],\n",
      "        [-2.0342, -2.0342, -1.3273, -1.1547, -0.9516, -0.8032, -0.6720, -2.9833,\n",
      "         -1.9093, -1.4738, -0.7023, -1.2053, -1.4684, -1.4201, -1.5950, -0.8469,\n",
      "         -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.4983, -1.9354,\n",
      "         -0.7023, -0.7023, -0.4983, -0.4983, -0.4983, -0.8398],\n",
      "        [-2.0342, -1.3273, -1.1547, -0.9516, -0.8032, -0.6720, -2.9833, -1.9093,\n",
      "         -1.4738, -0.7023, -1.2053, -1.4684, -1.4201, -1.5950, -0.8469, -0.7023,\n",
      "         -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.4983, -1.9354, -0.7023,\n",
      "         -0.7023, -0.4983, -0.4983, -0.4983, -0.8398, -0.4983],\n",
      "        [-1.3273, -1.1547, -0.9516, -0.8032, -0.6720, -2.9833, -1.9093, -1.4738,\n",
      "         -0.7023, -1.2053, -1.4684, -1.4201, -1.5950, -0.8469, -0.7023, -0.7023,\n",
      "         -0.7023, -0.7023, -0.7023, -0.7023, -0.4983, -1.9354, -0.7023, -0.7023,\n",
      "         -0.4983, -0.4983, -0.4983, -0.8398, -0.4983, -0.8386],\n",
      "        [-1.1547, -0.9516, -0.8032, -0.6720, -2.9833, -1.9093, -1.4738, -0.7023,\n",
      "         -1.2053, -1.4684, -1.4201, -1.5950, -0.8469, -0.7023, -0.7023, -0.7023,\n",
      "         -0.7023, -0.7023, -0.7023, -0.4983, -1.9354, -0.7023, -0.7023, -0.4983,\n",
      "         -0.4983, -0.4983, -0.8398, -0.4983, -0.8386, -2.0902],\n",
      "        [-0.9516, -0.8032, -0.6720, -2.9833, -1.9093, -1.4738, -0.7023, -1.2053,\n",
      "         -1.4684, -1.4201, -1.5950, -0.8469, -0.7023, -0.7023, -0.7023, -0.7023,\n",
      "         -0.7023, -0.7023, -0.4983, -1.9354, -0.7023, -0.7023, -0.4983, -0.4983,\n",
      "         -0.4983, -0.8398, -0.4983, -0.8386, -2.0902, -2.0342],\n",
      "        [-0.8032, -0.6720, -2.9833, -1.9093, -1.4738, -0.7023, -1.2053, -1.4684,\n",
      "         -1.4201, -1.5950, -0.8469, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023,\n",
      "         -0.7023, -0.4983, -1.9354, -0.7023, -0.7023, -0.4983, -0.4983, -0.4983,\n",
      "         -0.8398, -0.4983, -0.8386, -2.0902, -2.0342, -0.7023],\n",
      "        [-0.6720, -2.9833, -1.9093, -1.4738, -0.7023, -1.2053, -1.4684, -1.4201,\n",
      "         -1.5950, -0.8469, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023,\n",
      "         -0.4983, -1.9354, -0.7023, -0.7023, -0.4983, -0.4983, -0.4983, -0.8398,\n",
      "         -0.4983, -0.8386, -2.0902, -2.0342, -0.7023, -1.9756],\n",
      "        [-2.9833, -1.9093, -1.4738, -0.7023, -1.2053, -1.4684, -1.4201, -1.5950,\n",
      "         -0.8469, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.4983,\n",
      "         -1.9354, -0.7023, -0.7023, -0.4983, -0.4983, -0.4983, -0.8398, -0.4983,\n",
      "         -0.8386, -2.0902, -2.0342, -0.7023, -1.9756, -0.7772],\n",
      "        [-1.9093, -1.4738, -0.7023, -1.2053, -1.4684, -1.4201, -1.5950, -0.8469,\n",
      "         -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.7023, -0.4983, -1.9354,\n",
      "         -0.7023, -0.7023, -0.4983, -0.4983, -0.4983, -0.8398, -0.4983, -0.8386,\n",
      "         -2.0902, -2.0342, -0.7023, -1.9756, -0.7772, -0.7023]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 7, 5, 5, 5, 8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8,\n",
      "         8, 8, 8, 8, 8, 4],\n",
      "        [5, 5, 7, 5, 5, 5, 8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8,\n",
      "         8, 8, 8, 8, 4, 7],\n",
      "        [5, 7, 5, 5, 5, 8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8,\n",
      "         8, 8, 8, 4, 7, 8],\n",
      "        [7, 5, 5, 5, 8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8,\n",
      "         8, 8, 4, 7, 8, 8],\n",
      "        [5, 5, 5, 8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8,\n",
      "         8, 4, 7, 8, 8, 4],\n",
      "        [5, 5, 8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8,\n",
      "         4, 7, 8, 8, 4, 4],\n",
      "        [5, 8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4,\n",
      "         7, 8, 8, 4, 4, 4],\n",
      "        [8, 8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7,\n",
      "         8, 8, 4, 4, 4, 7],\n",
      "        [8, 5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8,\n",
      "         8, 4, 4, 4, 7, 4],\n",
      "        [5, 5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8, 8,\n",
      "         4, 4, 4, 7, 4, 7],\n",
      "        [5, 5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8, 8, 4,\n",
      "         4, 4, 7, 4, 7, 7],\n",
      "        [5, 6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8, 8, 4, 4,\n",
      "         4, 7, 4, 7, 7, 8],\n",
      "        [6, 6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8, 8, 4, 4, 4,\n",
      "         7, 4, 7, 7, 8, 8],\n",
      "        [6, 7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8, 8, 4, 4, 4, 7,\n",
      "         4, 7, 7, 8, 8, 7],\n",
      "        [7, 0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8, 8, 4, 4, 4, 7, 4,\n",
      "         7, 7, 8, 8, 7, 2],\n",
      "        [0, 0, 8, 7, 2, 1, 0, 3, 8, 8, 8, 8, 8, 8, 4, 7, 8, 8, 4, 4, 4, 7, 4, 7,\n",
      "         7, 8, 8, 7, 2, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.6094, -2.0227, -1.9726, -2.5352, -2.4962, -2.7548, -1.7937, -1.6981,\n",
      "         -1.5803, -1.4436, -1.3191, -1.2213, -1.1746, -1.0792, -2.0377, -0.8509,\n",
      "         -0.7306, -0.6373, -0.5261, -0.4962, -0.9084, -0.4962, -0.9072, -2.1974,\n",
      "         -1.6350, -0.4957, -2.0792, -1.6631, -1.6026, -0.4962],\n",
      "        [-2.0227, -1.9726, -2.5352, -2.4962, -2.7548, -1.7937, -1.6981, -1.5803,\n",
      "         -1.4436, -1.3191, -1.2213, -1.1746, -1.0792, -2.0377, -0.8509, -0.7306,\n",
      "         -0.6373, -0.5261, -0.4962, -0.9084, -0.4962, -0.9072, -2.1974, -1.6350,\n",
      "         -0.4957, -2.0792, -1.6631, -1.6026, -0.4962, -0.3495],\n",
      "        [-1.9726, -2.5352, -2.4962, -2.7548, -1.7937, -1.6981, -1.5803, -1.4436,\n",
      "         -1.3191, -1.2213, -1.1746, -1.0792, -2.0377, -0.8509, -0.7306, -0.6373,\n",
      "         -0.5261, -0.4962, -0.9084, -0.4962, -0.9072, -2.1974, -1.6350, -0.4957,\n",
      "         -2.0792, -1.6631, -1.6026, -0.4962, -0.3495, -0.8796],\n",
      "        [-2.5352, -2.4962, -2.7548, -1.7937, -1.6981, -1.5803, -1.4436, -1.3191,\n",
      "         -1.2213, -1.1746, -1.0792, -2.0377, -0.8509, -0.7306, -0.6373, -0.5261,\n",
      "         -0.4962, -0.9084, -0.4962, -0.9072, -2.1974, -1.6350, -0.4957, -2.0792,\n",
      "         -1.6631, -1.6026, -0.4962, -0.3495, -0.8796, -1.6350],\n",
      "        [-2.4962, -2.7548, -1.7937, -1.6981, -1.5803, -1.4436, -1.3191, -1.2213,\n",
      "         -1.1746, -1.0792, -2.0377, -0.8509, -0.7306, -0.6373, -0.5261, -0.4962,\n",
      "         -0.9084, -0.4962, -0.9072, -2.1974, -1.6350, -0.4957, -2.0792, -1.6631,\n",
      "         -1.6026, -0.4962, -0.3495, -0.8796, -1.6350, -1.6350],\n",
      "        [-2.7548, -1.7937, -1.6981, -1.5803, -1.4436, -1.3191, -1.2213, -1.1746,\n",
      "         -1.0792, -2.0377, -0.8509, -0.7306, -0.6373, -0.5261, -0.4962, -0.9084,\n",
      "         -0.4962, -0.9072, -2.1974, -1.6350, -0.4957, -2.0792, -1.6631, -1.6026,\n",
      "         -0.4962, -0.3495, -0.8796, -1.6350, -1.6350, -1.6350],\n",
      "        [-1.7937, -1.6981, -1.5803, -1.4436, -1.3191, -1.2213, -1.1746, -1.0792,\n",
      "         -2.0377, -0.8509, -0.7306, -0.6373, -0.5261, -0.4962, -0.9084, -0.4962,\n",
      "         -0.9072, -2.1974, -1.6350, -0.4957, -2.0792, -1.6631, -1.6026, -0.4962,\n",
      "         -0.3495, -0.8796, -1.6350, -1.6350, -1.6350, -1.6350],\n",
      "        [-1.6981, -1.5803, -1.4436, -1.3191, -1.2213, -1.1746, -1.0792, -2.0377,\n",
      "         -0.8509, -0.7306, -0.6373, -0.5261, -0.4962, -0.9084, -0.4962, -0.9072,\n",
      "         -2.1974, -1.6350, -0.4957, -2.0792, -1.6631, -1.6026, -0.4962, -0.3495,\n",
      "         -0.8796, -1.6350, -1.6350, -1.6350, -1.6350, -0.4962],\n",
      "        [-1.5803, -1.4436, -1.3191, -1.2213, -1.1746, -1.0792, -2.0377, -0.8509,\n",
      "         -0.7306, -0.6373, -0.5261, -0.4962, -0.9084, -0.4962, -0.9072, -2.1974,\n",
      "         -1.6350, -0.4957, -2.0792, -1.6631, -1.6026, -0.4962, -0.3495, -0.8796,\n",
      "         -1.6350, -1.6350, -1.6350, -1.6350, -0.4962, -0.4962],\n",
      "        [-1.4436, -1.3191, -1.2213, -1.1746, -1.0792, -2.0377, -0.8509, -0.7306,\n",
      "         -0.6373, -0.5261, -0.4962, -0.9084, -0.4962, -0.9072, -2.1974, -1.6350,\n",
      "         -0.4957, -2.0792, -1.6631, -1.6026, -0.4962, -0.3495, -0.8796, -1.6350,\n",
      "         -1.6350, -1.6350, -1.6350, -0.4962, -0.4962, -0.4962],\n",
      "        [-1.3191, -1.2213, -1.1746, -1.0792, -2.0377, -0.8509, -0.7306, -0.6373,\n",
      "         -0.5261, -0.4962, -0.9084, -0.4962, -0.9072, -2.1974, -1.6350, -0.4957,\n",
      "         -2.0792, -1.6631, -1.6026, -0.4962, -0.3495, -0.8796, -1.6350, -1.6350,\n",
      "         -1.6350, -1.6350, -0.4962, -0.4962, -0.4962, -0.4962],\n",
      "        [-1.2213, -1.1746, -1.0792, -2.0377, -0.8509, -0.7306, -0.6373, -0.5261,\n",
      "         -0.4962, -0.9084, -0.4962, -0.9072, -2.1974, -1.6350, -0.4957, -2.0792,\n",
      "         -1.6631, -1.6026, -0.4962, -0.3495, -0.8796, -1.6350, -1.6350, -1.6350,\n",
      "         -1.6350, -0.4962, -0.4962, -0.4962, -0.4962, -1.5423],\n",
      "        [-1.1746, -1.0792, -2.0377, -0.8509, -0.7306, -0.6373, -0.5261, -0.4962,\n",
      "         -0.9084, -0.4962, -0.9072, -2.1974, -1.6350, -0.4957, -2.0792, -1.6631,\n",
      "         -1.6026, -0.4962, -0.3495, -0.8796, -1.6350, -1.6350, -1.6350, -1.6350,\n",
      "         -0.4962, -0.4962, -0.4962, -0.4962, -1.5423, -0.4962],\n",
      "        [-1.0792, -2.0377, -0.8509, -0.7306, -0.6373, -0.5261, -0.4962, -0.9084,\n",
      "         -0.4962, -0.9072, -2.1974, -1.6350, -0.4957, -2.0792, -1.6631, -1.6026,\n",
      "         -0.4962, -0.3495, -0.8796, -1.6350, -1.6350, -1.6350, -1.6350, -0.4962,\n",
      "         -0.4962, -0.4962, -0.4962, -1.5423, -0.4962, -0.4962],\n",
      "        [-2.0377, -0.8509, -0.7306, -0.6373, -0.5261, -0.4962, -0.9084, -0.4962,\n",
      "         -0.9072, -2.1974, -1.6350, -0.4957, -2.0792, -1.6631, -1.6026, -0.4962,\n",
      "         -0.3495, -0.8796, -1.6350, -1.6350, -1.6350, -1.6350, -0.4962, -0.4962,\n",
      "         -0.4962, -0.4962, -1.5423, -0.4962, -0.4962, -0.8092],\n",
      "        [-0.8509, -0.7306, -0.6373, -0.5261, -0.4962, -0.9084, -0.4962, -0.9072,\n",
      "         -2.1974, -1.6350, -0.4957, -2.0792, -1.6631, -1.6026, -0.4962, -0.3495,\n",
      "         -0.8796, -1.6350, -1.6350, -1.6350, -1.6350, -0.4962, -0.4962, -0.4962,\n",
      "         -0.4962, -1.5423, -0.4962, -0.4962, -0.8092, -1.6350]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[0, 5, 5, 1, 1, 0, 5, 5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7,\n",
      "         8, 8, 7, 2, 0, 4],\n",
      "        [5, 5, 1, 1, 0, 5, 5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8,\n",
      "         8, 7, 2, 0, 4, 7],\n",
      "        [5, 1, 1, 0, 5, 5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8,\n",
      "         7, 2, 0, 4, 7, 2],\n",
      "        [1, 1, 0, 5, 5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7,\n",
      "         2, 0, 4, 7, 2, 8],\n",
      "        [1, 0, 5, 5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2,\n",
      "         0, 4, 7, 2, 8, 8],\n",
      "        [0, 5, 5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0,\n",
      "         4, 7, 2, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4,\n",
      "         7, 2, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7,\n",
      "         2, 8, 8, 8, 8, 4],\n",
      "        [5, 5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2,\n",
      "         8, 8, 8, 8, 4, 4],\n",
      "        [5, 5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2, 8,\n",
      "         8, 8, 8, 4, 4, 4],\n",
      "        [5, 6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2, 8, 8,\n",
      "         8, 8, 4, 4, 4, 4],\n",
      "        [6, 6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2, 8, 8, 8,\n",
      "         8, 4, 4, 4, 4, 7],\n",
      "        [6, 6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2, 8, 8, 8, 8,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [6, 7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2, 8, 8, 8, 8, 4,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [7, 0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2, 8, 8, 8, 8, 4, 4,\n",
      "         4, 4, 7, 4, 4, 7],\n",
      "        [0, 6, 6, 6, 4, 7, 4, 7, 7, 8, 8, 7, 2, 0, 4, 7, 2, 8, 8, 8, 8, 4, 4, 4,\n",
      "         4, 7, 4, 4, 7, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.7640, -2.6480, -2.5098, -2.3464, -2.1666, -1.9909, -1.7886, -2.3350,\n",
      "         -1.6591, -1.3654, -2.2074, -2.5967, -2.6992, -1.1563, -1.0876, -1.7423,\n",
      "         -1.2514, -1.1570, -1.1570, -1.1570, -0.4967, -0.4967, -0.4967, -0.4967,\n",
      "         -1.6278, -0.4967, -0.4967, -0.8363, -1.1570, -0.4967],\n",
      "        [-2.6480, -2.5098, -2.3464, -2.1666, -1.9909, -1.7886, -2.3350, -1.6591,\n",
      "         -1.3654, -2.2074, -2.5967, -2.6992, -1.1563, -1.0876, -1.7423, -1.2514,\n",
      "         -1.1570, -1.1570, -1.1570, -0.4967, -0.4967, -0.4967, -0.4967, -1.6278,\n",
      "         -0.4967, -0.4967, -0.8363, -1.1570, -0.4967, -0.4967],\n",
      "        [-2.5098, -2.3464, -2.1666, -1.9909, -1.7886, -2.3350, -1.6591, -1.3654,\n",
      "         -2.2074, -2.5967, -2.6992, -1.1563, -1.0876, -1.7423, -1.2514, -1.1570,\n",
      "         -1.1570, -1.1570, -0.4967, -0.4967, -0.4967, -0.4967, -1.6278, -0.4967,\n",
      "         -0.4967, -0.8363, -1.1570, -0.4967, -0.4967, -1.1721],\n",
      "        [-2.3464, -2.1666, -1.9909, -1.7886, -2.3350, -1.6591, -1.3654, -2.2074,\n",
      "         -2.5967, -2.6992, -1.1563, -1.0876, -1.7423, -1.2514, -1.1570, -1.1570,\n",
      "         -1.1570, -0.4967, -0.4967, -0.4967, -0.4967, -1.6278, -0.4967, -0.4967,\n",
      "         -0.8363, -1.1570, -0.4967, -0.4967, -1.1721, -1.1570],\n",
      "        [-2.1666, -1.9909, -1.7886, -2.3350, -1.6591, -1.3654, -2.2074, -2.5967,\n",
      "         -2.6992, -1.1563, -1.0876, -1.7423, -1.2514, -1.1570, -1.1570, -1.1570,\n",
      "         -0.4967, -0.4967, -0.4967, -0.4967, -1.6278, -0.4967, -0.4967, -0.8363,\n",
      "         -1.1570, -0.4967, -0.4967, -1.1721, -1.1570, -1.3577],\n",
      "        [-1.9909, -1.7886, -2.3350, -1.6591, -1.3654, -2.2074, -2.5967, -2.6992,\n",
      "         -1.1563, -1.0876, -1.7423, -1.2514, -1.1570, -1.1570, -1.1570, -0.4967,\n",
      "         -0.4967, -0.4967, -0.4967, -1.6278, -0.4967, -0.4967, -0.8363, -1.1570,\n",
      "         -0.4967, -0.4967, -1.1721, -1.1570, -1.3577, -1.1570],\n",
      "        [-1.7886, -2.3350, -1.6591, -1.3654, -2.2074, -2.5967, -2.6992, -1.1563,\n",
      "         -1.0876, -1.7423, -1.2514, -1.1570, -1.1570, -1.1570, -0.4967, -0.4967,\n",
      "         -0.4967, -0.4967, -1.6278, -0.4967, -0.4967, -0.8363, -1.1570, -0.4967,\n",
      "         -0.4967, -1.1721, -1.1570, -1.3577, -1.1570, -1.1570],\n",
      "        [-2.3350, -1.6591, -1.3654, -2.2074, -2.5967, -2.6992, -1.1563, -1.0876,\n",
      "         -1.7423, -1.2514, -1.1570, -1.1570, -1.1570, -0.4967, -0.4967, -0.4967,\n",
      "         -0.4967, -1.6278, -0.4967, -0.4967, -0.8363, -1.1570, -0.4967, -0.4967,\n",
      "         -1.1721, -1.1570, -1.3577, -1.1570, -1.1570, -1.1570],\n",
      "        [-1.6591, -1.3654, -2.2074, -2.5967, -2.6992, -1.1563, -1.0876, -1.7423,\n",
      "         -1.2514, -1.1570, -1.1570, -1.1570, -0.4967, -0.4967, -0.4967, -0.4967,\n",
      "         -1.6278, -0.4967, -0.4967, -0.8363, -1.1570, -0.4967, -0.4967, -1.1721,\n",
      "         -1.1570, -1.3577, -1.1570, -1.1570, -1.1570, -1.1570],\n",
      "        [-1.3654, -2.2074, -2.5967, -2.6992, -1.1563, -1.0876, -1.7423, -1.2514,\n",
      "         -1.1570, -1.1570, -1.1570, -0.4967, -0.4967, -0.4967, -0.4967, -1.6278,\n",
      "         -0.4967, -0.4967, -0.8363, -1.1570, -0.4967, -0.4967, -1.1721, -1.1570,\n",
      "         -1.3577, -1.1570, -1.1570, -1.1570, -1.1570, -1.1570],\n",
      "        [-2.2074, -2.5967, -2.6992, -1.1563, -1.0876, -1.7423, -1.2514, -1.1570,\n",
      "         -1.1570, -1.1570, -0.4967, -0.4967, -0.4967, -0.4967, -1.6278, -0.4967,\n",
      "         -0.4967, -0.8363, -1.1570, -0.4967, -0.4967, -1.1721, -1.1570, -1.3577,\n",
      "         -1.1570, -1.1570, -1.1570, -1.1570, -1.1570, -1.1570],\n",
      "        [-2.5967, -2.6992, -1.1563, -1.0876, -1.7423, -1.2514, -1.1570, -1.1570,\n",
      "         -1.1570, -0.4967, -0.4967, -0.4967, -0.4967, -1.6278, -0.4967, -0.4967,\n",
      "         -0.8363, -1.1570, -0.4967, -0.4967, -1.1721, -1.1570, -1.3577, -1.1570,\n",
      "         -1.1570, -1.1570, -1.1570, -1.1570, -1.1570, -1.1570],\n",
      "        [-2.6992, -1.1563, -1.0876, -1.7423, -1.2514, -1.1570, -1.1570, -1.1570,\n",
      "         -0.4967, -0.4967, -0.4967, -0.4967, -1.6278, -0.4967, -0.4967, -0.8363,\n",
      "         -1.1570, -0.4967, -0.4967, -1.1721, -1.1570, -1.3577, -1.1570, -1.1570,\n",
      "         -1.1570, -1.1570, -1.1570, -1.1570, -1.1570, -0.4967],\n",
      "        [-1.1563, -1.0876, -1.7423, -1.2514, -1.1570, -1.1570, -1.1570, -0.4967,\n",
      "         -0.4967, -0.4967, -0.4967, -1.6278, -0.4967, -0.4967, -0.8363, -1.1570,\n",
      "         -0.4967, -0.4967, -1.1721, -1.1570, -1.3577, -1.1570, -1.1570, -1.1570,\n",
      "         -1.1570, -1.1570, -1.1570, -1.1570, -0.4967, -0.5048],\n",
      "        [-1.0876, -1.7423, -1.2514, -1.1570, -1.1570, -1.1570, -0.4967, -0.4967,\n",
      "         -0.4967, -0.4967, -1.6278, -0.4967, -0.4967, -0.8363, -1.1570, -0.4967,\n",
      "         -0.4967, -1.1721, -1.1570, -1.3577, -1.1570, -1.1570, -1.1570, -1.1570,\n",
      "         -1.1570, -1.1570, -1.1570, -0.4967, -0.5048,  0.0534],\n",
      "        [-1.7423, -1.2514, -1.1570, -1.1570, -1.1570, -0.4967, -0.4967, -0.4967,\n",
      "         -0.4967, -1.6278, -0.4967, -0.4967, -0.8363, -1.1570, -0.4967, -0.4967,\n",
      "         -1.1721, -1.1570, -1.3577, -1.1570, -1.1570, -1.1570, -1.1570, -1.1570,\n",
      "         -1.1570, -1.1570, -0.4967, -0.5048,  0.0534, -0.4967]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4,\n",
      "         7, 4, 4, 7, 8, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7,\n",
      "         4, 4, 7, 8, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4,\n",
      "         4, 7, 8, 4, 4, 7],\n",
      "        [6, 6, 6, 6, 7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4,\n",
      "         7, 8, 4, 4, 7, 8],\n",
      "        [6, 6, 6, 7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7,\n",
      "         8, 4, 4, 7, 8, 7],\n",
      "        [6, 6, 7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8,\n",
      "         4, 4, 7, 8, 7, 8],\n",
      "        [6, 7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4,\n",
      "         4, 7, 8, 7, 8, 8],\n",
      "        [7, 0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4,\n",
      "         7, 8, 7, 8, 8, 8],\n",
      "        [0, 6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [6, 7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 8,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [7, 2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 8, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [2, 0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 8, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [0, 1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 8, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 4],\n",
      "        [1, 1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 8, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 4, 7],\n",
      "        [1, 2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 8, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 4, 7, 8],\n",
      "        [2, 3, 8, 8, 8, 4, 4, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 8, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 4, 7, 8, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.2218, -2.9976, -2.7602, -2.5164, -2.2861, -2.0847, -1.8924, -1.7078,\n",
      "         -1.6072, -1.4074, -1.2254, -1.0877, -1.2043, -0.7981, -0.6327, -0.9910,\n",
      "         -1.2043, -1.1618, -1.2686, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043,\n",
      "         -1.2043, -0.4990, -0.4990,  0.2167, -0.4990, -0.9292],\n",
      "        [-2.9976, -2.7602, -2.5164, -2.2861, -2.0847, -1.8924, -1.7078, -1.6072,\n",
      "         -1.4074, -1.2254, -1.0877, -1.2043, -0.7981, -0.6327, -0.9910, -1.2043,\n",
      "         -1.1618, -1.2686, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043,\n",
      "         -0.4990, -0.4990,  0.2167, -0.4990, -0.9292, -0.4990],\n",
      "        [-2.7602, -2.5164, -2.2861, -2.0847, -1.8924, -1.7078, -1.6072, -1.4074,\n",
      "         -1.2254, -1.0877, -1.2043, -0.7981, -0.6327, -0.9910, -1.2043, -1.1618,\n",
      "         -1.2686, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -0.4990,\n",
      "         -0.4990,  0.2167, -0.4990, -0.9292, -0.4990, -0.7767],\n",
      "        [-2.5164, -2.2861, -2.0847, -1.8924, -1.7078, -1.6072, -1.4074, -1.2254,\n",
      "         -1.0877, -1.2043, -0.7981, -0.6327, -0.9910, -1.2043, -1.1618, -1.2686,\n",
      "         -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,\n",
      "          0.2167, -0.4990, -0.9292, -0.4990, -0.7767, -3.0735],\n",
      "        [-2.2861, -2.0847, -1.8924, -1.7078, -1.6072, -1.4074, -1.2254, -1.0877,\n",
      "         -1.2043, -0.7981, -0.6327, -0.9910, -1.2043, -1.1618, -1.2686, -1.2043,\n",
      "         -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,  0.2167,\n",
      "         -0.4990, -0.9292, -0.4990, -0.7767, -3.0735, -1.6550],\n",
      "        [-2.0847, -1.8924, -1.7078, -1.6072, -1.4074, -1.2254, -1.0877, -1.2043,\n",
      "         -0.7981, -0.6327, -0.9910, -1.2043, -1.1618, -1.2686, -1.2043, -1.2043,\n",
      "         -1.2043, -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,  0.2167, -0.4990,\n",
      "         -0.9292, -0.4990, -0.7767, -3.0735, -1.6550, -1.0247],\n",
      "        [-1.8924, -1.7078, -1.6072, -1.4074, -1.2254, -1.0877, -1.2043, -0.7981,\n",
      "         -0.6327, -0.9910, -1.2043, -1.1618, -1.2686, -1.2043, -1.2043, -1.2043,\n",
      "         -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,  0.2167, -0.4990, -0.9292,\n",
      "         -0.4990, -0.7767, -3.0735, -1.6550, -1.0247, -1.2591],\n",
      "        [-1.7078, -1.6072, -1.4074, -1.2254, -1.0877, -1.2043, -0.7981, -0.6327,\n",
      "         -0.9910, -1.2043, -1.1618, -1.2686, -1.2043, -1.2043, -1.2043, -1.2043,\n",
      "         -1.2043, -1.2043, -0.4990, -0.4990,  0.2167, -0.4990, -0.9292, -0.4990,\n",
      "         -0.7767, -3.0735, -1.6550, -1.0247, -1.2591, -2.0620],\n",
      "        [-1.6072, -1.4074, -1.2254, -1.0877, -1.2043, -0.7981, -0.6327, -0.9910,\n",
      "         -1.2043, -1.1618, -1.2686, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043,\n",
      "         -1.2043, -0.4990, -0.4990,  0.2167, -0.4990, -0.9292, -0.4990, -0.7767,\n",
      "         -3.0735, -1.6550, -1.0247, -1.2591, -2.0620, -2.4610],\n",
      "        [-1.4074, -1.2254, -1.0877, -1.2043, -0.7981, -0.6327, -0.9910, -1.2043,\n",
      "         -1.1618, -1.2686, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043,\n",
      "         -0.4990, -0.4990,  0.2167, -0.4990, -0.9292, -0.4990, -0.7767, -3.0735,\n",
      "         -1.6550, -1.0247, -1.2591, -2.0620, -2.4610, -2.9142],\n",
      "        [-1.2254, -1.0877, -1.2043, -0.7981, -0.6327, -0.9910, -1.2043, -1.1618,\n",
      "         -1.2686, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -0.4990,\n",
      "         -0.4990,  0.2167, -0.4990, -0.9292, -0.4990, -0.7767, -3.0735, -1.6550,\n",
      "         -1.0247, -1.2591, -2.0620, -2.4610, -2.9142, -2.6767],\n",
      "        [-1.0877, -1.2043, -0.7981, -0.6327, -0.9910, -1.2043, -1.1618, -1.2686,\n",
      "         -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,\n",
      "          0.2167, -0.4990, -0.9292, -0.4990, -0.7767, -3.0735, -1.6550, -1.0247,\n",
      "         -1.2591, -2.0620, -2.4610, -2.9142, -2.6767, -1.7157],\n",
      "        [-1.2043, -0.7981, -0.6327, -0.9910, -1.2043, -1.1618, -1.2686, -1.2043,\n",
      "         -1.2043, -1.2043, -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,  0.2167,\n",
      "         -0.4990, -0.9292, -0.4990, -0.7767, -3.0735, -1.6550, -1.0247, -1.2591,\n",
      "         -2.0620, -2.4610, -2.9142, -2.6767, -1.7157, -0.6029],\n",
      "        [-0.7981, -0.6327, -0.9910, -1.2043, -1.1618, -1.2686, -1.2043, -1.2043,\n",
      "         -1.2043, -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,  0.2167, -0.4990,\n",
      "         -0.9292, -0.4990, -0.7767, -3.0735, -1.6550, -1.0247, -1.2591, -2.0620,\n",
      "         -2.4610, -2.9142, -2.6767, -1.7157, -0.6029, -0.4990],\n",
      "        [-0.6327, -0.9910, -1.2043, -1.1618, -1.2686, -1.2043, -1.2043, -1.2043,\n",
      "         -1.2043, -1.2043, -1.2043, -0.4990, -0.4990,  0.2167, -0.4990, -0.9292,\n",
      "         -0.4990, -0.7767, -3.0735, -1.6550, -1.0247, -1.2591, -2.0620, -2.4610,\n",
      "         -2.9142, -2.6767, -1.7157, -0.6029, -0.4990, -0.4990],\n",
      "        [-0.9910, -1.2043, -1.1618, -1.2686, -1.2043, -1.2043, -1.2043, -1.2043,\n",
      "         -1.2043, -1.2043, -0.4990, -0.4990,  0.2167, -0.4990, -0.9292, -0.4990,\n",
      "         -0.7767, -3.0735, -1.6550, -1.0247, -1.2591, -2.0620, -2.4610, -2.9142,\n",
      "         -2.6767, -1.7157, -0.6029, -0.4990, -0.4990, -0.4990]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8,\n",
      "         8, 4, 4, 8, 4, 7],\n",
      "        [6, 6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8,\n",
      "         4, 4, 8, 4, 7, 4],\n",
      "        [6, 6, 6, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4,\n",
      "         4, 8, 4, 7, 4, 7],\n",
      "        [6, 6, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4,\n",
      "         8, 4, 7, 4, 7, 7],\n",
      "        [6, 5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8,\n",
      "         4, 7, 4, 7, 7, 1],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4,\n",
      "         7, 4, 7, 7, 1, 1],\n",
      "        [5, 5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7,\n",
      "         4, 7, 7, 1, 1, 1],\n",
      "        [5, 5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4,\n",
      "         7, 7, 1, 1, 1, 0],\n",
      "        [5, 5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7,\n",
      "         7, 1, 1, 1, 0, 2],\n",
      "        [5, 5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7, 7,\n",
      "         1, 1, 1, 0, 2, 3],\n",
      "        [5, 5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7, 7, 1,\n",
      "         1, 1, 0, 2, 3, 3],\n",
      "        [5, 8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7, 7, 1, 1,\n",
      "         1, 0, 2, 3, 3, 0],\n",
      "        [8, 5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7, 7, 1, 1, 1,\n",
      "         0, 2, 3, 3, 0, 0],\n",
      "        [5, 5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7, 7, 1, 1, 1, 0,\n",
      "         2, 3, 3, 0, 0, 4],\n",
      "        [5, 7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7, 7, 1, 1, 1, 0, 2,\n",
      "         3, 3, 0, 0, 4, 4],\n",
      "        [7, 8, 7, 1, 8, 8, 8, 8, 8, 8, 4, 4, 8, 4, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3,\n",
      "         3, 0, 0, 4, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.2326, -2.1706, -2.1249, -1.9642, -1.8611, -1.7813, -1.7161, -1.6794,\n",
      "         -1.5798, -1.4846, -1.2723, -1.0647, -0.8621, -0.8716, -0.4957, -0.7373,\n",
      "         -2.7593, -1.2630, -0.8598, -1.0098, -1.5699, -1.8199, -2.0673, -1.9116,\n",
      "         -1.3899, -0.6051, -0.4957, -0.4957, -0.4957, -0.4957],\n",
      "        [-2.1706, -2.1249, -1.9642, -1.8611, -1.7813, -1.7161, -1.6794, -1.5798,\n",
      "         -1.4846, -1.2723, -1.0647, -0.8621, -0.8716, -0.4957, -0.7373, -2.7593,\n",
      "         -1.2630, -0.8598, -1.0098, -1.5699, -1.8199, -2.0673, -1.9116, -1.3899,\n",
      "         -0.6051, -0.4957, -0.4957, -0.4957, -0.4957,  0.1667],\n",
      "        [-2.1249, -1.9642, -1.8611, -1.7813, -1.7161, -1.6794, -1.5798, -1.4846,\n",
      "         -1.2723, -1.0647, -0.8621, -0.8716, -0.4957, -0.7373, -2.7593, -1.2630,\n",
      "         -0.8598, -1.0098, -1.5699, -1.8199, -2.0673, -1.9116, -1.3899, -0.6051,\n",
      "         -0.4957, -0.4957, -0.4957, -0.4957,  0.1667, -0.4957],\n",
      "        [-1.9642, -1.8611, -1.7813, -1.7161, -1.6794, -1.5798, -1.4846, -1.2723,\n",
      "         -1.0647, -0.8621, -0.8716, -0.4957, -0.7373, -2.7593, -1.2630, -0.8598,\n",
      "         -1.0098, -1.5699, -1.8199, -2.0673, -1.9116, -1.3899, -0.6051, -0.4957,\n",
      "         -0.4957, -0.4957, -0.4957,  0.1667, -0.4957, -0.8418],\n",
      "        [-1.8611, -1.7813, -1.7161, -1.6794, -1.5798, -1.4846, -1.2723, -1.0647,\n",
      "         -0.8621, -0.8716, -0.4957, -0.7373, -2.7593, -1.2630, -0.8598, -1.0098,\n",
      "         -1.5699, -1.8199, -2.0673, -1.9116, -1.3899, -0.6051, -0.4957, -0.4957,\n",
      "         -0.4957, -0.4957,  0.1667, -0.4957, -0.8418, -0.5959],\n",
      "        [-1.7813, -1.7161, -1.6794, -1.5798, -1.4846, -1.2723, -1.0647, -0.8621,\n",
      "         -0.8716, -0.4957, -0.7373, -2.7593, -1.2630, -0.8598, -1.0098, -1.5699,\n",
      "         -1.8199, -2.0673, -1.9116, -1.3899, -0.6051, -0.4957, -0.4957, -0.4957,\n",
      "         -0.4957,  0.1667, -0.4957, -0.8418, -0.5959, -1.3214],\n",
      "        [-1.7161, -1.6794, -1.5798, -1.4846, -1.2723, -1.0647, -0.8621, -0.8716,\n",
      "         -0.4957, -0.7373, -2.7593, -1.2630, -0.8598, -1.0098, -1.5699, -1.8199,\n",
      "         -2.0673, -1.9116, -1.3899, -0.6051, -0.4957, -0.4957, -0.4957, -0.4957,\n",
      "          0.1667, -0.4957, -0.8418, -0.5959, -1.3214, -1.1215],\n",
      "        [-1.6794, -1.5798, -1.4846, -1.2723, -1.0647, -0.8621, -0.8716, -0.4957,\n",
      "         -0.7373, -2.7593, -1.2630, -0.8598, -1.0098, -1.5699, -1.8199, -2.0673,\n",
      "         -1.9116, -1.3899, -0.6051, -0.4957, -0.4957, -0.4957, -0.4957,  0.1667,\n",
      "         -0.4957, -0.8418, -0.5959, -1.3214, -1.1215, -0.4957],\n",
      "        [-1.5798, -1.4846, -1.2723, -1.0647, -0.8621, -0.8716, -0.4957, -0.7373,\n",
      "         -2.7593, -1.2630, -0.8598, -1.0098, -1.5699, -1.8199, -2.0673, -1.9116,\n",
      "         -1.3899, -0.6051, -0.4957, -0.4957, -0.4957, -0.4957,  0.1667, -0.4957,\n",
      "         -0.8418, -0.5959, -1.3214, -1.1215, -0.4957, -0.4957],\n",
      "        [-1.4846, -1.2723, -1.0647, -0.8621, -0.8716, -0.4957, -0.7373, -2.7593,\n",
      "         -1.2630, -0.8598, -1.0098, -1.5699, -1.8199, -2.0673, -1.9116, -1.3899,\n",
      "         -0.6051, -0.4957, -0.4957, -0.4957, -0.4957,  0.1667, -0.4957, -0.8418,\n",
      "         -0.5959, -1.3214, -1.1215, -0.4957, -0.4957, -0.4957],\n",
      "        [-1.2723, -1.0647, -0.8621, -0.8716, -0.4957, -0.7373, -2.7593, -1.2630,\n",
      "         -0.8598, -1.0098, -1.5699, -1.8199, -2.0673, -1.9116, -1.3899, -0.6051,\n",
      "         -0.4957, -0.4957, -0.4957, -0.4957,  0.1667, -0.4957, -0.8418, -0.5959,\n",
      "         -1.3214, -1.1215, -0.4957, -0.4957, -0.4957, -0.4957],\n",
      "        [-1.0647, -0.8621, -0.8716, -0.4957, -0.7373, -2.7593, -1.2630, -0.8598,\n",
      "         -1.0098, -1.5699, -1.8199, -2.0673, -1.9116, -1.3899, -0.6051, -0.4957,\n",
      "         -0.4957, -0.4957, -0.4957,  0.1667, -0.4957, -0.8418, -0.5959, -1.3214,\n",
      "         -1.1215, -0.4957, -0.4957, -0.4957, -0.4957, -0.3171],\n",
      "        [-0.8621, -0.8716, -0.4957, -0.7373, -2.7593, -1.2630, -0.8598, -1.0098,\n",
      "         -1.5699, -1.8199, -2.0673, -1.9116, -1.3899, -0.6051, -0.4957, -0.4957,\n",
      "         -0.4957, -0.4957,  0.1667, -0.4957, -0.8418, -0.5959, -1.3214, -1.1215,\n",
      "         -0.4957, -0.4957, -0.4957, -0.4957, -0.3171, -1.3899],\n",
      "        [-0.8716, -0.4957, -0.7373, -2.7593, -1.2630, -0.8598, -1.0098, -1.5699,\n",
      "         -1.8199, -2.0673, -1.9116, -1.3899, -0.6051, -0.4957, -0.4957, -0.4957,\n",
      "         -0.4957,  0.1667, -0.4957, -0.8418, -0.5959, -1.3214, -1.1215, -0.4957,\n",
      "         -0.4957, -0.4957, -0.4957, -0.3171, -1.3899, -1.3899],\n",
      "        [-0.4957, -0.7373, -2.7593, -1.2630, -0.8598, -1.0098, -1.5699, -1.8199,\n",
      "         -2.0673, -1.9116, -1.3899, -0.6051, -0.4957, -0.4957, -0.4957, -0.4957,\n",
      "          0.1667, -0.4957, -0.8418, -0.5959, -1.3214, -1.1215, -0.4957, -0.4957,\n",
      "         -0.4957, -0.4957, -0.3171, -1.3899, -1.3899, -1.8969],\n",
      "        [-0.7373, -2.7593, -1.2630, -0.8598, -1.0098, -1.5699, -1.8199, -2.0673,\n",
      "         -1.9116, -1.3899, -0.6051, -0.4957, -0.4957, -0.4957, -0.4957,  0.1667,\n",
      "         -0.4957, -0.8418, -0.5959, -1.3214, -1.1215, -0.4957, -0.4957, -0.4957,\n",
      "         -0.4957, -0.3171, -1.3899, -1.3899, -1.8969, -2.4755]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3,\n",
      "         8, 0, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8,\n",
      "         0, 4, 4, 4, 4, 7],\n",
      "        [5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4,\n",
      "         4, 4, 4, 7, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4,\n",
      "         4, 4, 7, 4, 7, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4,\n",
      "         4, 7, 4, 7, 7, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4,\n",
      "         7, 4, 7, 7, 7, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7,\n",
      "         4, 7, 7, 7, 7, 4],\n",
      "        [6, 6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4,\n",
      "         7, 7, 7, 7, 4, 4],\n",
      "        [6, 6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4, 7,\n",
      "         7, 7, 7, 4, 4, 4],\n",
      "        [6, 6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4, 7, 7,\n",
      "         7, 7, 4, 4, 4, 4],\n",
      "        [6, 6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4, 7, 7, 7,\n",
      "         7, 4, 4, 4, 4, 7],\n",
      "        [6, 7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4, 7, 7, 7, 7,\n",
      "         4, 4, 4, 4, 7, 8],\n",
      "        [7, 4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4, 7, 7, 7, 7, 4,\n",
      "         4, 4, 4, 7, 8, 8],\n",
      "        [4, 7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4, 7, 7, 7, 7, 4, 4,\n",
      "         4, 4, 7, 8, 8, 7],\n",
      "        [7, 7, 1, 1, 1, 0, 2, 3, 3, 8, 0, 4, 4, 4, 4, 7, 4, 7, 7, 7, 7, 4, 4, 4,\n",
      "         4, 7, 8, 8, 7, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.0911, -2.0736, -2.1105, -2.1085, -2.0950, -1.9873, -1.8622, -1.8449,\n",
      "         -1.8683, -1.7780, -1.5995, -1.4016, -1.2268, -0.9908, -0.7489, -0.5210,\n",
      "         -0.5528, -0.4940, -0.9375, -0.7772, -0.4940, -0.4940, -0.4940, -0.4940,\n",
      "         -0.1318, -0.5821, -0.5821, -1.3992, -1.3005, -2.0188],\n",
      "        [-2.0736, -2.1105, -2.1085, -2.0950, -1.9873, -1.8622, -1.8449, -1.8683,\n",
      "         -1.7780, -1.5995, -1.4016, -1.2268, -0.9908, -0.7489, -0.5210, -0.5528,\n",
      "         -0.4940, -0.9375, -0.7772, -0.4940, -0.4940, -0.4940, -0.4940, -0.1318,\n",
      "         -0.5821, -0.5821, -1.3992, -1.3005, -2.0188, -1.3005],\n",
      "        [-2.1105, -2.1085, -2.0950, -1.9873, -1.8622, -1.8449, -1.8683, -1.7780,\n",
      "         -1.5995, -1.4016, -1.2268, -0.9908, -0.7489, -0.5210, -0.5528, -0.4940,\n",
      "         -0.9375, -0.7772, -0.4940, -0.4940, -0.4940, -0.4940, -0.1318, -0.5821,\n",
      "         -0.5821, -1.3992, -1.3005, -2.0188, -1.3005, -1.3005],\n",
      "        [-2.1085, -2.0950, -1.9873, -1.8622, -1.8449, -1.8683, -1.7780, -1.5995,\n",
      "         -1.4016, -1.2268, -0.9908, -0.7489, -0.5210, -0.5528, -0.4940, -0.9375,\n",
      "         -0.7772, -0.4940, -0.4940, -0.4940, -0.4940, -0.1318, -0.5821, -0.5821,\n",
      "         -1.3992, -1.3005, -2.0188, -1.3005, -1.3005, -0.5821],\n",
      "        [-2.0950, -1.9873, -1.8622, -1.8449, -1.8683, -1.7780, -1.5995, -1.4016,\n",
      "         -1.2268, -0.9908, -0.7489, -0.5210, -0.5528, -0.4940, -0.9375, -0.7772,\n",
      "         -0.4940, -0.4940, -0.4940, -0.4940, -0.1318, -0.5821, -0.5821, -1.3992,\n",
      "         -1.3005, -2.0188, -1.3005, -1.3005, -0.5821, -0.5821],\n",
      "        [-1.9873, -1.8622, -1.8449, -1.8683, -1.7780, -1.5995, -1.4016, -1.2268,\n",
      "         -0.9908, -0.7489, -0.5210, -0.5528, -0.4940, -0.9375, -0.7772, -0.4940,\n",
      "         -0.4940, -0.4940, -0.4940, -0.1318, -0.5821, -0.5821, -1.3992, -1.3005,\n",
      "         -2.0188, -1.3005, -1.3005, -0.5821, -0.5821, -0.2770],\n",
      "        [-1.8622, -1.8449, -1.8683, -1.7780, -1.5995, -1.4016, -1.2268, -0.9908,\n",
      "         -0.7489, -0.5210, -0.5528, -0.4940, -0.9375, -0.7772, -0.4940, -0.4940,\n",
      "         -0.4940, -0.4940, -0.1318, -0.5821, -0.5821, -1.3992, -1.3005, -2.0188,\n",
      "         -1.3005, -1.3005, -0.5821, -0.5821, -0.2770, -0.4940],\n",
      "        [-1.8449, -1.8683, -1.7780, -1.5995, -1.4016, -1.2268, -0.9908, -0.7489,\n",
      "         -0.5210, -0.5528, -0.4940, -0.9375, -0.7772, -0.4940, -0.4940, -0.4940,\n",
      "         -0.4940, -0.1318, -0.5821, -0.5821, -1.3992, -1.3005, -2.0188, -1.3005,\n",
      "         -1.3005, -0.5821, -0.5821, -0.2770, -0.4940, -0.6237],\n",
      "        [-1.8683, -1.7780, -1.5995, -1.4016, -1.2268, -0.9908, -0.7489, -0.5210,\n",
      "         -0.5528, -0.4940, -0.9375, -0.7772, -0.4940, -0.4940, -0.4940, -0.4940,\n",
      "         -0.1318, -0.5821, -0.5821, -1.3992, -1.3005, -2.0188, -1.3005, -1.3005,\n",
      "         -0.5821, -0.5821, -0.2770, -0.4940, -0.6237, -2.4415],\n",
      "        [-1.7780, -1.5995, -1.4016, -1.2268, -0.9908, -0.7489, -0.5210, -0.5528,\n",
      "         -0.4940, -0.9375, -0.7772, -0.4940, -0.4940, -0.4940, -0.4940, -0.1318,\n",
      "         -0.5821, -0.5821, -1.3992, -1.3005, -2.0188, -1.3005, -1.3005, -0.5821,\n",
      "         -0.5821, -0.2770, -0.4940, -0.6237, -2.4415, -2.9781],\n",
      "        [-1.5995, -1.4016, -1.2268, -0.9908, -0.7489, -0.5210, -0.5528, -0.4940,\n",
      "         -0.9375, -0.7772, -0.4940, -0.4940, -0.4940, -0.4940, -0.1318, -0.5821,\n",
      "         -0.5821, -1.3992, -1.3005, -2.0188, -1.3005, -1.3005, -0.5821, -0.5821,\n",
      "         -0.2770, -0.4940, -0.6237, -2.4415, -2.9781, -5.5645],\n",
      "        [-1.4016, -1.2268, -0.9908, -0.7489, -0.5210, -0.5528, -0.4940, -0.9375,\n",
      "         -0.7772, -0.4940, -0.4940, -0.4940, -0.4940, -0.1318, -0.5821, -0.5821,\n",
      "         -1.3992, -1.3005, -2.0188, -1.3005, -1.3005, -0.5821, -0.5821, -0.2770,\n",
      "         -0.4940, -0.6237, -2.4415, -2.9781, -5.5645, -4.3856],\n",
      "        [-1.2268, -0.9908, -0.7489, -0.5210, -0.5528, -0.4940, -0.9375, -0.7772,\n",
      "         -0.4940, -0.4940, -0.4940, -0.4940, -0.1318, -0.5821, -0.5821, -1.3992,\n",
      "         -1.3005, -2.0188, -1.3005, -1.3005, -0.5821, -0.5821, -0.2770, -0.4940,\n",
      "         -0.6237, -2.4415, -2.9781, -5.5645, -4.3856, -3.7032],\n",
      "        [-0.9908, -0.7489, -0.5210, -0.5528, -0.4940, -0.9375, -0.7772, -0.4940,\n",
      "         -0.4940, -0.4940, -0.4940, -0.1318, -0.5821, -0.5821, -1.3992, -1.3005,\n",
      "         -2.0188, -1.3005, -1.3005, -0.5821, -0.5821, -0.2770, -0.4940, -0.6237,\n",
      "         -2.4415, -2.9781, -5.5645, -4.3856, -3.7032, -2.6850],\n",
      "        [-0.7489, -0.5210, -0.5528, -0.4940, -0.9375, -0.7772, -0.4940, -0.4940,\n",
      "         -0.4940, -0.4940, -0.1318, -0.5821, -0.5821, -1.3992, -1.3005, -2.0188,\n",
      "         -1.3005, -1.3005, -0.5821, -0.5821, -0.2770, -0.4940, -0.6237, -2.4415,\n",
      "         -2.9781, -5.5645, -4.3856, -3.7032, -2.6850, -2.9709],\n",
      "        [-0.5210, -0.5528, -0.4940, -0.9375, -0.7772, -0.4940, -0.4940, -0.4940,\n",
      "         -0.4940, -0.1318, -0.5821, -0.5821, -1.3992, -1.3005, -2.0188, -1.3005,\n",
      "         -1.3005, -0.5821, -0.5821, -0.2770, -0.4940, -0.6237, -2.4415, -2.9781,\n",
      "         -5.5645, -4.3856, -3.7032, -2.6850, -2.9709, -3.3358]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4,\n",
      "         7, 8, 8, 7, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7,\n",
      "         8, 8, 7, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8,\n",
      "         8, 8, 8, 8, 8, 0],\n",
      "        [6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8,\n",
      "         8, 8, 8, 8, 0, 4],\n",
      "        [6, 6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8,\n",
      "         8, 8, 8, 0, 4, 7],\n",
      "        [6, 6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8,\n",
      "         8, 8, 0, 4, 7, 7],\n",
      "        [6, 6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8, 8,\n",
      "         8, 0, 4, 7, 7, 7],\n",
      "        [6, 5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8,\n",
      "         0, 4, 7, 7, 7, 0],\n",
      "        [5, 6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 0,\n",
      "         4, 7, 7, 7, 0, 3],\n",
      "        [6, 6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 0, 4,\n",
      "         7, 7, 7, 0, 3, 1],\n",
      "        [6, 6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 0, 4, 7,\n",
      "         7, 7, 0, 3, 1, 5],\n",
      "        [6, 6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 0, 4, 7, 7,\n",
      "         7, 0, 3, 1, 5, 5],\n",
      "        [6, 7, 4, 7, 7, 4, 4, 4, 4, 7, 8, 8, 7, 8, 8, 8, 8, 8, 8, 0, 4, 7, 7, 7,\n",
      "         0, 3, 1, 5, 5, 5]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-0.4928, -0.4928, -0.5675, -0.4593, -0.4928, -0.4928, -0.4928, -0.4928,\n",
      "         -0.0234, -0.4928, -0.4928, -0.8793, -0.7283, -1.6368, -0.7283, -0.7283,\n",
      "         -0.4928, -0.4928,  0.6598, -0.4928, -0.4928, -1.5832, -1.9455, -2.8376,\n",
      "         -2.0970, -1.6368, -0.7332, -0.6207, -0.6964, -1.5692],\n",
      "        [-0.4928, -0.5675, -0.4593, -0.4928, -0.4928, -0.4928, -0.4928, -0.0234,\n",
      "         -0.4928, -0.4928, -0.8793, -0.7283, -1.6368, -0.7283, -0.7283, -0.4928,\n",
      "         -0.4928,  0.6598, -0.4928, -0.4928, -1.5832, -1.9455, -2.8376, -2.0970,\n",
      "         -1.6368, -0.7332, -0.6207, -0.6964, -1.5692, -1.1610],\n",
      "        [-0.5675, -0.4593, -0.4928, -0.4928, -0.4928, -0.4928, -0.0234, -0.4928,\n",
      "         -0.4928, -0.8793, -0.7283, -1.6368, -0.7283, -0.7283, -0.4928, -0.4928,\n",
      "          0.6598, -0.4928, -0.4928, -1.5832, -1.9455, -2.8376, -2.0970, -1.6368,\n",
      "         -0.7332, -0.6207, -0.6964, -1.5692, -1.1610, -1.1031],\n",
      "        [-0.4593, -0.4928, -0.4928, -0.4928, -0.4928, -0.0234, -0.4928, -0.4928,\n",
      "         -0.8793, -0.7283, -1.6368, -0.7283, -0.7283, -0.4928, -0.4928,  0.6598,\n",
      "         -0.4928, -0.4928, -1.5832, -1.9455, -2.8376, -2.0970, -1.6368, -0.7332,\n",
      "         -0.6207, -0.6964, -1.5692, -1.1610, -1.1031, -1.3932],\n",
      "        [-0.4928, -0.4928, -0.4928, -0.4928, -0.0234, -0.4928, -0.4928, -0.8793,\n",
      "         -0.7283, -1.6368, -0.7283, -0.7283, -0.4928, -0.4928,  0.6598, -0.4928,\n",
      "         -0.4928, -1.5832, -1.9455, -2.8376, -2.0970, -1.6368, -0.7332, -0.6207,\n",
      "         -0.6964, -1.5692, -1.1610, -1.1031, -1.3932, -1.6368],\n",
      "        [-0.4928, -0.4928, -0.4928, -0.0234, -0.4928, -0.4928, -0.8793, -0.7283,\n",
      "         -1.6368, -0.7283, -0.7283, -0.4928, -0.4928,  0.6598, -0.4928, -0.4928,\n",
      "         -1.5832, -1.9455, -2.8376, -2.0970, -1.6368, -0.7332, -0.6207, -0.6964,\n",
      "         -1.5692, -1.1610, -1.1031, -1.3932, -1.6368, -1.4846],\n",
      "        [-0.4928, -0.4928, -0.0234, -0.4928, -0.4928, -0.8793, -0.7283, -1.6368,\n",
      "         -0.7283, -0.7283, -0.4928, -0.4928,  0.6598, -0.4928, -0.4928, -1.5832,\n",
      "         -1.9455, -2.8376, -2.0970, -1.6368, -0.7332, -0.6207, -0.6964, -1.5692,\n",
      "         -1.1610, -1.1031, -1.3932, -1.6368, -1.4846, -1.6679],\n",
      "        [-0.4928, -0.0234, -0.4928, -0.4928, -0.8793, -0.7283, -1.6368, -0.7283,\n",
      "         -0.7283, -0.4928, -0.4928,  0.6598, -0.4928, -0.4928, -1.5832, -1.9455,\n",
      "         -2.8376, -2.0970, -1.6368, -0.7332, -0.6207, -0.6964, -1.5692, -1.1610,\n",
      "         -1.1031, -1.3932, -1.6368, -1.4846, -1.6679, -1.8253],\n",
      "        [-0.0234, -0.4928, -0.4928, -0.8793, -0.7283, -1.6368, -0.7283, -0.7283,\n",
      "         -0.4928, -0.4928,  0.6598, -0.4928, -0.4928, -1.5832, -1.9455, -2.8376,\n",
      "         -2.0970, -1.6368, -0.7332, -0.6207, -0.6964, -1.5692, -1.1610, -1.1031,\n",
      "         -1.3932, -1.6368, -1.4846, -1.6679, -1.8253, -1.9808],\n",
      "        [-0.4928, -0.4928, -0.8793, -0.7283, -1.6368, -0.7283, -0.7283, -0.4928,\n",
      "         -0.4928,  0.6598, -0.4928, -0.4928, -1.5832, -1.9455, -2.8376, -2.0970,\n",
      "         -1.6368, -0.7332, -0.6207, -0.6964, -1.5692, -1.1610, -1.1031, -1.3932,\n",
      "         -1.6368, -1.4846, -1.6679, -1.8253, -1.9808, -2.1231],\n",
      "        [-0.4928, -0.8793, -0.7283, -1.6368, -0.7283, -0.7283, -0.4928, -0.4928,\n",
      "          0.6598, -0.4928, -0.4928, -1.5832, -1.9455, -2.8376, -2.0970, -1.6368,\n",
      "         -0.7332, -0.6207, -0.6964, -1.5692, -1.1610, -1.1031, -1.3932, -1.6368,\n",
      "         -1.4846, -1.6679, -1.8253, -1.9808, -2.1231, -2.2398],\n",
      "        [-0.8793, -0.7283, -1.6368, -0.7283, -0.7283, -0.4928, -0.4928,  0.6598,\n",
      "         -0.4928, -0.4928, -1.5832, -1.9455, -2.8376, -2.0970, -1.6368, -0.7332,\n",
      "         -0.6207, -0.6964, -1.5692, -1.1610, -1.1031, -1.3932, -1.6368, -1.4846,\n",
      "         -1.6679, -1.8253, -1.9808, -2.1231, -2.2398, -2.3142],\n",
      "        [-0.7283, -1.6368, -0.7283, -0.7283, -0.4928, -0.4928,  0.6598, -0.4928,\n",
      "         -0.4928, -1.5832, -1.9455, -2.8376, -2.0970, -1.6368, -0.7332, -0.6207,\n",
      "         -0.6964, -1.5692, -1.1610, -1.1031, -1.3932, -1.6368, -1.4846, -1.6679,\n",
      "         -1.8253, -1.9808, -2.1231, -2.2398, -2.3142, -2.3815],\n",
      "        [-1.6368, -0.7283, -0.7283, -0.4928, -0.4928,  0.6598, -0.4928, -0.4928,\n",
      "         -1.5832, -1.9455, -2.8376, -2.0970, -1.6368, -0.7332, -0.6207, -0.6964,\n",
      "         -1.5692, -1.1610, -1.1031, -1.3932, -1.6368, -1.4846, -1.6679, -1.8253,\n",
      "         -1.9808, -2.1231, -2.2398, -2.3142, -2.3815, -2.5216],\n",
      "        [-0.7283, -0.7283, -0.4928, -0.4928,  0.6598, -0.4928, -0.4928, -1.5832,\n",
      "         -1.9455, -2.8376, -2.0970, -1.6368, -0.7332, -0.6207, -0.6964, -1.5692,\n",
      "         -1.1610, -1.1031, -1.3932, -1.6368, -1.4846, -1.6679, -1.8253, -1.9808,\n",
      "         -2.1231, -2.2398, -2.3142, -2.3815, -2.5216, -2.6640],\n",
      "        [-0.7283, -0.4928, -0.4928,  0.6598, -0.4928, -0.4928, -1.5832, -1.9455,\n",
      "         -2.8376, -2.0970, -1.6368, -0.7332, -0.6207, -0.6964, -1.5692, -1.1610,\n",
      "         -1.1031, -1.3932, -1.6368, -1.4846, -1.6679, -1.8253, -1.9808, -2.1231,\n",
      "         -2.2398, -2.3142, -2.3815, -2.5216, -2.6640, -2.8293]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[4, 4, 7, 7, 4, 4, 4, 4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0,\n",
      "         3, 8, 1, 1, 1, 7],\n",
      "        [4, 7, 7, 4, 4, 4, 4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3,\n",
      "         8, 1, 1, 1, 7, 1],\n",
      "        [7, 7, 4, 4, 4, 4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8,\n",
      "         1, 1, 1, 7, 1, 5],\n",
      "        [7, 4, 4, 4, 4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1,\n",
      "         1, 1, 7, 1, 5, 1],\n",
      "        [4, 4, 4, 4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1,\n",
      "         1, 7, 1, 5, 1, 8],\n",
      "        [4, 4, 4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1,\n",
      "         7, 1, 5, 1, 8, 6],\n",
      "        [4, 4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7,\n",
      "         1, 5, 1, 8, 6, 6],\n",
      "        [4, 7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1,\n",
      "         5, 1, 8, 6, 6, 6],\n",
      "        [7, 4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5,\n",
      "         1, 8, 6, 6, 6, 6],\n",
      "        [4, 4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5, 1,\n",
      "         8, 6, 6, 6, 6, 6],\n",
      "        [4, 7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5, 1, 8,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5, 1, 8, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5, 1, 8, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5, 1, 8, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5, 1, 8, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 1, 1, 1, 7, 1, 5, 1, 8, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-0.4936, -0.4936,  0.6175, -0.4936, -0.4936, -1.7936, -2.1831, -3.6326,\n",
      "         -2.2703, -2.0024, -1.1290, -0.4936, -0.6240, -1.7786, -1.1290, -0.4936,\n",
      "         -1.1290, -2.0024, -1.1290, -1.1290, -0.4936, -0.1649, -0.4936, -0.4936,\n",
      "         -0.4936, -0.8183, -0.2666, -0.8901, -0.4936, -0.5527],\n",
      "        [-0.4936,  0.6175, -0.4936, -0.4936, -1.7936, -2.1831, -3.6326, -2.2703,\n",
      "         -2.0024, -1.1290, -0.4936, -0.6240, -1.7786, -1.1290, -0.4936, -1.1290,\n",
      "         -2.0024, -1.1290, -1.1290, -0.4936, -0.1649, -0.4936, -0.4936, -0.4936,\n",
      "         -0.8183, -0.2666, -0.8901, -0.4936, -0.5527, -0.6498],\n",
      "        [ 0.6175, -0.4936, -0.4936, -1.7936, -2.1831, -3.6326, -2.2703, -2.0024,\n",
      "         -1.1290, -0.4936, -0.6240, -1.7786, -1.1290, -0.4936, -1.1290, -2.0024,\n",
      "         -1.1290, -1.1290, -0.4936, -0.1649, -0.4936, -0.4936, -0.4936, -0.8183,\n",
      "         -0.2666, -0.8901, -0.4936, -0.5527, -0.6498, -1.9327],\n",
      "        [-0.4936, -0.4936, -1.7936, -2.1831, -3.6326, -2.2703, -2.0024, -1.1290,\n",
      "         -0.4936, -0.6240, -1.7786, -1.1290, -0.4936, -1.1290, -2.0024, -1.1290,\n",
      "         -1.1290, -0.4936, -0.1649, -0.4936, -0.4936, -0.4936, -0.8183, -0.2666,\n",
      "         -0.8901, -0.4936, -0.5527, -0.6498, -1.9327, -2.1728],\n",
      "        [-0.4936, -1.7936, -2.1831, -3.6326, -2.2703, -2.0024, -1.1290, -0.4936,\n",
      "         -0.6240, -1.7786, -1.1290, -0.4936, -1.1290, -2.0024, -1.1290, -1.1290,\n",
      "         -0.4936, -0.1649, -0.4936, -0.4936, -0.4936, -0.8183, -0.2666, -0.8901,\n",
      "         -0.4936, -0.5527, -0.6498, -1.9327, -2.1728, -1.8470],\n",
      "        [-1.7936, -2.1831, -3.6326, -2.2703, -2.0024, -1.1290, -0.4936, -0.6240,\n",
      "         -1.7786, -1.1290, -0.4936, -1.1290, -2.0024, -1.1290, -1.1290, -0.4936,\n",
      "         -0.1649, -0.4936, -0.4936, -0.4936, -0.8183, -0.2666, -0.8901, -0.4936,\n",
      "         -0.5527, -0.6498, -1.9327, -2.1728, -1.8470, -1.7641],\n",
      "        [-2.1831, -3.6326, -2.2703, -2.0024, -1.1290, -0.4936, -0.6240, -1.7786,\n",
      "         -1.1290, -0.4936, -1.1290, -2.0024, -1.1290, -1.1290, -0.4936, -0.1649,\n",
      "         -0.4936, -0.4936, -0.4936, -0.8183, -0.2666, -0.8901, -0.4936, -0.5527,\n",
      "         -0.6498, -1.9327, -2.1728, -1.8470, -1.7641, -1.7176],\n",
      "        [-3.6326, -2.2703, -2.0024, -1.1290, -0.4936, -0.6240, -1.7786, -1.1290,\n",
      "         -0.4936, -1.1290, -2.0024, -1.1290, -1.1290, -0.4936, -0.1649, -0.4936,\n",
      "         -0.4936, -0.4936, -0.8183, -0.2666, -0.8901, -0.4936, -0.5527, -0.6498,\n",
      "         -1.9327, -2.1728, -1.8470, -1.7641, -1.7176, -1.6331],\n",
      "        [-2.2703, -2.0024, -1.1290, -0.4936, -0.6240, -1.7786, -1.1290, -0.4936,\n",
      "         -1.1290, -2.0024, -1.1290, -1.1290, -0.4936, -0.1649, -0.4936, -0.4936,\n",
      "         -0.4936, -0.8183, -0.2666, -0.8901, -0.4936, -0.5527, -0.6498, -1.9327,\n",
      "         -2.1728, -1.8470, -1.7641, -1.7176, -1.6331, -1.7409],\n",
      "        [-2.0024, -1.1290, -0.4936, -0.6240, -1.7786, -1.1290, -0.4936, -1.1290,\n",
      "         -2.0024, -1.1290, -1.1290, -0.4936, -0.1649, -0.4936, -0.4936, -0.4936,\n",
      "         -0.8183, -0.2666, -0.8901, -0.4936, -0.5527, -0.6498, -1.9327, -2.1728,\n",
      "         -1.8470, -1.7641, -1.7176, -1.6331, -1.7409, -1.8491],\n",
      "        [-1.1290, -0.4936, -0.6240, -1.7786, -1.1290, -0.4936, -1.1290, -2.0024,\n",
      "         -1.1290, -1.1290, -0.4936, -0.1649, -0.4936, -0.4936, -0.4936, -0.8183,\n",
      "         -0.2666, -0.8901, -0.4936, -0.5527, -0.6498, -1.9327, -2.1728, -1.8470,\n",
      "         -1.7641, -1.7176, -1.6331, -1.7409, -1.8491, -1.9036],\n",
      "        [-0.4936, -0.6240, -1.7786, -1.1290, -0.4936, -1.1290, -2.0024, -1.1290,\n",
      "         -1.1290, -0.4936, -0.1649, -0.4936, -0.4936, -0.4936, -0.8183, -0.2666,\n",
      "         -0.8901, -0.4936, -0.5527, -0.6498, -1.9327, -2.1728, -1.8470, -1.7641,\n",
      "         -1.7176, -1.6331, -1.7409, -1.8491, -1.9036, -1.9610],\n",
      "        [-0.6240, -1.7786, -1.1290, -0.4936, -1.1290, -2.0024, -1.1290, -1.1290,\n",
      "         -0.4936, -0.1649, -0.4936, -0.4936, -0.4936, -0.8183, -0.2666, -0.8901,\n",
      "         -0.4936, -0.5527, -0.6498, -1.9327, -2.1728, -1.8470, -1.7641, -1.7176,\n",
      "         -1.6331, -1.7409, -1.8491, -1.9036, -1.9610, -2.0205],\n",
      "        [-1.7786, -1.1290, -0.4936, -1.1290, -2.0024, -1.1290, -1.1290, -0.4936,\n",
      "         -0.1649, -0.4936, -0.4936, -0.4936, -0.8183, -0.2666, -0.8901, -0.4936,\n",
      "         -0.5527, -0.6498, -1.9327, -2.1728, -1.8470, -1.7641, -1.7176, -1.6331,\n",
      "         -1.7409, -1.8491, -1.9036, -1.9610, -2.0205, -2.0760],\n",
      "        [-1.1290, -0.4936, -1.1290, -2.0024, -1.1290, -1.1290, -0.4936, -0.1649,\n",
      "         -0.4936, -0.4936, -0.4936, -0.8183, -0.2666, -0.8901, -0.4936, -0.5527,\n",
      "         -0.6498, -1.9327, -2.1728, -1.8470, -1.7641, -1.7176, -1.6331, -1.7409,\n",
      "         -1.8491, -1.9036, -1.9610, -2.0205, -2.0760, -2.1397],\n",
      "        [-0.4936, -1.1290, -2.0024, -1.1290, -1.1290, -0.4936, -0.1649, -0.4936,\n",
      "         -0.4936, -0.4936, -0.8183, -0.2666, -0.8901, -0.4936, -0.5527, -0.6498,\n",
      "         -1.9327, -2.1728, -1.8470, -1.7641, -1.7176, -1.6331, -1.7409, -1.8491,\n",
      "         -1.9036, -1.9610, -2.0205, -2.0760, -2.1397, -2.2096]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[4, 4, 7, 4, 4, 7, 7, 0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4,\n",
      "         4, 7, 6, 7, 4, 1],\n",
      "        [4, 7, 4, 4, 7, 7, 0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4,\n",
      "         7, 6, 7, 4, 1, 5],\n",
      "        [7, 4, 4, 7, 7, 0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7,\n",
      "         6, 7, 4, 1, 5, 3],\n",
      "        [4, 4, 7, 7, 0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6,\n",
      "         7, 4, 1, 5, 3, 3],\n",
      "        [4, 7, 7, 0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7,\n",
      "         4, 1, 5, 3, 3, 1],\n",
      "        [7, 7, 0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4,\n",
      "         1, 5, 3, 3, 1, 1],\n",
      "        [7, 0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1,\n",
      "         5, 3, 3, 1, 1, 0],\n",
      "        [0, 3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5,\n",
      "         3, 3, 1, 1, 0, 6],\n",
      "        [3, 8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3,\n",
      "         3, 1, 1, 0, 6, 6],\n",
      "        [8, 8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3, 3,\n",
      "         1, 1, 0, 6, 6, 6],\n",
      "        [8, 4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3, 3, 1,\n",
      "         1, 0, 6, 6, 6, 6],\n",
      "        [4, 7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3, 3, 1, 1,\n",
      "         0, 6, 6, 6, 6, 6],\n",
      "        [7, 7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3, 3, 1, 1, 0,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3, 3, 1, 1, 0, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3, 3, 1, 1, 0, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [4, 8, 8, 8, 8, 4, 7, 4, 4, 4, 7, 6, 7, 4, 1, 5, 3, 3, 1, 1, 0, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.8958, -2.6251, -1.8958, -1.8958, -1.1665, -0.4459, -0.4942, -0.4942,\n",
      "         -0.4942, -1.3662, -0.4372, -1.4674, -0.4942, -0.7392, -1.0222, -2.7578,\n",
      "         -2.1244, -1.7574, -1.6430, -1.8187, -0.6138, -0.7454, -1.1665, -1.1665,\n",
      "         -0.8403, -0.8505, -0.9130, -0.9661, -0.9412, -0.9005],\n",
      "        [-2.6251, -1.8958, -1.8958, -1.1665, -0.4459, -0.4942, -0.4942, -0.4942,\n",
      "         -1.3662, -0.4372, -1.4674, -0.4942, -0.7392, -1.0222, -2.7578, -2.1244,\n",
      "         -1.7574, -1.6430, -1.8187, -0.6138, -0.7454, -1.1665, -1.1665, -0.8403,\n",
      "         -0.8505, -0.9130, -0.9661, -0.9412, -0.9005, -0.8424],\n",
      "        [-1.8958, -1.8958, -1.1665, -0.4459, -0.4942, -0.4942, -0.4942, -1.3662,\n",
      "         -0.4372, -1.4674, -0.4942, -0.7392, -1.0222, -2.7578, -2.1244, -1.7574,\n",
      "         -1.6430, -1.8187, -0.6138, -0.7454, -1.1665, -1.1665, -0.8403, -0.8505,\n",
      "         -0.9130, -0.9661, -0.9412, -0.9005, -0.8424, -0.8398],\n",
      "        [-1.8958, -1.1665, -0.4459, -0.4942, -0.4942, -0.4942, -1.3662, -0.4372,\n",
      "         -1.4674, -0.4942, -0.7392, -1.0222, -2.7578, -2.1244, -1.7574, -1.6430,\n",
      "         -1.8187, -0.6138, -0.7454, -1.1665, -1.1665, -0.8403, -0.8505, -0.9130,\n",
      "         -0.9661, -0.9412, -0.9005, -0.8424, -0.8398, -0.9102],\n",
      "        [-1.1665, -0.4459, -0.4942, -0.4942, -0.4942, -1.3662, -0.4372, -1.4674,\n",
      "         -0.4942, -0.7392, -1.0222, -2.7578, -2.1244, -1.7574, -1.6430, -1.8187,\n",
      "         -0.6138, -0.7454, -1.1665, -1.1665, -0.8403, -0.8505, -0.9130, -0.9661,\n",
      "         -0.9412, -0.9005, -0.8424, -0.8398, -0.9102, -1.0080],\n",
      "        [-0.4459, -0.4942, -0.4942, -0.4942, -1.3662, -0.4372, -1.4674, -0.4942,\n",
      "         -0.7392, -1.0222, -2.7578, -2.1244, -1.7574, -1.6430, -1.8187, -0.6138,\n",
      "         -0.7454, -1.1665, -1.1665, -0.8403, -0.8505, -0.9130, -0.9661, -0.9412,\n",
      "         -0.9005, -0.8424, -0.8398, -0.9102, -1.0080, -1.0741],\n",
      "        [-0.4942, -0.4942, -0.4942, -1.3662, -0.4372, -1.4674, -0.4942, -0.7392,\n",
      "         -1.0222, -2.7578, -2.1244, -1.7574, -1.6430, -1.8187, -0.6138, -0.7454,\n",
      "         -1.1665, -1.1665, -0.8403, -0.8505, -0.9130, -0.9661, -0.9412, -0.9005,\n",
      "         -0.8424, -0.8398, -0.9102, -1.0080, -1.0741, -1.1227],\n",
      "        [-0.4942, -0.4942, -1.3662, -0.4372, -1.4674, -0.4942, -0.7392, -1.0222,\n",
      "         -2.7578, -2.1244, -1.7574, -1.6430, -1.8187, -0.6138, -0.7454, -1.1665,\n",
      "         -1.1665, -0.8403, -0.8505, -0.9130, -0.9661, -0.9412, -0.9005, -0.8424,\n",
      "         -0.8398, -0.9102, -1.0080, -1.0741, -1.1227, -1.1875],\n",
      "        [-0.4942, -1.3662, -0.4372, -1.4674, -0.4942, -0.7392, -1.0222, -2.7578,\n",
      "         -2.1244, -1.7574, -1.6430, -1.8187, -0.6138, -0.7454, -1.1665, -1.1665,\n",
      "         -0.8403, -0.8505, -0.9130, -0.9661, -0.9412, -0.9005, -0.8424, -0.8398,\n",
      "         -0.9102, -1.0080, -1.0741, -1.1227, -1.1875, -1.2572],\n",
      "        [-1.3662, -0.4372, -1.4674, -0.4942, -0.7392, -1.0222, -2.7578, -2.1244,\n",
      "         -1.7574, -1.6430, -1.8187, -0.6138, -0.7454, -1.1665, -1.1665, -0.8403,\n",
      "         -0.8505, -0.9130, -0.9661, -0.9412, -0.9005, -0.8424, -0.8398, -0.9102,\n",
      "         -1.0080, -1.0741, -1.1227, -1.1875, -1.2572, -1.2987],\n",
      "        [-0.4372, -1.4674, -0.4942, -0.7392, -1.0222, -2.7578, -2.1244, -1.7574,\n",
      "         -1.6430, -1.8187, -0.6138, -0.7454, -1.1665, -1.1665, -0.8403, -0.8505,\n",
      "         -0.9130, -0.9661, -0.9412, -0.9005, -0.8424, -0.8398, -0.9102, -1.0080,\n",
      "         -1.0741, -1.1227, -1.1875, -1.2572, -1.2987, -1.3348],\n",
      "        [-1.4674, -0.4942, -0.7392, -1.0222, -2.7578, -2.1244, -1.7574, -1.6430,\n",
      "         -1.8187, -0.6138, -0.7454, -1.1665, -1.1665, -0.8403, -0.8505, -0.9130,\n",
      "         -0.9661, -0.9412, -0.9005, -0.8424, -0.8398, -0.9102, -1.0080, -1.0741,\n",
      "         -1.1227, -1.1875, -1.2572, -1.2987, -1.3348, -1.3690],\n",
      "        [-0.4942, -0.7392, -1.0222, -2.7578, -2.1244, -1.7574, -1.6430, -1.8187,\n",
      "         -0.6138, -0.7454, -1.1665, -1.1665, -0.8403, -0.8505, -0.9130, -0.9661,\n",
      "         -0.9412, -0.9005, -0.8424, -0.8398, -0.9102, -1.0080, -1.0741, -1.1227,\n",
      "         -1.1875, -1.2572, -1.2987, -1.3348, -1.3690, -1.3548],\n",
      "        [-0.7392, -1.0222, -2.7578, -2.1244, -1.7574, -1.6430, -1.8187, -0.6138,\n",
      "         -0.7454, -1.1665, -1.1665, -0.8403, -0.8505, -0.9130, -0.9661, -0.9412,\n",
      "         -0.9005, -0.8424, -0.8398, -0.9102, -1.0080, -1.0741, -1.1227, -1.1875,\n",
      "         -1.2572, -1.2987, -1.3348, -1.3690, -1.3548, -1.3158],\n",
      "        [-1.0222, -2.7578, -2.1244, -1.7574, -1.6430, -1.8187, -0.6138, -0.7454,\n",
      "         -1.1665, -1.1665, -0.8403, -0.8505, -0.9130, -0.9661, -0.9412, -0.9005,\n",
      "         -0.8424, -0.8398, -0.9102, -1.0080, -1.0741, -1.1227, -1.1875, -1.2572,\n",
      "         -1.2987, -1.3348, -1.3690, -1.3548, -1.3158, -1.2962],\n",
      "        [-2.7578, -2.1244, -1.7574, -1.6430, -1.8187, -0.6138, -0.7454, -1.1665,\n",
      "         -1.1665, -0.8403, -0.8505, -0.9130, -0.9661, -0.9412, -0.9005, -0.8424,\n",
      "         -0.8398, -0.9102, -1.0080, -1.0741, -1.1227, -1.1875, -1.2572, -1.2987,\n",
      "         -1.3348, -1.3690, -1.3548, -1.3158, -1.2962, -1.2902]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[8, 8, 8, 8, 8, 7, 4, 4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8,\n",
      "         5, 5, 7, 5, 5, 5],\n",
      "        [8, 8, 8, 8, 7, 4, 4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5,\n",
      "         5, 7, 5, 5, 5, 5],\n",
      "        [8, 8, 8, 7, 4, 4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5,\n",
      "         7, 5, 5, 5, 5, 6],\n",
      "        [8, 8, 7, 4, 4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7,\n",
      "         5, 5, 5, 5, 6, 6],\n",
      "        [8, 7, 4, 4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5,\n",
      "         5, 5, 5, 6, 6, 6],\n",
      "        [7, 4, 4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5,\n",
      "         5, 5, 6, 6, 6, 6],\n",
      "        [4, 4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5,\n",
      "         5, 6, 6, 6, 6, 6],\n",
      "        [4, 4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [4, 7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [4, 1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [1, 7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 3, 0, 1, 0, 5, 7, 8, 8, 5, 5, 7, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.6866, -3.1096, -3.0264, -3.1723, -1.8345, -1.8897, -1.7365, -1.6578,\n",
      "         -1.3388, -1.2964, -1.5144, -1.6214, -1.3990, -1.0806, -1.0358, -1.0112,\n",
      "         -1.1760, -0.9645, -0.8263, -0.6901, -0.5614, -0.5030, -0.7024, -0.6854,\n",
      "         -0.7763, -0.7385, -0.6352, -0.5829, -0.5672, -1.3739],\n",
      "        [-3.1096, -3.0264, -3.1723, -1.8345, -1.8897, -1.7365, -1.6578, -1.3388,\n",
      "         -1.2964, -1.5144, -1.6214, -1.3990, -1.0806, -1.0358, -1.0112, -1.1760,\n",
      "         -0.9645, -0.8263, -0.6901, -0.5614, -0.5030, -0.7024, -0.6854, -0.7763,\n",
      "         -0.7385, -0.6352, -0.5829, -0.5672, -1.3739, -0.5816],\n",
      "        [-3.0264, -3.1723, -1.8345, -1.8897, -1.7365, -1.6578, -1.3388, -1.2964,\n",
      "         -1.5144, -1.6214, -1.3990, -1.0806, -1.0358, -1.0112, -1.1760, -0.9645,\n",
      "         -0.8263, -0.6901, -0.5614, -0.5030, -0.7024, -0.6854, -0.7763, -0.7385,\n",
      "         -0.6352, -0.5829, -0.5672, -1.3739, -0.5816, -0.6131],\n",
      "        [-3.1723, -1.8345, -1.8897, -1.7365, -1.6578, -1.3388, -1.2964, -1.5144,\n",
      "         -1.6214, -1.3990, -1.0806, -1.0358, -1.0112, -1.1760, -0.9645, -0.8263,\n",
      "         -0.6901, -0.5614, -0.5030, -0.7024, -0.6854, -0.7763, -0.7385, -0.6352,\n",
      "         -0.5829, -0.5672, -1.3739, -0.5816, -0.6131, -1.5974],\n",
      "        [-1.8345, -1.8897, -1.7365, -1.6578, -1.3388, -1.2964, -1.5144, -1.6214,\n",
      "         -1.3990, -1.0806, -1.0358, -1.0112, -1.1760, -0.9645, -0.8263, -0.6901,\n",
      "         -0.5614, -0.5030, -0.7024, -0.6854, -0.7763, -0.7385, -0.6352, -0.5829,\n",
      "         -0.5672, -1.3739, -0.5816, -0.6131, -1.5974, -1.9345],\n",
      "        [-1.8897, -1.7365, -1.6578, -1.3388, -1.2964, -1.5144, -1.6214, -1.3990,\n",
      "         -1.0806, -1.0358, -1.0112, -1.1760, -0.9645, -0.8263, -0.6901, -0.5614,\n",
      "         -0.5030, -0.7024, -0.6854, -0.7763, -0.7385, -0.6352, -0.5829, -0.5672,\n",
      "         -1.3739, -0.5816, -0.6131, -1.5974, -1.9345, -2.2935],\n",
      "        [-1.7365, -1.6578, -1.3388, -1.2964, -1.5144, -1.6214, -1.3990, -1.0806,\n",
      "         -1.0358, -1.0112, -1.1760, -0.9645, -0.8263, -0.6901, -0.5614, -0.5030,\n",
      "         -0.7024, -0.6854, -0.7763, -0.7385, -0.6352, -0.5829, -0.5672, -1.3739,\n",
      "         -0.5816, -0.6131, -1.5974, -1.9345, -2.2935, -1.6743],\n",
      "        [-1.6578, -1.3388, -1.2964, -1.5144, -1.6214, -1.3990, -1.0806, -1.0358,\n",
      "         -1.0112, -1.1760, -0.9645, -0.8263, -0.6901, -0.5614, -0.5030, -0.7024,\n",
      "         -0.6854, -0.7763, -0.7385, -0.6352, -0.5829, -0.5672, -1.3739, -0.5816,\n",
      "         -0.6131, -1.5974, -1.9345, -2.2935, -1.6743, -1.6743],\n",
      "        [-1.3388, -1.2964, -1.5144, -1.6214, -1.3990, -1.0806, -1.0358, -1.0112,\n",
      "         -1.1760, -0.9645, -0.8263, -0.6901, -0.5614, -0.5030, -0.7024, -0.6854,\n",
      "         -0.7763, -0.7385, -0.6352, -0.5829, -0.5672, -1.3739, -0.5816, -0.6131,\n",
      "         -1.5974, -1.9345, -2.2935, -1.6743, -1.6743, -1.0551],\n",
      "        [-1.2964, -1.5144, -1.6214, -1.3990, -1.0806, -1.0358, -1.0112, -1.1760,\n",
      "         -0.9645, -0.8263, -0.6901, -0.5614, -0.5030, -0.7024, -0.6854, -0.7763,\n",
      "         -0.7385, -0.6352, -0.5829, -0.5672, -1.3739, -0.5816, -0.6131, -1.5974,\n",
      "         -1.9345, -2.2935, -1.6743, -1.6743, -1.0551, -1.0551],\n",
      "        [-1.5144, -1.6214, -1.3990, -1.0806, -1.0358, -1.0112, -1.1760, -0.9645,\n",
      "         -0.8263, -0.6901, -0.5614, -0.5030, -0.7024, -0.6854, -0.7763, -0.7385,\n",
      "         -0.6352, -0.5829, -0.5672, -1.3739, -0.5816, -0.6131, -1.5974, -1.9345,\n",
      "         -2.2935, -1.6743, -1.6743, -1.0551, -1.0551, -1.0551],\n",
      "        [-1.6214, -1.3990, -1.0806, -1.0358, -1.0112, -1.1760, -0.9645, -0.8263,\n",
      "         -0.6901, -0.5614, -0.5030, -0.7024, -0.6854, -0.7763, -0.7385, -0.6352,\n",
      "         -0.5829, -0.5672, -1.3739, -0.5816, -0.6131, -1.5974, -1.9345, -2.2935,\n",
      "         -1.6743, -1.6743, -1.0551, -1.0551, -1.0551, -1.6743],\n",
      "        [-1.3990, -1.0806, -1.0358, -1.0112, -1.1760, -0.9645, -0.8263, -0.6901,\n",
      "         -0.5614, -0.5030, -0.7024, -0.6854, -0.7763, -0.7385, -0.6352, -0.5829,\n",
      "         -0.5672, -1.3739, -0.5816, -0.6131, -1.5974, -1.9345, -2.2935, -1.6743,\n",
      "         -1.6743, -1.0551, -1.0551, -1.0551, -1.6743, -1.0551],\n",
      "        [-1.0806, -1.0358, -1.0112, -1.1760, -0.9645, -0.8263, -0.6901, -0.5614,\n",
      "         -0.5030, -0.7024, -0.6854, -0.7763, -0.7385, -0.6352, -0.5829, -0.5672,\n",
      "         -1.3739, -0.5816, -0.6131, -1.5974, -1.9345, -2.2935, -1.6743, -1.6743,\n",
      "         -1.0551, -1.0551, -1.0551, -1.6743, -1.0551, -0.8245],\n",
      "        [-1.0358, -1.0112, -1.1760, -0.9645, -0.8263, -0.6901, -0.5614, -0.5030,\n",
      "         -0.7024, -0.6854, -0.7763, -0.7385, -0.6352, -0.5829, -0.5672, -1.3739,\n",
      "         -0.5816, -0.6131, -1.5974, -1.9345, -2.2935, -1.6743, -1.6743, -1.0551,\n",
      "         -1.0551, -1.0551, -1.6743, -1.0551, -0.8245, -0.7181],\n",
      "        [-1.0112, -1.1760, -0.9645, -0.8263, -0.6901, -0.5614, -0.5030, -0.7024,\n",
      "         -0.6854, -0.7763, -0.7385, -0.6352, -0.5829, -0.5672, -1.3739, -0.5816,\n",
      "         -0.6131, -1.5974, -1.9345, -2.2935, -1.6743, -1.6743, -1.0551, -1.0551,\n",
      "         -1.0551, -1.6743, -1.0551, -0.8245, -0.7181, -0.5030]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[3, 0, 1, 0, 0, 3, 1, 2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6,\n",
      "         6, 6, 6, 6, 6, 7],\n",
      "        [0, 1, 0, 0, 3, 1, 2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6,\n",
      "         6, 6, 6, 6, 7, 6],\n",
      "        [1, 0, 0, 3, 1, 2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6,\n",
      "         6, 6, 6, 7, 6, 6],\n",
      "        [0, 0, 3, 1, 2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6,\n",
      "         6, 6, 7, 6, 6, 7],\n",
      "        [0, 3, 1, 2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6,\n",
      "         6, 7, 6, 6, 7, 7],\n",
      "        [3, 1, 2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6,\n",
      "         7, 6, 6, 7, 7, 8],\n",
      "        [1, 2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7,\n",
      "         6, 6, 7, 7, 8, 8],\n",
      "        [2, 1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6,\n",
      "         6, 7, 7, 8, 8, 8],\n",
      "        [1, 1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6,\n",
      "         7, 7, 8, 8, 8, 8],\n",
      "        [1, 3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6, 7,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [3, 3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [3, 0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [0, 5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 6],\n",
      "        [5, 5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 6, 6],\n",
      "        [5, 3, 5, 5, 5, 5, 4, 7, 6, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 6, 6, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.6074, -3.0497, -2.5598, -2.4158, -2.2797, -2.0945, -1.9323, -1.7916,\n",
      "         -1.5956, -1.3908, -1.1944, -1.0158, -0.8269, -1.0300, -0.5584, -0.5416,\n",
      "         -1.2348, -2.2318, -2.4196, -1.3995, -1.3995, -0.7712, -0.7502, -0.6988,\n",
      "         -1.3995, -0.6518, -0.6110, -0.5329, -0.5416, -0.6510],\n",
      "        [-3.0497, -2.5598, -2.4158, -2.2797, -2.0945, -1.9323, -1.7916, -1.5956,\n",
      "         -1.3908, -1.1944, -1.0158, -0.8269, -1.0300, -0.5584, -0.5416, -1.2348,\n",
      "         -2.2318, -2.4196, -1.3995, -1.3995, -0.7712, -0.7502, -0.6988, -1.3995,\n",
      "         -0.6518, -0.6110, -0.5329, -0.5416, -0.6510, -1.7154],\n",
      "        [-2.5598, -2.4158, -2.2797, -2.0945, -1.9323, -1.7916, -1.5956, -1.3908,\n",
      "         -1.1944, -1.0158, -0.8269, -1.0300, -0.5584, -0.5416, -1.2348, -2.2318,\n",
      "         -2.4196, -1.3995, -1.3995, -0.7712, -0.7502, -0.6988, -1.3995, -0.6518,\n",
      "         -0.6110, -0.5329, -0.5416, -0.6510, -1.7154, -0.5416],\n",
      "        [-2.4158, -2.2797, -2.0945, -1.9323, -1.7916, -1.5956, -1.3908, -1.1944,\n",
      "         -1.0158, -0.8269, -1.0300, -0.5584, -0.5416, -1.2348, -2.2318, -2.4196,\n",
      "         -1.3995, -1.3995, -0.7712, -0.7502, -0.6988, -1.3995, -0.6518, -0.6110,\n",
      "         -0.5329, -0.5416, -0.6510, -1.7154, -0.5416, -0.8001],\n",
      "        [-2.2797, -2.0945, -1.9323, -1.7916, -1.5956, -1.3908, -1.1944, -1.0158,\n",
      "         -0.8269, -1.0300, -0.5584, -0.5416, -1.2348, -2.2318, -2.4196, -1.3995,\n",
      "         -1.3995, -0.7712, -0.7502, -0.6988, -1.3995, -0.6518, -0.6110, -0.5329,\n",
      "         -0.5416, -0.6510, -1.7154, -0.5416, -0.8001, -0.5416],\n",
      "        [-2.0945, -1.9323, -1.7916, -1.5956, -1.3908, -1.1944, -1.0158, -0.8269,\n",
      "         -1.0300, -0.5584, -0.5416, -1.2348, -2.2318, -2.4196, -1.3995, -1.3995,\n",
      "         -0.7712, -0.7502, -0.6988, -1.3995, -0.6518, -0.6110, -0.5329, -0.5416,\n",
      "         -0.6510, -1.7154, -0.5416, -0.8001, -0.5416, -1.5066],\n",
      "        [-1.9323, -1.7916, -1.5956, -1.3908, -1.1944, -1.0158, -0.8269, -1.0300,\n",
      "         -0.5584, -0.5416, -1.2348, -2.2318, -2.4196, -1.3995, -1.3995, -0.7712,\n",
      "         -0.7502, -0.6988, -1.3995, -0.6518, -0.6110, -0.5329, -0.5416, -0.6510,\n",
      "         -1.7154, -0.5416, -0.8001, -0.5416, -1.5066, -0.6922],\n",
      "        [-1.7916, -1.5956, -1.3908, -1.1944, -1.0158, -0.8269, -1.0300, -0.5584,\n",
      "         -0.5416, -1.2348, -2.2318, -2.4196, -1.3995, -1.3995, -0.7712, -0.7502,\n",
      "         -0.6988, -1.3995, -0.6518, -0.6110, -0.5329, -0.5416, -0.6510, -1.7154,\n",
      "         -0.5416, -0.8001, -0.5416, -1.5066, -0.6922, -2.2418],\n",
      "        [-1.5956, -1.3908, -1.1944, -1.0158, -0.8269, -1.0300, -0.5584, -0.5416,\n",
      "         -1.2348, -2.2318, -2.4196, -1.3995, -1.3995, -0.7712, -0.7502, -0.6988,\n",
      "         -1.3995, -0.6518, -0.6110, -0.5329, -0.5416, -0.6510, -1.7154, -0.5416,\n",
      "         -0.8001, -0.5416, -1.5066, -0.6922, -2.2418, -2.6415],\n",
      "        [-1.3908, -1.1944, -1.0158, -0.8269, -1.0300, -0.5584, -0.5416, -1.2348,\n",
      "         -2.2318, -2.4196, -1.3995, -1.3995, -0.7712, -0.7502, -0.6988, -1.3995,\n",
      "         -0.6518, -0.6110, -0.5329, -0.5416, -0.6510, -1.7154, -0.5416, -0.8001,\n",
      "         -0.5416, -1.5066, -0.6922, -2.2418, -2.6415, -1.2425],\n",
      "        [-1.1944, -1.0158, -0.8269, -1.0300, -0.5584, -0.5416, -1.2348, -2.2318,\n",
      "         -2.4196, -1.3995, -1.3995, -0.7712, -0.7502, -0.6988, -1.3995, -0.6518,\n",
      "         -0.6110, -0.5329, -0.5416, -0.6510, -1.7154, -0.5416, -0.8001, -0.5416,\n",
      "         -1.5066, -0.6922, -2.2418, -2.6415, -1.2425, -0.7545],\n",
      "        [-1.0158, -0.8269, -1.0300, -0.5584, -0.5416, -1.2348, -2.2318, -2.4196,\n",
      "         -1.3995, -1.3995, -0.7712, -0.7502, -0.6988, -1.3995, -0.6518, -0.6110,\n",
      "         -0.5329, -0.5416, -0.6510, -1.7154, -0.5416, -0.8001, -0.5416, -1.5066,\n",
      "         -0.6922, -2.2418, -2.6415, -1.2425, -0.7545, -1.3692],\n",
      "        [-0.8269, -1.0300, -0.5584, -0.5416, -1.2348, -2.2318, -2.4196, -1.3995,\n",
      "         -1.3995, -0.7712, -0.7502, -0.6988, -1.3995, -0.6518, -0.6110, -0.5329,\n",
      "         -0.5416, -0.6510, -1.7154, -0.5416, -0.8001, -0.5416, -1.5066, -0.6922,\n",
      "         -2.2418, -2.6415, -1.2425, -0.7545, -1.3692, -2.3070],\n",
      "        [-1.0300, -0.5584, -0.5416, -1.2348, -2.2318, -2.4196, -1.3995, -1.3995,\n",
      "         -0.7712, -0.7502, -0.6988, -1.3995, -0.6518, -0.6110, -0.5329, -0.5416,\n",
      "         -0.6510, -1.7154, -0.5416, -0.8001, -0.5416, -1.5066, -0.6922, -2.2418,\n",
      "         -2.6415, -1.2425, -0.7545, -1.3692, -2.3070, -2.2357],\n",
      "        [-0.5584, -0.5416, -1.2348, -2.2318, -2.4196, -1.3995, -1.3995, -0.7712,\n",
      "         -0.7502, -0.6988, -1.3995, -0.6518, -0.6110, -0.5329, -0.5416, -0.6510,\n",
      "         -1.7154, -0.5416, -0.8001, -0.5416, -1.5066, -0.6922, -2.2418, -2.6415,\n",
      "         -1.2425, -0.7545, -1.3692, -2.3070, -2.2357, -1.5562],\n",
      "        [-0.5416, -1.2348, -2.2318, -2.4196, -1.3995, -1.3995, -0.7712, -0.7502,\n",
      "         -0.6988, -1.3995, -0.6518, -0.6110, -0.5329, -0.5416, -0.6510, -1.7154,\n",
      "         -0.5416, -0.8001, -0.5416, -1.5066, -0.6922, -2.2418, -2.6415, -1.2425,\n",
      "         -0.7545, -1.3692, -2.3070, -2.2357, -1.5562, -0.8860]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[3, 0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6,\n",
      "         8, 6, 6, 6, 4, 7],\n",
      "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8,\n",
      "         6, 6, 6, 4, 7, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6,\n",
      "         6, 6, 4, 7, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6,\n",
      "         6, 4, 7, 7, 4, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6,\n",
      "         4, 7, 7, 4, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4,\n",
      "         7, 7, 4, 7, 4, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7,\n",
      "         7, 4, 7, 4, 7, 0],\n",
      "        [5, 5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7,\n",
      "         4, 7, 4, 7, 0, 7],\n",
      "        [5, 5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4,\n",
      "         7, 4, 7, 0, 7, 2],\n",
      "        [5, 5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4, 7,\n",
      "         4, 7, 0, 7, 2, 0],\n",
      "        [5, 5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4, 7, 4,\n",
      "         7, 0, 7, 2, 0, 2],\n",
      "        [5, 5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4, 7, 4, 7,\n",
      "         0, 7, 2, 0, 2, 7],\n",
      "        [5, 7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4, 7, 4, 7, 0,\n",
      "         7, 2, 0, 2, 7, 3],\n",
      "        [7, 5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4, 7, 4, 7, 0, 7,\n",
      "         2, 0, 2, 7, 3, 1],\n",
      "        [5, 4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4, 7, 4, 7, 0, 7, 2,\n",
      "         0, 2, 7, 3, 1, 1],\n",
      "        [4, 7, 3, 0, 8, 8, 6, 6, 6, 8, 6, 6, 6, 4, 7, 7, 4, 7, 4, 7, 0, 7, 2, 0,\n",
      "         2, 7, 3, 1, 1, 1]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.7739, -2.7893, -2.7104, -2.6316, -2.4075, -2.1927, -1.9325, -1.6842,\n",
      "         -1.6617, -1.5556, -1.5318, -1.4862, -1.3892, -1.2002, -1.2796, -0.7266,\n",
      "         -0.5399, -0.5307, -1.1064, -0.8077, -1.7159, -0.8077, -0.5307, -0.5307,\n",
      "         -0.9925, -1.1752, -0.8077, -0.8077, -0.5307, -0.5307],\n",
      "        [-2.7893, -2.7104, -2.6316, -2.4075, -2.1927, -1.9325, -1.6842, -1.6617,\n",
      "         -1.5556, -1.5318, -1.4862, -1.3892, -1.2002, -1.2796, -0.7266, -0.5399,\n",
      "         -0.5307, -1.1064, -0.8077, -1.7159, -0.8077, -0.5307, -0.5307, -0.9925,\n",
      "         -1.1752, -0.8077, -0.8077, -0.5307, -0.5307,  0.0199],\n",
      "        [-2.7104, -2.6316, -2.4075, -2.1927, -1.9325, -1.6842, -1.6617, -1.5556,\n",
      "         -1.5318, -1.4862, -1.3892, -1.2002, -1.2796, -0.7266, -0.5399, -0.5307,\n",
      "         -1.1064, -0.8077, -1.7159, -0.8077, -0.5307, -0.5307, -0.9925, -1.1752,\n",
      "         -0.8077, -0.8077, -0.5307, -0.5307,  0.0199, -0.5307],\n",
      "        [-2.6316, -2.4075, -2.1927, -1.9325, -1.6842, -1.6617, -1.5556, -1.5318,\n",
      "         -1.4862, -1.3892, -1.2002, -1.2796, -0.7266, -0.5399, -0.5307, -1.1064,\n",
      "         -0.8077, -1.7159, -0.8077, -0.5307, -0.5307, -0.9925, -1.1752, -0.8077,\n",
      "         -0.8077, -0.5307, -0.5307,  0.0199, -0.5307, -0.5481],\n",
      "        [-2.4075, -2.1927, -1.9325, -1.6842, -1.6617, -1.5556, -1.5318, -1.4862,\n",
      "         -1.3892, -1.2002, -1.2796, -0.7266, -0.5399, -0.5307, -1.1064, -0.8077,\n",
      "         -1.7159, -0.8077, -0.5307, -0.5307, -0.9925, -1.1752, -0.8077, -0.8077,\n",
      "         -0.5307, -0.5307,  0.0199, -0.5307, -0.5481, -0.8224],\n",
      "        [-2.1927, -1.9325, -1.6842, -1.6617, -1.5556, -1.5318, -1.4862, -1.3892,\n",
      "         -1.2002, -1.2796, -0.7266, -0.5399, -0.5307, -1.1064, -0.8077, -1.7159,\n",
      "         -0.8077, -0.5307, -0.5307, -0.9925, -1.1752, -0.8077, -0.8077, -0.5307,\n",
      "         -0.5307,  0.0199, -0.5307, -0.5481, -0.8224, -1.5921],\n",
      "        [-1.9325, -1.6842, -1.6617, -1.5556, -1.5318, -1.4862, -1.3892, -1.2002,\n",
      "         -1.2796, -0.7266, -0.5399, -0.5307, -1.1064, -0.8077, -1.7159, -0.8077,\n",
      "         -0.5307, -0.5307, -0.9925, -1.1752, -0.8077, -0.8077, -0.5307, -0.5307,\n",
      "          0.0199, -0.5307, -0.5481, -0.8224, -1.5921, -0.9468],\n",
      "        [-1.6842, -1.6617, -1.5556, -1.5318, -1.4862, -1.3892, -1.2002, -1.2796,\n",
      "         -0.7266, -0.5399, -0.5307, -1.1064, -0.8077, -1.7159, -0.8077, -0.5307,\n",
      "         -0.5307, -0.9925, -1.1752, -0.8077, -0.8077, -0.5307, -0.5307,  0.0199,\n",
      "         -0.5307, -0.5481, -0.8224, -1.5921, -0.9468, -1.6579],\n",
      "        [-1.6617, -1.5556, -1.5318, -1.4862, -1.3892, -1.2002, -1.2796, -0.7266,\n",
      "         -0.5399, -0.5307, -1.1064, -0.8077, -1.7159, -0.8077, -0.5307, -0.5307,\n",
      "         -0.9925, -1.1752, -0.8077, -0.8077, -0.5307, -0.5307,  0.0199, -0.5307,\n",
      "         -0.5481, -0.8224, -1.5921, -0.9468, -1.6579, -2.4330],\n",
      "        [-1.5556, -1.5318, -1.4862, -1.3892, -1.2002, -1.2796, -0.7266, -0.5399,\n",
      "         -0.5307, -1.1064, -0.8077, -1.7159, -0.8077, -0.5307, -0.5307, -0.9925,\n",
      "         -1.1752, -0.8077, -0.8077, -0.5307, -0.5307,  0.0199, -0.5307, -0.5481,\n",
      "         -0.8224, -1.5921, -0.9468, -1.6579, -2.4330, -2.7842],\n",
      "        [-1.5318, -1.4862, -1.3892, -1.2002, -1.2796, -0.7266, -0.5399, -0.5307,\n",
      "         -1.1064, -0.8077, -1.7159, -0.8077, -0.5307, -0.5307, -0.9925, -1.1752,\n",
      "         -0.8077, -0.8077, -0.5307, -0.5307,  0.0199, -0.5307, -0.5481, -0.8224,\n",
      "         -1.5921, -0.9468, -1.6579, -2.4330, -2.7842, -3.0082],\n",
      "        [-1.4862, -1.3892, -1.2002, -1.2796, -0.7266, -0.5399, -0.5307, -1.1064,\n",
      "         -0.8077, -1.7159, -0.8077, -0.5307, -0.5307, -0.9925, -1.1752, -0.8077,\n",
      "         -0.8077, -0.5307, -0.5307,  0.0199, -0.5307, -0.5481, -0.8224, -1.5921,\n",
      "         -0.9468, -1.6579, -2.4330, -2.7842, -3.0082, -2.7534],\n",
      "        [-1.3892, -1.2002, -1.2796, -0.7266, -0.5399, -0.5307, -1.1064, -0.8077,\n",
      "         -1.7159, -0.8077, -0.5307, -0.5307, -0.9925, -1.1752, -0.8077, -0.8077,\n",
      "         -0.5307, -0.5307,  0.0199, -0.5307, -0.5481, -0.8224, -1.5921, -0.9468,\n",
      "         -1.6579, -2.4330, -2.7842, -3.0082, -2.7534, -3.6857],\n",
      "        [-1.2002, -1.2796, -0.7266, -0.5399, -0.5307, -1.1064, -0.8077, -1.7159,\n",
      "         -0.8077, -0.5307, -0.5307, -0.9925, -1.1752, -0.8077, -0.8077, -0.5307,\n",
      "         -0.5307,  0.0199, -0.5307, -0.5481, -0.8224, -1.5921, -0.9468, -1.6579,\n",
      "         -2.4330, -2.7842, -3.0082, -2.7534, -3.6857, -3.8817],\n",
      "        [-1.2796, -0.7266, -0.5399, -0.5307, -1.1064, -0.8077, -1.7159, -0.8077,\n",
      "         -0.5307, -0.5307, -0.9925, -1.1752, -0.8077, -0.8077, -0.5307, -0.5307,\n",
      "          0.0199, -0.5307, -0.5481, -0.8224, -1.5921, -0.9468, -1.6579, -2.4330,\n",
      "         -2.7842, -3.0082, -2.7534, -3.6857, -3.8817, -4.5528],\n",
      "        [-0.7266, -0.5399, -0.5307, -1.1064, -0.8077, -1.7159, -0.8077, -0.5307,\n",
      "         -0.5307, -0.9925, -1.1752, -0.8077, -0.8077, -0.5307, -0.5307,  0.0199,\n",
      "         -0.5307, -0.5481, -0.8224, -1.5921, -0.9468, -1.6579, -2.4330, -2.7842,\n",
      "         -3.0082, -2.7534, -3.6857, -3.8817, -4.5528, -4.4592]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4,\n",
      "         7, 7, 8, 8, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7,\n",
      "         7, 8, 8, 4, 4, 1],\n",
      "        [5, 5, 5, 5, 5, 5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7,\n",
      "         8, 8, 4, 4, 1, 4],\n",
      "        [5, 5, 5, 5, 5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8,\n",
      "         8, 4, 4, 1, 4, 7],\n",
      "        [5, 5, 5, 5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8,\n",
      "         4, 4, 1, 4, 7, 7],\n",
      "        [5, 5, 5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4,\n",
      "         4, 1, 4, 7, 7, 7],\n",
      "        [5, 5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4,\n",
      "         1, 4, 7, 7, 7, 1],\n",
      "        [5, 8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1,\n",
      "         4, 7, 7, 7, 1, 0],\n",
      "        [8, 6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4,\n",
      "         7, 7, 7, 1, 0, 3],\n",
      "        [6, 6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4, 7,\n",
      "         7, 7, 1, 0, 3, 3],\n",
      "        [6, 6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4, 7, 7,\n",
      "         7, 1, 0, 3, 3, 2],\n",
      "        [6, 6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4, 7, 7, 7,\n",
      "         1, 0, 3, 3, 2, 0],\n",
      "        [6, 6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4, 7, 7, 7, 1,\n",
      "         0, 3, 3, 2, 0, 3],\n",
      "        [6, 7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4, 7, 7, 7, 1, 0,\n",
      "         3, 3, 2, 0, 3, 0],\n",
      "        [7, 6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4, 7, 7, 7, 1, 0, 3,\n",
      "         3, 2, 0, 3, 0, 0],\n",
      "        [6, 6, 4, 7, 8, 7, 8, 4, 4, 7, 7, 8, 8, 4, 4, 1, 4, 7, 7, 7, 1, 0, 3, 3,\n",
      "         2, 0, 3, 0, 0, 5]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.4915, -2.2760, -2.0749, -1.8913, -1.5864, -1.4496, -1.2866, -1.0545,\n",
      "         -0.8613, -0.8547, -0.5835, -0.5090, -0.5090, -0.5090, -0.0718, -0.5090,\n",
      "         -0.5090, -0.5595, -1.2036, -0.5090, -0.5206, -1.7934, -0.5090, -0.5376,\n",
      "         -0.5090, -1.9833, -1.0249, -1.5161, -1.5600, -1.5758],\n",
      "        [-2.2760, -2.0749, -1.8913, -1.5864, -1.4496, -1.2866, -1.0545, -0.8613,\n",
      "         -0.8547, -0.5835, -0.5090, -0.5090, -0.5090, -0.0718, -0.5090, -0.5090,\n",
      "         -0.5595, -1.2036, -0.5090, -0.5206, -1.7934, -0.5090, -0.5376, -0.5090,\n",
      "         -1.9833, -1.0249, -1.5161, -1.5600, -1.5758, -2.0951],\n",
      "        [-2.0749, -1.8913, -1.5864, -1.4496, -1.2866, -1.0545, -0.8613, -0.8547,\n",
      "         -0.5835, -0.5090, -0.5090, -0.5090, -0.0718, -0.5090, -0.5090, -0.5595,\n",
      "         -1.2036, -0.5090, -0.5206, -1.7934, -0.5090, -0.5376, -0.5090, -1.9833,\n",
      "         -1.0249, -1.5161, -1.5600, -1.5758, -2.0951, -1.5600],\n",
      "        [-1.8913, -1.5864, -1.4496, -1.2866, -1.0545, -0.8613, -0.8547, -0.5835,\n",
      "         -0.5090, -0.5090, -0.5090, -0.0718, -0.5090, -0.5090, -0.5595, -1.2036,\n",
      "         -0.5090, -0.5206, -1.7934, -0.5090, -0.5376, -0.5090, -1.9833, -1.0249,\n",
      "         -1.5161, -1.5600, -1.5758, -2.0951, -1.5600, -1.1431],\n",
      "        [-1.5864, -1.4496, -1.2866, -1.0545, -0.8613, -0.8547, -0.5835, -0.5090,\n",
      "         -0.5090, -0.5090, -0.0718, -0.5090, -0.5090, -0.5595, -1.2036, -0.5090,\n",
      "         -0.5206, -1.7934, -0.5090, -0.5376, -0.5090, -1.9833, -1.0249, -1.5161,\n",
      "         -1.5600, -1.5758, -2.0951, -1.5600, -1.1431, -1.2701],\n",
      "        [-1.4496, -1.2866, -1.0545, -0.8613, -0.8547, -0.5835, -0.5090, -0.5090,\n",
      "         -0.5090, -0.0718, -0.5090, -0.5090, -0.5595, -1.2036, -0.5090, -0.5206,\n",
      "         -1.7934, -0.5090, -0.5376, -0.5090, -1.9833, -1.0249, -1.5161, -1.5600,\n",
      "         -1.5758, -2.0951, -1.5600, -1.1431, -1.2701, -1.4363],\n",
      "        [-1.2866, -1.0545, -0.8613, -0.8547, -0.5835, -0.5090, -0.5090, -0.5090,\n",
      "         -0.0718, -0.5090, -0.5090, -0.5595, -1.2036, -0.5090, -0.5206, -1.7934,\n",
      "         -0.5090, -0.5376, -0.5090, -1.9833, -1.0249, -1.5161, -1.5600, -1.5758,\n",
      "         -2.0951, -1.5600, -1.1431, -1.2701, -1.4363, -1.5809],\n",
      "        [-1.0545, -0.8613, -0.8547, -0.5835, -0.5090, -0.5090, -0.5090, -0.0718,\n",
      "         -0.5090, -0.5090, -0.5595, -1.2036, -0.5090, -0.5206, -1.7934, -0.5090,\n",
      "         -0.5376, -0.5090, -1.9833, -1.0249, -1.5161, -1.5600, -1.5758, -2.0951,\n",
      "         -1.5600, -1.1431, -1.2701, -1.4363, -1.5809, -1.6748],\n",
      "        [-0.8613, -0.8547, -0.5835, -0.5090, -0.5090, -0.5090, -0.0718, -0.5090,\n",
      "         -0.5090, -0.5595, -1.2036, -0.5090, -0.5206, -1.7934, -0.5090, -0.5376,\n",
      "         -0.5090, -1.9833, -1.0249, -1.5161, -1.5600, -1.5758, -2.0951, -1.5600,\n",
      "         -1.1431, -1.2701, -1.4363, -1.5809, -1.6748, -1.7631],\n",
      "        [-0.8547, -0.5835, -0.5090, -0.5090, -0.5090, -0.0718, -0.5090, -0.5090,\n",
      "         -0.5595, -1.2036, -0.5090, -0.5206, -1.7934, -0.5090, -0.5376, -0.5090,\n",
      "         -1.9833, -1.0249, -1.5161, -1.5600, -1.5758, -2.0951, -1.5600, -1.1431,\n",
      "         -1.2701, -1.4363, -1.5809, -1.6748, -1.7631, -1.8934],\n",
      "        [-0.5835, -0.5090, -0.5090, -0.5090, -0.0718, -0.5090, -0.5090, -0.5595,\n",
      "         -1.2036, -0.5090, -0.5206, -1.7934, -0.5090, -0.5376, -0.5090, -1.9833,\n",
      "         -1.0249, -1.5161, -1.5600, -1.5758, -2.0951, -1.5600, -1.1431, -1.2701,\n",
      "         -1.4363, -1.5809, -1.6748, -1.7631, -1.8934, -2.0253],\n",
      "        [-0.5090, -0.5090, -0.5090, -0.0718, -0.5090, -0.5090, -0.5595, -1.2036,\n",
      "         -0.5090, -0.5206, -1.7934, -0.5090, -0.5376, -0.5090, -1.9833, -1.0249,\n",
      "         -1.5161, -1.5600, -1.5758, -2.0951, -1.5600, -1.1431, -1.2701, -1.4363,\n",
      "         -1.5809, -1.6748, -1.7631, -1.8934, -2.0253, -2.1510],\n",
      "        [-0.5090, -0.5090, -0.0718, -0.5090, -0.5090, -0.5595, -1.2036, -0.5090,\n",
      "         -0.5206, -1.7934, -0.5090, -0.5376, -0.5090, -1.9833, -1.0249, -1.5161,\n",
      "         -1.5600, -1.5758, -2.0951, -1.5600, -1.1431, -1.2701, -1.4363, -1.5809,\n",
      "         -1.6748, -1.7631, -1.8934, -2.0253, -2.1510, -2.4830],\n",
      "        [-0.5090, -0.0718, -0.5090, -0.5090, -0.5595, -1.2036, -0.5090, -0.5206,\n",
      "         -1.7934, -0.5090, -0.5376, -0.5090, -1.9833, -1.0249, -1.5161, -1.5600,\n",
      "         -1.5758, -2.0951, -1.5600, -1.1431, -1.2701, -1.4363, -1.5809, -1.6748,\n",
      "         -1.7631, -1.8934, -2.0253, -2.1510, -2.4830, -2.9835],\n",
      "        [-0.0718, -0.5090, -0.5090, -0.5595, -1.2036, -0.5090, -0.5206, -1.7934,\n",
      "         -0.5090, -0.5376, -0.5090, -1.9833, -1.0249, -1.5161, -1.5600, -1.5758,\n",
      "         -2.0951, -1.5600, -1.1431, -1.2701, -1.4363, -1.5809, -1.6748, -1.7631,\n",
      "         -1.8934, -2.0253, -2.1510, -2.4830, -2.9835, -3.5398],\n",
      "        [-0.5090, -0.5090, -0.5595, -1.2036, -0.5090, -0.5206, -1.7934, -0.5090,\n",
      "         -0.5376, -0.5090, -1.9833, -1.0249, -1.5161, -1.5600, -1.5758, -2.0951,\n",
      "         -1.5600, -1.1431, -1.2701, -1.4363, -1.5809, -1.6748, -1.7631, -1.8934,\n",
      "         -2.0253, -2.1510, -2.4830, -2.9835, -3.5398, -4.1561]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2,\n",
      "         4, 7, 8, 7, 8, 2],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4,\n",
      "         7, 8, 7, 8, 2, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7,\n",
      "         8, 7, 8, 2, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8,\n",
      "         7, 8, 2, 8, 8, 5],\n",
      "        [6, 6, 6, 6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7,\n",
      "         8, 2, 8, 8, 5, 5],\n",
      "        [6, 6, 6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8,\n",
      "         2, 8, 8, 5, 5, 5],\n",
      "        [6, 6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2,\n",
      "         8, 8, 5, 5, 5, 5],\n",
      "        [6, 6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8,\n",
      "         8, 5, 5, 5, 5, 5],\n",
      "        [6, 7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8,\n",
      "         5, 5, 5, 5, 5, 5],\n",
      "        [7, 6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8, 5,\n",
      "         5, 5, 5, 5, 5, 5],\n",
      "        [6, 4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8, 5, 5,\n",
      "         5, 5, 5, 5, 5, 5],\n",
      "        [4, 4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8, 5, 5, 5,\n",
      "         5, 5, 5, 5, 5, 5],\n",
      "        [4, 4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8, 5, 5, 5, 5,\n",
      "         5, 5, 5, 5, 5, 6],\n",
      "        [4, 6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8, 5, 5, 5, 5, 5,\n",
      "         5, 5, 5, 5, 6, 6],\n",
      "        [6, 4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8, 5, 5, 5, 5, 5, 5,\n",
      "         5, 5, 5, 6, 6, 6],\n",
      "        [4, 4, 7, 7, 4, 7, 7, 4, 2, 4, 7, 8, 7, 8, 2, 8, 8, 5, 5, 5, 5, 5, 5, 5,\n",
      "         5, 5, 6, 6, 6, 6]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-0.4970, -0.7087, -1.3285, -0.4970, -0.6713, -1.8960, -0.5491, -0.5491,\n",
      "         -0.5491, -2.0788, -1.1149, -1.6292, -1.6807, -1.6807, -2.2465, -1.6807,\n",
      "         -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,  0.1261, -1.3163, -0.4970,\n",
      "         -0.4970, -1.8972, -1.8667, -2.0059, -1.6512, -2.0484],\n",
      "        [-0.7087, -1.3285, -0.4970, -0.6713, -1.8960, -0.5491, -0.5491, -0.5491,\n",
      "         -2.0788, -1.1149, -1.6292, -1.6807, -1.6807, -2.2465, -1.6807, -1.1149,\n",
      "         -1.1149, -1.2634, -0.5491, -0.4970,  0.1261, -1.3163, -0.4970, -0.4970,\n",
      "         -1.8972, -1.8667, -2.0059, -1.6512, -2.0484, -1.5761],\n",
      "        [-1.3285, -0.4970, -0.6713, -1.8960, -0.5491, -0.5491, -0.5491, -2.0788,\n",
      "         -1.1149, -1.6292, -1.6807, -1.6807, -2.2465, -1.6807, -1.1149, -1.1149,\n",
      "         -1.2634, -0.5491, -0.4970,  0.1261, -1.3163, -0.4970, -0.4970, -1.8972,\n",
      "         -1.8667, -2.0059, -1.6512, -2.0484, -1.5761, -1.0842],\n",
      "        [-0.4970, -0.6713, -1.8960, -0.5491, -0.5491, -0.5491, -2.0788, -1.1149,\n",
      "         -1.6292, -1.6807, -1.6807, -2.2465, -1.6807, -1.1149, -1.1149, -1.2634,\n",
      "         -0.5491, -0.4970,  0.1261, -1.3163, -0.4970, -0.4970, -1.8972, -1.8667,\n",
      "         -2.0059, -1.6512, -2.0484, -1.5761, -1.0842, -1.1650],\n",
      "        [-0.6713, -1.8960, -0.5491, -0.5491, -0.5491, -2.0788, -1.1149, -1.6292,\n",
      "         -1.6807, -1.6807, -2.2465, -1.6807, -1.1149, -1.1149, -1.2634, -0.5491,\n",
      "         -0.4970,  0.1261, -1.3163, -0.4970, -0.4970, -1.8972, -1.8667, -2.0059,\n",
      "         -1.6512, -2.0484, -1.5761, -1.0842, -1.1650, -1.3016],\n",
      "        [-1.8960, -0.5491, -0.5491, -0.5491, -2.0788, -1.1149, -1.6292, -1.6807,\n",
      "         -1.6807, -2.2465, -1.6807, -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,\n",
      "          0.1261, -1.3163, -0.4970, -0.4970, -1.8972, -1.8667, -2.0059, -1.6512,\n",
      "         -2.0484, -1.5761, -1.0842, -1.1650, -1.3016, -1.4455],\n",
      "        [-0.5491, -0.5491, -0.5491, -2.0788, -1.1149, -1.6292, -1.6807, -1.6807,\n",
      "         -2.2465, -1.6807, -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,  0.1261,\n",
      "         -1.3163, -0.4970, -0.4970, -1.8972, -1.8667, -2.0059, -1.6512, -2.0484,\n",
      "         -1.5761, -1.0842, -1.1650, -1.3016, -1.4455, -1.5898],\n",
      "        [-0.5491, -0.5491, -2.0788, -1.1149, -1.6292, -1.6807, -1.6807, -2.2465,\n",
      "         -1.6807, -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,  0.1261, -1.3163,\n",
      "         -0.4970, -0.4970, -1.8972, -1.8667, -2.0059, -1.6512, -2.0484, -1.5761,\n",
      "         -1.0842, -1.1650, -1.3016, -1.4455, -1.5898, -1.7077],\n",
      "        [-0.5491, -2.0788, -1.1149, -1.6292, -1.6807, -1.6807, -2.2465, -1.6807,\n",
      "         -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,  0.1261, -1.3163, -0.4970,\n",
      "         -0.4970, -1.8972, -1.8667, -2.0059, -1.6512, -2.0484, -1.5761, -1.0842,\n",
      "         -1.1650, -1.3016, -1.4455, -1.5898, -1.7077, -1.8379],\n",
      "        [-2.0788, -1.1149, -1.6292, -1.6807, -1.6807, -2.2465, -1.6807, -1.1149,\n",
      "         -1.1149, -1.2634, -0.5491, -0.4970,  0.1261, -1.3163, -0.4970, -0.4970,\n",
      "         -1.8972, -1.8667, -2.0059, -1.6512, -2.0484, -1.5761, -1.0842, -1.1650,\n",
      "         -1.3016, -1.4455, -1.5898, -1.7077, -1.8379, -1.9557],\n",
      "        [-1.1149, -1.6292, -1.6807, -1.6807, -2.2465, -1.6807, -1.1149, -1.1149,\n",
      "         -1.2634, -0.5491, -0.4970,  0.1261, -1.3163, -0.4970, -0.4970, -1.8972,\n",
      "         -1.8667, -2.0059, -1.6512, -2.0484, -1.5761, -1.0842, -1.1650, -1.3016,\n",
      "         -1.4455, -1.5898, -1.7077, -1.8379, -1.9557, -2.0507],\n",
      "        [-1.6292, -1.6807, -1.6807, -2.2465, -1.6807, -1.1149, -1.1149, -1.2634,\n",
      "         -0.5491, -0.4970,  0.1261, -1.3163, -0.4970, -0.4970, -1.8972, -1.8667,\n",
      "         -2.0059, -1.6512, -2.0484, -1.5761, -1.0842, -1.1650, -1.3016, -1.4455,\n",
      "         -1.5898, -1.7077, -1.8379, -1.9557, -2.0507, -2.1265],\n",
      "        [-1.6807, -1.6807, -2.2465, -1.6807, -1.1149, -1.1149, -1.2634, -0.5491,\n",
      "         -0.4970,  0.1261, -1.3163, -0.4970, -0.4970, -1.8972, -1.8667, -2.0059,\n",
      "         -1.6512, -2.0484, -1.5761, -1.0842, -1.1650, -1.3016, -1.4455, -1.5898,\n",
      "         -1.7077, -1.8379, -1.9557, -2.0507, -2.1265, -2.2223],\n",
      "        [-1.6807, -2.2465, -1.6807, -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,\n",
      "          0.1261, -1.3163, -0.4970, -0.4970, -1.8972, -1.8667, -2.0059, -1.6512,\n",
      "         -2.0484, -1.5761, -1.0842, -1.1650, -1.3016, -1.4455, -1.5898, -1.7077,\n",
      "         -1.8379, -1.9557, -2.0507, -2.1265, -2.2223, -2.2889],\n",
      "        [-2.2465, -1.6807, -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,  0.1261,\n",
      "         -1.3163, -0.4970, -0.4970, -1.8972, -1.8667, -2.0059, -1.6512, -2.0484,\n",
      "         -1.5761, -1.0842, -1.1650, -1.3016, -1.4455, -1.5898, -1.7077, -1.8379,\n",
      "         -1.9557, -2.0507, -2.1265, -2.2223, -2.2889, -2.3724],\n",
      "        [-1.6807, -1.1149, -1.1149, -1.2634, -0.5491, -0.4970,  0.1261, -1.3163,\n",
      "         -0.4970, -0.4970, -1.8972, -1.8667, -2.0059, -1.6512, -2.0484, -1.5761,\n",
      "         -1.0842, -1.1650, -1.3016, -1.4455, -1.5898, -1.7077, -1.8379, -1.9557,\n",
      "         -2.0507, -2.1265, -2.2223, -2.2889, -2.3724, -2.4547]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[4, 7, 7, 4, 7, 7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4,\n",
      "         4, 7, 1, 0, 3, 0],\n",
      "        [7, 7, 4, 7, 7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4,\n",
      "         7, 1, 0, 3, 0, 1],\n",
      "        [7, 4, 7, 7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7,\n",
      "         1, 0, 3, 0, 1, 5],\n",
      "        [4, 7, 7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1,\n",
      "         0, 3, 0, 1, 5, 6],\n",
      "        [7, 7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0,\n",
      "         3, 0, 1, 5, 6, 6],\n",
      "        [7, 8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3,\n",
      "         0, 1, 5, 6, 6, 6],\n",
      "        [8, 8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0,\n",
      "         1, 5, 6, 6, 6, 6],\n",
      "        [8, 8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1,\n",
      "         5, 6, 6, 6, 6, 6],\n",
      "        [8, 7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 8, 7, 8, 4, 5, 7, 4, 4, 7, 1, 0, 3, 0, 1, 5, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.8468, -2.8468, -2.1735, -2.1735, -1.5002, -0.8269, -2.0079, -0.8269,\n",
      "         -0.8269, -2.7695, -2.0862, -2.2453, -1.9004, -2.2853, -1.8165, -1.1467,\n",
      "         -0.8269, -1.0000, -0.8269, -0.8269, -1.3633, -0.8269, -0.6377, -0.6887,\n",
      "         -0.7593, -0.7423, -0.7169, -0.6897, -0.6571, -0.7214],\n",
      "        [-2.8468, -2.1735, -2.1735, -1.5002, -0.8269, -2.0079, -0.8269, -0.8269,\n",
      "         -2.7695, -2.0862, -2.2453, -1.9004, -2.2853, -1.8165, -1.1467, -0.8269,\n",
      "         -1.0000, -0.8269, -0.8269, -1.3633, -0.8269, -0.6377, -0.6887, -0.7593,\n",
      "         -0.7423, -0.7169, -0.6897, -0.6571, -0.7214, -1.2287],\n",
      "        [-2.1735, -2.1735, -1.5002, -0.8269, -2.0079, -0.8269, -0.8269, -2.7695,\n",
      "         -2.0862, -2.2453, -1.9004, -2.2853, -1.8165, -1.1467, -0.8269, -1.0000,\n",
      "         -0.8269, -0.8269, -1.3633, -0.8269, -0.6377, -0.6887, -0.7593, -0.7423,\n",
      "         -0.7169, -0.6897, -0.6571, -0.7214, -1.2287, -0.8900],\n",
      "        [-2.1735, -1.5002, -0.8269, -2.0079, -0.8269, -0.8269, -2.7695, -2.0862,\n",
      "         -2.2453, -1.9004, -2.2853, -1.8165, -1.1467, -0.8269, -1.0000, -0.8269,\n",
      "         -0.8269, -1.3633, -0.8269, -0.6377, -0.6887, -0.7593, -0.7423, -0.7169,\n",
      "         -0.6897, -0.6571, -0.7214, -1.2287, -0.8900, -0.9778],\n",
      "        [-1.5002, -0.8269, -2.0079, -0.8269, -0.8269, -2.7695, -2.0862, -2.2453,\n",
      "         -1.9004, -2.2853, -1.8165, -1.1467, -0.8269, -1.0000, -0.8269, -0.8269,\n",
      "         -1.3633, -0.8269, -0.6377, -0.6887, -0.7593, -0.7423, -0.7169, -0.6897,\n",
      "         -0.6571, -0.7214, -1.2287, -0.8900, -0.9778, -1.0703],\n",
      "        [-0.8269, -2.0079, -0.8269, -0.8269, -2.7695, -2.0862, -2.2453, -1.9004,\n",
      "         -2.2853, -1.8165, -1.1467, -0.8269, -1.0000, -0.8269, -0.8269, -1.3633,\n",
      "         -0.8269, -0.6377, -0.6887, -0.7593, -0.7423, -0.7169, -0.6897, -0.6571,\n",
      "         -0.7214, -1.2287, -0.8900, -0.9778, -1.0703, -1.1419],\n",
      "        [-2.0079, -0.8269, -0.8269, -2.7695, -2.0862, -2.2453, -1.9004, -2.2853,\n",
      "         -1.8165, -1.1467, -0.8269, -1.0000, -0.8269, -0.8269, -1.3633, -0.8269,\n",
      "         -0.6377, -0.6887, -0.7593, -0.7423, -0.7169, -0.6897, -0.6571, -0.7214,\n",
      "         -1.2287, -0.8900, -0.9778, -1.0703, -1.1419, -1.2226],\n",
      "        [-0.8269, -0.8269, -2.7695, -2.0862, -2.2453, -1.9004, -2.2853, -1.8165,\n",
      "         -1.1467, -0.8269, -1.0000, -0.8269, -0.8269, -1.3633, -0.8269, -0.6377,\n",
      "         -0.6887, -0.7593, -0.7423, -0.7169, -0.6897, -0.6571, -0.7214, -1.2287,\n",
      "         -0.8900, -0.9778, -1.0703, -1.1419, -1.2226, -1.3010],\n",
      "        [-0.8269, -2.7695, -2.0862, -2.2453, -1.9004, -2.2853, -1.8165, -1.1467,\n",
      "         -0.8269, -1.0000, -0.8269, -0.8269, -1.3633, -0.8269, -0.6377, -0.6887,\n",
      "         -0.7593, -0.7423, -0.7169, -0.6897, -0.6571, -0.7214, -1.2287, -0.8900,\n",
      "         -0.9778, -1.0703, -1.1419, -1.2226, -1.3010, -1.3553],\n",
      "        [-2.7695, -2.0862, -2.2453, -1.9004, -2.2853, -1.8165, -1.1467, -0.8269,\n",
      "         -1.0000, -0.8269, -0.8269, -1.3633, -0.8269, -0.6377, -0.6887, -0.7593,\n",
      "         -0.7423, -0.7169, -0.6897, -0.6571, -0.7214, -1.2287, -0.8900, -0.9778,\n",
      "         -1.0703, -1.1419, -1.2226, -1.3010, -1.3553, -1.4283],\n",
      "        [-2.0862, -2.2453, -1.9004, -2.2853, -1.8165, -1.1467, -0.8269, -1.0000,\n",
      "         -0.8269, -0.8269, -1.3633, -0.8269, -0.6377, -0.6887, -0.7593, -0.7423,\n",
      "         -0.7169, -0.6897, -0.6571, -0.7214, -1.2287, -0.8900, -0.9778, -1.0703,\n",
      "         -1.1419, -1.2226, -1.3010, -1.3553, -1.4283, -1.4892],\n",
      "        [-2.2453, -1.9004, -2.2853, -1.8165, -1.1467, -0.8269, -1.0000, -0.8269,\n",
      "         -0.8269, -1.3633, -0.8269, -0.6377, -0.6887, -0.7593, -0.7423, -0.7169,\n",
      "         -0.6897, -0.6571, -0.7214, -1.2287, -0.8900, -0.9778, -1.0703, -1.1419,\n",
      "         -1.2226, -1.3010, -1.3553, -1.4283, -1.4892, -1.5467],\n",
      "        [-1.9004, -2.2853, -1.8165, -1.1467, -0.8269, -1.0000, -0.8269, -0.8269,\n",
      "         -1.3633, -0.8269, -0.6377, -0.6887, -0.7593, -0.7423, -0.7169, -0.6897,\n",
      "         -0.6571, -0.7214, -1.2287, -0.8900, -0.9778, -1.0703, -1.1419, -1.2226,\n",
      "         -1.3010, -1.3553, -1.4283, -1.4892, -1.5467, -1.5867],\n",
      "        [-2.2853, -1.8165, -1.1467, -0.8269, -1.0000, -0.8269, -0.8269, -1.3633,\n",
      "         -0.8269, -0.6377, -0.6887, -0.7593, -0.7423, -0.7169, -0.6897, -0.6571,\n",
      "         -0.7214, -1.2287, -0.8900, -0.9778, -1.0703, -1.1419, -1.2226, -1.3010,\n",
      "         -1.3553, -1.4283, -1.4892, -1.5467, -1.5867, -1.6416],\n",
      "        [-1.8165, -1.1467, -0.8269, -1.0000, -0.8269, -0.8269, -1.3633, -0.8269,\n",
      "         -0.6377, -0.6887, -0.7593, -0.7423, -0.7169, -0.6897, -0.6571, -0.7214,\n",
      "         -1.2287, -0.8900, -0.9778, -1.0703, -1.1419, -1.2226, -1.3010, -1.3553,\n",
      "         -1.4283, -1.4892, -1.5467, -1.5867, -1.6416, -1.6734],\n",
      "        [-1.1467, -0.8269, -1.0000, -0.8269, -0.8269, -1.3633, -0.8269, -0.6377,\n",
      "         -0.6887, -0.7593, -0.7423, -0.7169, -0.6897, -0.6571, -0.7214, -1.2287,\n",
      "         -0.8900, -0.9778, -1.0703, -1.1419, -1.2226, -1.3010, -1.3553, -1.4283,\n",
      "         -1.4892, -1.5467, -1.5867, -1.6416, -1.6734, -1.7102]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[8, 8, 8, 8, 8, 8, 7, 8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5,\n",
      "         5, 5, 5, 5, 5, 6],\n",
      "        [8, 8, 8, 8, 8, 7, 8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5,\n",
      "         5, 5, 5, 5, 6, 7],\n",
      "        [8, 8, 8, 8, 7, 8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5,\n",
      "         5, 5, 5, 6, 7, 6],\n",
      "        [8, 8, 8, 7, 8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5,\n",
      "         5, 5, 6, 7, 6, 6],\n",
      "        [8, 8, 7, 8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5,\n",
      "         5, 6, 7, 6, 6, 6],\n",
      "        [8, 7, 8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5,\n",
      "         6, 7, 6, 6, 6, 6],\n",
      "        [7, 8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6,\n",
      "         7, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [1, 0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [0, 3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [3, 0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [0, 1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [1, 1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [1, 8, 7, 8, 8, 7, 8, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.7610, -2.7001, -2.8288, -2.6045, -2.6045, -2.9331, -2.0293, -1.7082,\n",
      "         -2.0216, -1.5535, -1.0118, -0.9665, -0.9122, -0.8691, -1.6819, -1.0803,\n",
      "         -1.1810, -0.8066, -0.7213, -0.7678, -0.5661, -0.4939, -0.4939, -0.3743,\n",
      "         -0.4939, -1.5217, -0.6351, -0.6895, -0.7525, -0.8031],\n",
      "        [-2.7001, -2.8288, -2.6045, -2.6045, -2.9331, -2.0293, -1.7082, -2.0216,\n",
      "         -1.5535, -1.0118, -0.9665, -0.9122, -0.8691, -1.6819, -1.0803, -1.1810,\n",
      "         -0.8066, -0.7213, -0.7678, -0.5661, -0.4939, -0.4939, -0.3743, -0.4939,\n",
      "         -1.5217, -0.6351, -0.6895, -0.7525, -0.8031, -0.8718],\n",
      "        [-2.8288, -2.6045, -2.6045, -2.9331, -2.0293, -1.7082, -2.0216, -1.5535,\n",
      "         -1.0118, -0.9665, -0.9122, -0.8691, -1.6819, -1.0803, -1.1810, -0.8066,\n",
      "         -0.7213, -0.7678, -0.5661, -0.4939, -0.4939, -0.3743, -0.4939, -1.5217,\n",
      "         -0.6351, -0.6895, -0.7525, -0.8031, -0.8718, -0.9169],\n",
      "        [-2.6045, -2.6045, -2.9331, -2.0293, -1.7082, -2.0216, -1.5535, -1.0118,\n",
      "         -0.9665, -0.9122, -0.8691, -1.6819, -1.0803, -1.1810, -0.8066, -0.7213,\n",
      "         -0.7678, -0.5661, -0.4939, -0.4939, -0.3743, -0.4939, -1.5217, -0.6351,\n",
      "         -0.6895, -0.7525, -0.8031, -0.8718, -0.9169, -0.9198],\n",
      "        [-2.6045, -2.9331, -2.0293, -1.7082, -2.0216, -1.5535, -1.0118, -0.9665,\n",
      "         -0.9122, -0.8691, -1.6819, -1.0803, -1.1810, -0.8066, -0.7213, -0.7678,\n",
      "         -0.5661, -0.4939, -0.4939, -0.3743, -0.4939, -1.5217, -0.6351, -0.6895,\n",
      "         -0.7525, -0.8031, -0.8718, -0.9169, -0.9198, -1.4025],\n",
      "        [-2.9331, -2.0293, -1.7082, -2.0216, -1.5535, -1.0118, -0.9665, -0.9122,\n",
      "         -0.8691, -1.6819, -1.0803, -1.1810, -0.8066, -0.7213, -0.7678, -0.5661,\n",
      "         -0.4939, -0.4939, -0.3743, -0.4939, -1.5217, -0.6351, -0.6895, -0.7525,\n",
      "         -0.8031, -0.8718, -0.9169, -0.9198, -1.4025, -0.9994],\n",
      "        [-2.0293, -1.7082, -2.0216, -1.5535, -1.0118, -0.9665, -0.9122, -0.8691,\n",
      "         -1.6819, -1.0803, -1.1810, -0.8066, -0.7213, -0.7678, -0.5661, -0.4939,\n",
      "         -0.4939, -0.3743, -0.4939, -1.5217, -0.6351, -0.6895, -0.7525, -0.8031,\n",
      "         -0.8718, -0.9169, -0.9198, -1.4025, -0.9994, -1.9941],\n",
      "        [-1.7082, -2.0216, -1.5535, -1.0118, -0.9665, -0.9122, -0.8691, -1.6819,\n",
      "         -1.0803, -1.1810, -0.8066, -0.7213, -0.7678, -0.5661, -0.4939, -0.4939,\n",
      "         -0.3743, -0.4939, -1.5217, -0.6351, -0.6895, -0.7525, -0.8031, -0.8718,\n",
      "         -0.9169, -0.9198, -1.4025, -0.9994, -1.9941, -1.1101],\n",
      "        [-2.0216, -1.5535, -1.0118, -0.9665, -0.9122, -0.8691, -1.6819, -1.0803,\n",
      "         -1.1810, -0.8066, -0.7213, -0.7678, -0.5661, -0.4939, -0.4939, -0.3743,\n",
      "         -0.4939, -1.5217, -0.6351, -0.6895, -0.7525, -0.8031, -0.8718, -0.9169,\n",
      "         -0.9198, -1.4025, -0.9994, -1.9941, -1.1101, -1.1748],\n",
      "        [-1.5535, -1.0118, -0.9665, -0.9122, -0.8691, -1.6819, -1.0803, -1.1810,\n",
      "         -0.8066, -0.7213, -0.7678, -0.5661, -0.4939, -0.4939, -0.3743, -0.4939,\n",
      "         -1.5217, -0.6351, -0.6895, -0.7525, -0.8031, -0.8718, -0.9169, -0.9198,\n",
      "         -1.4025, -0.9994, -1.9941, -1.1101, -1.1748, -1.5349],\n",
      "        [-1.0118, -0.9665, -0.9122, -0.8691, -1.6819, -1.0803, -1.1810, -0.8066,\n",
      "         -0.7213, -0.7678, -0.5661, -0.4939, -0.4939, -0.3743, -0.4939, -1.5217,\n",
      "         -0.6351, -0.6895, -0.7525, -0.8031, -0.8718, -0.9169, -0.9198, -1.4025,\n",
      "         -0.9994, -1.9941, -1.1101, -1.1748, -1.5349, -1.5349],\n",
      "        [-0.9665, -0.9122, -0.8691, -1.6819, -1.0803, -1.1810, -0.8066, -0.7213,\n",
      "         -0.7678, -0.5661, -0.4939, -0.4939, -0.3743, -0.4939, -1.5217, -0.6351,\n",
      "         -0.6895, -0.7525, -0.8031, -0.8718, -0.9169, -0.9198, -1.4025, -0.9994,\n",
      "         -1.9941, -1.1101, -1.1748, -1.5349, -1.5349, -1.3544],\n",
      "        [-0.9122, -0.8691, -1.6819, -1.0803, -1.1810, -0.8066, -0.7213, -0.7678,\n",
      "         -0.5661, -0.4939, -0.4939, -0.3743, -0.4939, -1.5217, -0.6351, -0.6895,\n",
      "         -0.7525, -0.8031, -0.8718, -0.9169, -0.9198, -1.4025, -0.9994, -1.9941,\n",
      "         -1.1101, -1.1748, -1.5349, -1.5349, -1.3544, -1.5349],\n",
      "        [-0.8691, -1.6819, -1.0803, -1.1810, -0.8066, -0.7213, -0.7678, -0.5661,\n",
      "         -0.4939, -0.4939, -0.3743, -0.4939, -1.5217, -0.6351, -0.6895, -0.7525,\n",
      "         -0.8031, -0.8718, -0.9169, -0.9198, -1.4025, -0.9994, -1.9941, -1.1101,\n",
      "         -1.1748, -1.5349, -1.5349, -1.3544, -1.5349, -1.5349],\n",
      "        [-1.6819, -1.0803, -1.1810, -0.8066, -0.7213, -0.7678, -0.5661, -0.4939,\n",
      "         -0.4939, -0.3743, -0.4939, -1.5217, -0.6351, -0.6895, -0.7525, -0.8031,\n",
      "         -0.8718, -0.9169, -0.9198, -1.4025, -0.9994, -1.9941, -1.1101, -1.1748,\n",
      "         -1.5349, -1.5349, -1.3544, -1.5349, -1.5349, -1.5349],\n",
      "        [-1.0803, -1.1810, -0.8066, -0.7213, -0.7678, -0.5661, -0.4939, -0.4939,\n",
      "         -0.3743, -0.4939, -1.5217, -0.6351, -0.6895, -0.7525, -0.8031, -0.8718,\n",
      "         -0.9169, -0.9198, -1.4025, -0.9994, -1.9941, -1.1101, -1.1748, -1.5349,\n",
      "         -1.5349, -1.3544, -1.5349, -1.5349, -1.5349, -2.6045]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[0, 3, 0, 8, 8, 0, 2, 3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6,\n",
      "         4, 7, 6, 6, 6, 6],\n",
      "        [3, 0, 8, 8, 0, 2, 3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4,\n",
      "         7, 6, 6, 6, 6, 6],\n",
      "        [0, 8, 8, 0, 2, 3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 8, 0, 2, 3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 0, 2, 3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6,\n",
      "         6, 6, 6, 6, 6, 7],\n",
      "        [0, 2, 3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6,\n",
      "         6, 6, 6, 6, 7, 6],\n",
      "        [2, 3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6,\n",
      "         6, 6, 6, 7, 6, 7],\n",
      "        [3, 3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6,\n",
      "         6, 6, 7, 6, 7, 6],\n",
      "        [3, 0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6,\n",
      "         6, 7, 6, 7, 6, 6],\n",
      "        [0, 5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6, 6,\n",
      "         7, 6, 7, 6, 6, 8],\n",
      "        [5, 5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6, 6, 7,\n",
      "         6, 7, 6, 6, 8, 8],\n",
      "        [5, 5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6,\n",
      "         7, 6, 6, 8, 8, 6],\n",
      "        [5, 5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 7,\n",
      "         6, 6, 8, 8, 6, 8],\n",
      "        [5, 7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 7, 6,\n",
      "         6, 8, 8, 6, 8, 8],\n",
      "        [7, 1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 7, 6, 6,\n",
      "         8, 8, 6, 8, 8, 8],\n",
      "        [1, 2, 5, 5, 7, 5, 4, 4, 6, 4, 7, 6, 6, 6, 6, 6, 6, 6, 7, 6, 7, 6, 6, 8,\n",
      "         8, 6, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.2577, -2.0955, -1.9207, -2.2225, -2.0154, -1.7328, -1.6433, -1.5462,\n",
      "         -1.4419, -1.4231, -1.6448, -1.4349, -1.4523, -1.0209, -0.8949, -0.7378,\n",
      "         -0.6269, -1.2925, -0.4923, -1.9408, -0.6629, -0.8201, -1.0470, -1.2070,\n",
      "         -1.2566, -1.2212, -1.1826, -1.0799, -0.8726, -0.6211],\n",
      "        [-2.0955, -1.9207, -2.2225, -2.0154, -1.7328, -1.6433, -1.5462, -1.4419,\n",
      "         -1.4231, -1.6448, -1.4349, -1.4523, -1.0209, -0.8949, -0.7378, -0.6269,\n",
      "         -1.2925, -0.4923, -1.9408, -0.6629, -0.8201, -1.0470, -1.2070, -1.2566,\n",
      "         -1.2212, -1.1826, -1.0799, -0.8726, -0.6211, -1.0750],\n",
      "        [-1.9207, -2.2225, -2.0154, -1.7328, -1.6433, -1.5462, -1.4419, -1.4231,\n",
      "         -1.6448, -1.4349, -1.4523, -1.0209, -0.8949, -0.7378, -0.6269, -1.2925,\n",
      "         -0.4923, -1.9408, -0.6629, -0.8201, -1.0470, -1.2070, -1.2566, -1.2212,\n",
      "         -1.1826, -1.0799, -0.8726, -0.6211, -1.0750, -0.9051],\n",
      "        [-2.2225, -2.0154, -1.7328, -1.6433, -1.5462, -1.4419, -1.4231, -1.6448,\n",
      "         -1.4349, -1.4523, -1.0209, -0.8949, -0.7378, -0.6269, -1.2925, -0.4923,\n",
      "         -1.9408, -0.6629, -0.8201, -1.0470, -1.2070, -1.2566, -1.2212, -1.1826,\n",
      "         -1.0799, -0.8726, -0.6211, -1.0750, -0.9051, -0.9051],\n",
      "        [-2.0154, -1.7328, -1.6433, -1.5462, -1.4419, -1.4231, -1.6448, -1.4349,\n",
      "         -1.4523, -1.0209, -0.8949, -0.7378, -0.6269, -1.2925, -0.4923, -1.9408,\n",
      "         -0.6629, -0.8201, -1.0470, -1.2070, -1.2566, -1.2212, -1.1826, -1.0799,\n",
      "         -0.8726, -0.6211, -1.0750, -0.9051, -0.9051, -1.3630],\n",
      "        [-1.7328, -1.6433, -1.5462, -1.4419, -1.4231, -1.6448, -1.4349, -1.4523,\n",
      "         -1.0209, -0.8949, -0.7378, -0.6269, -1.2925, -0.4923, -1.9408, -0.6629,\n",
      "         -0.8201, -1.0470, -1.2070, -1.2566, -1.2212, -1.1826, -1.0799, -0.8726,\n",
      "         -0.6211, -1.0750, -0.9051, -0.9051, -1.3630, -1.5568],\n",
      "        [-1.6433, -1.5462, -1.4419, -1.4231, -1.6448, -1.4349, -1.4523, -1.0209,\n",
      "         -0.8949, -0.7378, -0.6269, -1.2925, -0.4923, -1.9408, -0.6629, -0.8201,\n",
      "         -1.0470, -1.2070, -1.2566, -1.2212, -1.1826, -1.0799, -0.8726, -0.6211,\n",
      "         -1.0750, -0.9051, -0.9051, -1.3630, -1.5568, -1.8209],\n",
      "        [-1.5462, -1.4419, -1.4231, -1.6448, -1.4349, -1.4523, -1.0209, -0.8949,\n",
      "         -0.7378, -0.6269, -1.2925, -0.4923, -1.9408, -0.6629, -0.8201, -1.0470,\n",
      "         -1.2070, -1.2566, -1.2212, -1.1826, -1.0799, -0.8726, -0.6211, -1.0750,\n",
      "         -0.9051, -0.9051, -1.3630, -1.5568, -1.8209, -1.8209],\n",
      "        [-1.4419, -1.4231, -1.6448, -1.4349, -1.4523, -1.0209, -0.8949, -0.7378,\n",
      "         -0.6269, -1.2925, -0.4923, -1.9408, -0.6629, -0.8201, -1.0470, -1.2070,\n",
      "         -1.2566, -1.2212, -1.1826, -1.0799, -0.8726, -0.6211, -1.0750, -0.9051,\n",
      "         -0.9051, -1.3630, -1.5568, -1.8209, -1.8209, -1.8209],\n",
      "        [-1.4231, -1.6448, -1.4349, -1.4523, -1.0209, -0.8949, -0.7378, -0.6269,\n",
      "         -1.2925, -0.4923, -1.9408, -0.6629, -0.8201, -1.0470, -1.2070, -1.2566,\n",
      "         -1.2212, -1.1826, -1.0799, -0.8726, -0.6211, -1.0750, -0.9051, -0.9051,\n",
      "         -1.3630, -1.5568, -1.8209, -1.8209, -1.8209, -2.2788],\n",
      "        [-1.6448, -1.4349, -1.4523, -1.0209, -0.8949, -0.7378, -0.6269, -1.2925,\n",
      "         -0.4923, -1.9408, -0.6629, -0.8201, -1.0470, -1.2070, -1.2566, -1.2212,\n",
      "         -1.1826, -1.0799, -0.8726, -0.6211, -1.0750, -0.9051, -0.9051, -1.3630,\n",
      "         -1.5568, -1.8209, -1.8209, -1.8209, -2.2788, -2.2788],\n",
      "        [-1.4349, -1.4523, -1.0209, -0.8949, -0.7378, -0.6269, -1.2925, -0.4923,\n",
      "         -1.9408, -0.6629, -0.8201, -1.0470, -1.2070, -1.2566, -1.2212, -1.1826,\n",
      "         -1.0799, -0.8726, -0.6211, -1.0750, -0.9051, -0.9051, -1.3630, -1.5568,\n",
      "         -1.8209, -1.8209, -1.8209, -2.2788, -2.2788, -2.3355],\n",
      "        [-1.4523, -1.0209, -0.8949, -0.7378, -0.6269, -1.2925, -0.4923, -1.9408,\n",
      "         -0.6629, -0.8201, -1.0470, -1.2070, -1.2566, -1.2212, -1.1826, -1.0799,\n",
      "         -0.8726, -0.6211, -1.0750, -0.9051, -0.9051, -1.3630, -1.5568, -1.8209,\n",
      "         -1.8209, -1.8209, -2.2788, -2.2788, -2.3355, -2.2788],\n",
      "        [-1.0209, -0.8949, -0.7378, -0.6269, -1.2925, -0.4923, -1.9408, -0.6629,\n",
      "         -0.8201, -1.0470, -1.2070, -1.2566, -1.2212, -1.1826, -1.0799, -0.8726,\n",
      "         -0.6211, -1.0750, -0.9051, -0.9051, -1.3630, -1.5568, -1.8209, -1.8209,\n",
      "         -1.8209, -2.2788, -2.2788, -2.3355, -2.2788, -1.8209],\n",
      "        [-0.8949, -0.7378, -0.6269, -1.2925, -0.4923, -1.9408, -0.6629, -0.8201,\n",
      "         -1.0470, -1.2070, -1.2566, -1.2212, -1.1826, -1.0799, -0.8726, -0.6211,\n",
      "         -1.0750, -0.9051, -0.9051, -1.3630, -1.5568, -1.8209, -1.8209, -1.8209,\n",
      "         -2.2788, -2.2788, -2.3355, -2.2788, -1.8209, -1.8209],\n",
      "        [-0.7378, -0.6269, -1.2925, -0.4923, -1.9408, -0.6629, -0.8201, -1.0470,\n",
      "         -1.2070, -1.2566, -1.2212, -1.1826, -1.0799, -0.8726, -0.6211, -1.0750,\n",
      "         -0.9051, -0.9051, -1.3630, -1.5568, -1.8209, -1.8209, -1.8209, -2.2788,\n",
      "         -2.2788, -2.3355, -2.2788, -1.8209, -1.8209, -1.8209]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[2, 0, 5, 1, 0, 5, 5, 5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [0, 5, 1, 0, 5, 5, 5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 7],\n",
      "        [5, 1, 0, 5, 5, 5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 7, 8],\n",
      "        [1, 0, 5, 5, 5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 7, 8, 8],\n",
      "        [0, 5, 5, 5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 7, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 7, 8, 8, 8, 7],\n",
      "        [5, 5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "         7, 8, 8, 8, 7, 8],\n",
      "        [5, 5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7,\n",
      "         8, 8, 8, 7, 8, 8],\n",
      "        [5, 7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8,\n",
      "         8, 8, 7, 8, 8, 8],\n",
      "        [7, 1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 8,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [1, 1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [1, 0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8, 7,\n",
      "         8, 8, 8, 8, 8, 0],\n",
      "        [0, 5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8, 7, 8,\n",
      "         8, 8, 8, 8, 0, 8],\n",
      "        [5, 5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8, 7, 8, 8,\n",
      "         8, 8, 8, 0, 8, 8],\n",
      "        [5, 5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8, 7, 8, 8, 8,\n",
      "         8, 8, 0, 8, 8, 8],\n",
      "        [5, 7, 7, 4, 7, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 8, 8, 8, 7, 8, 8, 8, 8,\n",
      "         8, 0, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-4.0194, -3.7784, -3.3900, -3.1589, -2.9301, -2.7430, -2.4835, -2.0802,\n",
      "         -1.6920, -1.3410, -1.3231, -1.2753, -1.1789, -1.0619, -0.9966, -0.8590,\n",
      "         -0.7170, -0.6123, -1.4780, -0.8108, -0.8108, -1.3859, -1.3314, -1.3314,\n",
      "         -1.5635, -1.3314, -0.8108, -1.2488, -1.0534, -1.2654],\n",
      "        [-3.7784, -3.3900, -3.1589, -2.9301, -2.7430, -2.4835, -2.0802, -1.6920,\n",
      "         -1.3410, -1.3231, -1.2753, -1.1789, -1.0619, -0.9966, -0.8590, -0.7170,\n",
      "         -0.6123, -1.4780, -0.8108, -0.8108, -1.3859, -1.3314, -1.3314, -1.5635,\n",
      "         -1.3314, -0.8108, -1.2488, -1.0534, -1.2654, -1.1606],\n",
      "        [-3.3900, -3.1589, -2.9301, -2.7430, -2.4835, -2.0802, -1.6920, -1.3410,\n",
      "         -1.3231, -1.2753, -1.1789, -1.0619, -0.9966, -0.8590, -0.7170, -0.6123,\n",
      "         -1.4780, -0.8108, -0.8108, -1.3859, -1.3314, -1.3314, -1.5635, -1.3314,\n",
      "         -0.8108, -1.2488, -1.0534, -1.2654, -1.1606, -1.5277],\n",
      "        [-3.1589, -2.9301, -2.7430, -2.4835, -2.0802, -1.6920, -1.3410, -1.3231,\n",
      "         -1.2753, -1.1789, -1.0619, -0.9966, -0.8590, -0.7170, -0.6123, -1.4780,\n",
      "         -0.8108, -0.8108, -1.3859, -1.3314, -1.3314, -1.5635, -1.3314, -0.8108,\n",
      "         -1.2488, -1.0534, -1.2654, -1.1606, -1.5277, -1.4427],\n",
      "        [-2.9301, -2.7430, -2.4835, -2.0802, -1.6920, -1.3410, -1.3231, -1.2753,\n",
      "         -1.1789, -1.0619, -0.9966, -0.8590, -0.7170, -0.6123, -1.4780, -0.8108,\n",
      "         -0.8108, -1.3859, -1.3314, -1.3314, -1.5635, -1.3314, -0.8108, -1.2488,\n",
      "         -1.0534, -1.2654, -1.1606, -1.5277, -1.4427, -1.4306],\n",
      "        [-2.7430, -2.4835, -2.0802, -1.6920, -1.3410, -1.3231, -1.2753, -1.1789,\n",
      "         -1.0619, -0.9966, -0.8590, -0.7170, -0.6123, -1.4780, -0.8108, -0.8108,\n",
      "         -1.3859, -1.3314, -1.3314, -1.5635, -1.3314, -0.8108, -1.2488, -1.0534,\n",
      "         -1.2654, -1.1606, -1.5277, -1.4427, -1.4306, -1.1535],\n",
      "        [-2.4835, -2.0802, -1.6920, -1.3410, -1.3231, -1.2753, -1.1789, -1.0619,\n",
      "         -0.9966, -0.8590, -0.7170, -0.6123, -1.4780, -0.8108, -0.8108, -1.3859,\n",
      "         -1.3314, -1.3314, -1.5635, -1.3314, -0.8108, -1.2488, -1.0534, -1.2654,\n",
      "         -1.1606, -1.5277, -1.4427, -1.4306, -1.1535, -0.7036],\n",
      "        [-2.0802, -1.6920, -1.3410, -1.3231, -1.2753, -1.1789, -1.0619, -0.9966,\n",
      "         -0.8590, -0.7170, -0.6123, -1.4780, -0.8108, -0.8108, -1.3859, -1.3314,\n",
      "         -1.3314, -1.5635, -1.3314, -0.8108, -1.2488, -1.0534, -1.2654, -1.1606,\n",
      "         -1.5277, -1.4427, -1.4306, -1.1535, -0.7036, -0.4929],\n",
      "        [-1.6920, -1.3410, -1.3231, -1.2753, -1.1789, -1.0619, -0.9966, -0.8590,\n",
      "         -0.7170, -0.6123, -1.4780, -0.8108, -0.8108, -1.3859, -1.3314, -1.3314,\n",
      "         -1.5635, -1.3314, -0.8108, -1.2488, -1.0534, -1.2654, -1.1606, -1.5277,\n",
      "         -1.4427, -1.4306, -1.1535, -0.7036, -0.4929, -0.4929],\n",
      "        [-1.3410, -1.3231, -1.2753, -1.1789, -1.0619, -0.9966, -0.8590, -0.7170,\n",
      "         -0.6123, -1.4780, -0.8108, -0.8108, -1.3859, -1.3314, -1.3314, -1.5635,\n",
      "         -1.3314, -0.8108, -1.2488, -1.0534, -1.2654, -1.1606, -1.5277, -1.4427,\n",
      "         -1.4306, -1.1535, -0.7036, -0.4929, -0.4929, -0.4929],\n",
      "        [-1.3231, -1.2753, -1.1789, -1.0619, -0.9966, -0.8590, -0.7170, -0.6123,\n",
      "         -1.4780, -0.8108, -0.8108, -1.3859, -1.3314, -1.3314, -1.5635, -1.3314,\n",
      "         -0.8108, -1.2488, -1.0534, -1.2654, -1.1606, -1.5277, -1.4427, -1.4306,\n",
      "         -1.1535, -0.7036, -0.4929, -0.4929, -0.4929, -0.4929],\n",
      "        [-1.2753, -1.1789, -1.0619, -0.9966, -0.8590, -0.7170, -0.6123, -1.4780,\n",
      "         -0.8108, -0.8108, -1.3859, -1.3314, -1.3314, -1.5635, -1.3314, -0.8108,\n",
      "         -1.2488, -1.0534, -1.2654, -1.1606, -1.5277, -1.4427, -1.4306, -1.1535,\n",
      "         -0.7036, -0.4929, -0.4929, -0.4929, -0.4929,  0.4381],\n",
      "        [-1.1789, -1.0619, -0.9966, -0.8590, -0.7170, -0.6123, -1.4780, -0.8108,\n",
      "         -0.8108, -1.3859, -1.3314, -1.3314, -1.5635, -1.3314, -0.8108, -1.2488,\n",
      "         -1.0534, -1.2654, -1.1606, -1.5277, -1.4427, -1.4306, -1.1535, -0.7036,\n",
      "         -0.4929, -0.4929, -0.4929, -0.4929,  0.4381, -0.4929],\n",
      "        [-1.0619, -0.9966, -0.8590, -0.7170, -0.6123, -1.4780, -0.8108, -0.8108,\n",
      "         -1.3859, -1.3314, -1.3314, -1.5635, -1.3314, -0.8108, -1.2488, -1.0534,\n",
      "         -1.2654, -1.1606, -1.5277, -1.4427, -1.4306, -1.1535, -0.7036, -0.4929,\n",
      "         -0.4929, -0.4929, -0.4929,  0.4381, -0.4929, -0.4929],\n",
      "        [-0.9966, -0.8590, -0.7170, -0.6123, -1.4780, -0.8108, -0.8108, -1.3859,\n",
      "         -1.3314, -1.3314, -1.5635, -1.3314, -0.8108, -1.2488, -1.0534, -1.2654,\n",
      "         -1.1606, -1.5277, -1.4427, -1.4306, -1.1535, -0.7036, -0.4929, -0.4929,\n",
      "         -0.4929, -0.4929,  0.4381, -0.4929, -0.4929, -0.7102],\n",
      "        [-0.8590, -0.7170, -0.6123, -1.4780, -0.8108, -0.8108, -1.3859, -1.3314,\n",
      "         -1.3314, -1.5635, -1.3314, -0.8108, -1.2488, -1.0534, -1.2654, -1.1606,\n",
      "         -1.5277, -1.4427, -1.4306, -1.1535, -0.7036, -0.4929, -0.4929, -0.4929,\n",
      "         -0.4929,  0.4381, -0.4929, -0.4929, -0.7102,  0.7462]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8,\n",
      "         0, 8, 8, 7, 2, 3],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0,\n",
      "         8, 8, 7, 2, 3, 0],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8,\n",
      "         8, 7, 2, 3, 0, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8,\n",
      "         7, 2, 3, 0, 7, 0],\n",
      "        [5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7,\n",
      "         2, 3, 0, 7, 0, 1],\n",
      "        [5, 5, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2,\n",
      "         3, 0, 7, 0, 1, 0],\n",
      "        [5, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3,\n",
      "         0, 7, 0, 1, 0, 1],\n",
      "        [5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0,\n",
      "         7, 0, 1, 0, 1, 4],\n",
      "        [5, 6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7,\n",
      "         0, 1, 0, 1, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7, 0,\n",
      "         1, 0, 1, 4, 4, 4],\n",
      "        [6, 6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7, 0, 1,\n",
      "         0, 1, 4, 4, 4, 4],\n",
      "        [6, 6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7, 0, 1, 0,\n",
      "         1, 4, 4, 4, 4, 7],\n",
      "        [6, 6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7, 0, 1, 0, 1,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [6, 7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7, 0, 1, 0, 1, 4,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [7, 6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7, 0, 1, 0, 1, 4, 4,\n",
      "         4, 4, 7, 4, 4, 7],\n",
      "        [6, 6, 7, 7, 8, 8, 7, 8, 8, 0, 8, 8, 7, 2, 3, 0, 7, 0, 1, 0, 1, 4, 4, 4,\n",
      "         4, 7, 4, 4, 7, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.9831, -1.9038, -1.7949, -1.6996, -1.6114, -1.5111, -1.6306, -1.6306,\n",
      "         -1.6306, -1.6306, -1.2090, -1.2297, -1.1925, -1.3383, -1.2187, -1.4844,\n",
      "         -1.4786, -1.5226, -1.2122, -1.1713, -1.0445, -0.8695, -0.6890, -0.4940,\n",
      "         -0.2256, -0.4940, -0.4940, -0.7380,  0.5916, -0.4940],\n",
      "        [-1.9038, -1.7949, -1.6996, -1.6114, -1.5111, -1.6306, -1.6306, -1.6306,\n",
      "         -1.6306, -1.2090, -1.2297, -1.1925, -1.3383, -1.2187, -1.4844, -1.4786,\n",
      "         -1.5226, -1.2122, -1.1713, -1.0445, -0.8695, -0.6890, -0.4940, -0.2256,\n",
      "         -0.4940, -0.4940, -0.7380,  0.5916, -0.4940, -0.4940],\n",
      "        [-1.7949, -1.6996, -1.6114, -1.5111, -1.6306, -1.6306, -1.6306, -1.6306,\n",
      "         -1.2090, -1.2297, -1.1925, -1.3383, -1.2187, -1.4844, -1.4786, -1.5226,\n",
      "         -1.2122, -1.1713, -1.0445, -0.8695, -0.6890, -0.4940, -0.2256, -0.4940,\n",
      "         -0.4940, -0.7380,  0.5916, -0.4940, -0.4940, -0.4940],\n",
      "        [-1.6996, -1.6114, -1.5111, -1.6306, -1.6306, -1.6306, -1.6306, -1.2090,\n",
      "         -1.2297, -1.1925, -1.3383, -1.2187, -1.4844, -1.4786, -1.5226, -1.2122,\n",
      "         -1.1713, -1.0445, -0.8695, -0.6890, -0.4940, -0.2256, -0.4940, -0.4940,\n",
      "         -0.7380,  0.5916, -0.4940, -0.4940, -0.4940, -1.5893],\n",
      "        [-1.6114, -1.5111, -1.6306, -1.6306, -1.6306, -1.6306, -1.2090, -1.2297,\n",
      "         -1.1925, -1.3383, -1.2187, -1.4844, -1.4786, -1.5226, -1.2122, -1.1713,\n",
      "         -1.0445, -0.8695, -0.6890, -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,\n",
      "          0.5916, -0.4940, -0.4940, -0.4940, -1.5893, -1.1553],\n",
      "        [-1.5111, -1.6306, -1.6306, -1.6306, -1.6306, -1.2090, -1.2297, -1.1925,\n",
      "         -1.3383, -1.2187, -1.4844, -1.4786, -1.5226, -1.2122, -1.1713, -1.0445,\n",
      "         -0.8695, -0.6890, -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,  0.5916,\n",
      "         -0.4940, -0.4940, -0.4940, -1.5893, -1.1553, -0.4940],\n",
      "        [-1.6306, -1.6306, -1.6306, -1.6306, -1.2090, -1.2297, -1.1925, -1.3383,\n",
      "         -1.2187, -1.4844, -1.4786, -1.5226, -1.2122, -1.1713, -1.0445, -0.8695,\n",
      "         -0.6890, -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,  0.5916, -0.4940,\n",
      "         -0.4940, -0.4940, -1.5893, -1.1553, -0.4940, -0.4940],\n",
      "        [-1.6306, -1.6306, -1.6306, -1.2090, -1.2297, -1.1925, -1.3383, -1.2187,\n",
      "         -1.4844, -1.4786, -1.5226, -1.2122, -1.1713, -1.0445, -0.8695, -0.6890,\n",
      "         -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,  0.5916, -0.4940, -0.4940,\n",
      "         -0.4940, -1.5893, -1.1553, -0.4940, -0.4940, -0.4940],\n",
      "        [-1.6306, -1.6306, -1.2090, -1.2297, -1.1925, -1.3383, -1.2187, -1.4844,\n",
      "         -1.4786, -1.5226, -1.2122, -1.1713, -1.0445, -0.8695, -0.6890, -0.4940,\n",
      "         -0.2256, -0.4940, -0.4940, -0.7380,  0.5916, -0.4940, -0.4940, -0.4940,\n",
      "         -1.5893, -1.1553, -0.4940, -0.4940, -0.4940, -1.1184],\n",
      "        [-1.6306, -1.2090, -1.2297, -1.1925, -1.3383, -1.2187, -1.4844, -1.4786,\n",
      "         -1.5226, -1.2122, -1.1713, -1.0445, -0.8695, -0.6890, -0.4940, -0.2256,\n",
      "         -0.4940, -0.4940, -0.7380,  0.5916, -0.4940, -0.4940, -0.4940, -1.5893,\n",
      "         -1.1553, -0.4940, -0.4940, -0.4940, -1.1184, -0.3162],\n",
      "        [-1.2090, -1.2297, -1.1925, -1.3383, -1.2187, -1.4844, -1.4786, -1.5226,\n",
      "         -1.2122, -1.1713, -1.0445, -0.8695, -0.6890, -0.4940, -0.2256, -0.4940,\n",
      "         -0.4940, -0.7380,  0.5916, -0.4940, -0.4940, -0.4940, -1.5893, -1.1553,\n",
      "         -0.4940, -0.4940, -0.4940, -1.1184, -0.3162, -0.4940],\n",
      "        [-1.2297, -1.1925, -1.3383, -1.2187, -1.4844, -1.4786, -1.5226, -1.2122,\n",
      "         -1.1713, -1.0445, -0.8695, -0.6890, -0.4940, -0.2256, -0.4940, -0.4940,\n",
      "         -0.7380,  0.5916, -0.4940, -0.4940, -0.4940, -1.5893, -1.1553, -0.4940,\n",
      "         -0.4940, -0.4940, -1.1184, -0.3162, -0.4940, -0.4940],\n",
      "        [-1.1925, -1.3383, -1.2187, -1.4844, -1.4786, -1.5226, -1.2122, -1.1713,\n",
      "         -1.0445, -0.8695, -0.6890, -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,\n",
      "          0.5916, -0.4940, -0.4940, -0.4940, -1.5893, -1.1553, -0.4940, -0.4940,\n",
      "         -0.4940, -1.1184, -0.3162, -0.4940, -0.4940, -0.7543],\n",
      "        [-1.3383, -1.2187, -1.4844, -1.4786, -1.5226, -1.2122, -1.1713, -1.0445,\n",
      "         -0.8695, -0.6890, -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,  0.5916,\n",
      "         -0.4940, -0.4940, -0.4940, -1.5893, -1.1553, -0.4940, -0.4940, -0.4940,\n",
      "         -1.1184, -0.3162, -0.4940, -0.4940, -0.7543, -4.9233],\n",
      "        [-1.2187, -1.4844, -1.4786, -1.5226, -1.2122, -1.1713, -1.0445, -0.8695,\n",
      "         -0.6890, -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,  0.5916, -0.4940,\n",
      "         -0.4940, -0.4940, -1.5893, -1.1553, -0.4940, -0.4940, -0.4940, -1.1184,\n",
      "         -0.3162, -0.4940, -0.4940, -0.7543, -4.9233, -2.7845],\n",
      "        [-1.4844, -1.4786, -1.5226, -1.2122, -1.1713, -1.0445, -0.8695, -0.6890,\n",
      "         -0.4940, -0.2256, -0.4940, -0.4940, -0.7380,  0.5916, -0.4940, -0.4940,\n",
      "         -0.4940, -1.5893, -1.1553, -0.4940, -0.4940, -0.4940, -1.1184, -0.3162,\n",
      "         -0.4940, -0.4940, -0.7543, -4.9233, -2.7845, -2.1752]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 8, 8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4,\n",
      "         5, 4, 4, 7, 7, 4],\n",
      "        [6, 6, 6, 6, 6, 8, 8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5,\n",
      "         4, 4, 7, 7, 4, 4],\n",
      "        [6, 6, 6, 6, 8, 8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4,\n",
      "         4, 7, 7, 4, 4, 4],\n",
      "        [6, 6, 6, 8, 8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4,\n",
      "         7, 7, 4, 4, 4, 7],\n",
      "        [6, 6, 8, 8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7,\n",
      "         7, 4, 4, 4, 7, 7],\n",
      "        [6, 8, 8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7,\n",
      "         4, 4, 4, 7, 7, 4],\n",
      "        [8, 8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4,\n",
      "         4, 4, 7, 7, 4, 4],\n",
      "        [8, 8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4,\n",
      "         4, 7, 7, 4, 4, 4],\n",
      "        [8, 8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4,\n",
      "         7, 7, 4, 4, 4, 7],\n",
      "        [8, 6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4, 7,\n",
      "         7, 4, 4, 4, 7, 8],\n",
      "        [6, 7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4, 7, 7,\n",
      "         4, 4, 4, 7, 8, 4],\n",
      "        [7, 8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4, 7, 7, 4,\n",
      "         4, 4, 7, 8, 4, 4],\n",
      "        [8, 3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4, 7, 7, 4, 4,\n",
      "         4, 7, 8, 4, 4, 8],\n",
      "        [3, 0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4, 7, 7, 4, 4, 4,\n",
      "         7, 8, 4, 4, 8, 7],\n",
      "        [0, 7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4, 7, 7, 4, 4, 4, 7,\n",
      "         8, 4, 4, 8, 7, 7],\n",
      "        [7, 0, 1, 0, 5, 5, 5, 5, 4, 5, 4, 4, 7, 7, 4, 4, 4, 7, 7, 4, 4, 4, 7, 8,\n",
      "         4, 4, 8, 7, 7, 0]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.7915, -3.5418, -3.2985, -3.0321, -2.7586, -2.4715, -2.2456, -2.0183,\n",
      "         -1.7738, -1.5306, -1.3214, -1.0650, -0.8457, -0.6338, -0.4953, -0.4953,\n",
      "         -1.1269, -0.8238, -0.4953, -0.4953, -0.6520, -0.7980, -0.9812, -0.9812,\n",
      "         -0.9812, -1.5343, -3.4560, -2.7950, -2.2917, -1.5343],\n",
      "        [-3.5418, -3.2985, -3.0321, -2.7586, -2.4715, -2.2456, -2.0183, -1.7738,\n",
      "         -1.5306, -1.3214, -1.0650, -0.8457, -0.6338, -0.4953, -0.4953, -1.1269,\n",
      "         -0.8238, -0.4953, -0.4953, -0.6520, -0.7980, -0.9812, -0.9812, -0.9812,\n",
      "         -1.5343, -3.4560, -2.7950, -2.2917, -1.5343, -0.9812],\n",
      "        [-3.2985, -3.0321, -2.7586, -2.4715, -2.2456, -2.0183, -1.7738, -1.5306,\n",
      "         -1.3214, -1.0650, -0.8457, -0.6338, -0.4953, -0.4953, -1.1269, -0.8238,\n",
      "         -0.4953, -0.4953, -0.6520, -0.7980, -0.9812, -0.9812, -0.9812, -1.5343,\n",
      "         -3.4560, -2.7950, -2.2917, -1.5343, -0.9812, -0.4953],\n",
      "        [-3.0321, -2.7586, -2.4715, -2.2456, -2.0183, -1.7738, -1.5306, -1.3214,\n",
      "         -1.0650, -0.8457, -0.6338, -0.4953, -0.4953, -1.1269, -0.8238, -0.4953,\n",
      "         -0.4953, -0.6520, -0.7980, -0.9812, -0.9812, -0.9812, -1.5343, -3.4560,\n",
      "         -2.7950, -2.2917, -1.5343, -0.9812, -0.4953, -0.7151],\n",
      "        [-2.7586, -2.4715, -2.2456, -2.0183, -1.7738, -1.5306, -1.3214, -1.0650,\n",
      "         -0.8457, -0.6338, -0.4953, -0.4953, -1.1269, -0.8238, -0.4953, -0.4953,\n",
      "         -0.6520, -0.7980, -0.9812, -0.9812, -0.9812, -1.5343, -3.4560, -2.7950,\n",
      "         -2.2917, -1.5343, -0.9812, -0.4953, -0.7151, -0.6828],\n",
      "        [-2.4715, -2.2456, -2.0183, -1.7738, -1.5306, -1.3214, -1.0650, -0.8457,\n",
      "         -0.6338, -0.4953, -0.4953, -1.1269, -0.8238, -0.4953, -0.4953, -0.6520,\n",
      "         -0.7980, -0.9812, -0.9812, -0.9812, -1.5343, -3.4560, -2.7950, -2.2917,\n",
      "         -1.5343, -0.9812, -0.4953, -0.7151, -0.6828, -0.4953],\n",
      "        [-2.2456, -2.0183, -1.7738, -1.5306, -1.3214, -1.0650, -0.8457, -0.6338,\n",
      "         -0.4953, -0.4953, -1.1269, -0.8238, -0.4953, -0.4953, -0.6520, -0.7980,\n",
      "         -0.9812, -0.9812, -0.9812, -1.5343, -3.4560, -2.7950, -2.2917, -1.5343,\n",
      "         -0.9812, -0.4953, -0.7151, -0.6828, -0.4953, -0.4953],\n",
      "        [-2.0183, -1.7738, -1.5306, -1.3214, -1.0650, -0.8457, -0.6338, -0.4953,\n",
      "         -0.4953, -1.1269, -0.8238, -0.4953, -0.4953, -0.6520, -0.7980, -0.9812,\n",
      "         -0.9812, -0.9812, -1.5343, -3.4560, -2.7950, -2.2917, -1.5343, -0.9812,\n",
      "         -0.4953, -0.7151, -0.6828, -0.4953, -0.4953,  0.4926],\n",
      "        [-1.7738, -1.5306, -1.3214, -1.0650, -0.8457, -0.6338, -0.4953, -0.4953,\n",
      "         -1.1269, -0.8238, -0.4953, -0.4953, -0.6520, -0.7980, -0.9812, -0.9812,\n",
      "         -0.9812, -1.5343, -3.4560, -2.7950, -2.2917, -1.5343, -0.9812, -0.4953,\n",
      "         -0.7151, -0.6828, -0.4953, -0.4953,  0.4926, -0.4953],\n",
      "        [-1.5306, -1.3214, -1.0650, -0.8457, -0.6338, -0.4953, -0.4953, -1.1269,\n",
      "         -0.8238, -0.4953, -0.4953, -0.6520, -0.7980, -0.9812, -0.9812, -0.9812,\n",
      "         -1.5343, -3.4560, -2.7950, -2.2917, -1.5343, -0.9812, -0.4953, -0.7151,\n",
      "         -0.6828, -0.4953, -0.4953,  0.4926, -0.4953, -0.4953],\n",
      "        [-1.3214, -1.0650, -0.8457, -0.6338, -0.4953, -0.4953, -1.1269, -0.8238,\n",
      "         -0.4953, -0.4953, -0.6520, -0.7980, -0.9812, -0.9812, -0.9812, -1.5343,\n",
      "         -3.4560, -2.7950, -2.2917, -1.5343, -0.9812, -0.4953, -0.7151, -0.6828,\n",
      "         -0.4953, -0.4953,  0.4926, -0.4953, -0.4953, -0.4953],\n",
      "        [-1.0650, -0.8457, -0.6338, -0.4953, -0.4953, -1.1269, -0.8238, -0.4953,\n",
      "         -0.4953, -0.6520, -0.7980, -0.9812, -0.9812, -0.9812, -1.5343, -3.4560,\n",
      "         -2.7950, -2.2917, -1.5343, -0.9812, -0.4953, -0.7151, -0.6828, -0.4953,\n",
      "         -0.4953,  0.4926, -0.4953, -0.4953, -0.4953, -0.4953],\n",
      "        [-0.8457, -0.6338, -0.4953, -0.4953, -1.1269, -0.8238, -0.4953, -0.4953,\n",
      "         -0.6520, -0.7980, -0.9812, -0.9812, -0.9812, -1.5343, -3.4560, -2.7950,\n",
      "         -2.2917, -1.5343, -0.9812, -0.4953, -0.7151, -0.6828, -0.4953, -0.4953,\n",
      "          0.4926, -0.4953, -0.4953, -0.4953, -0.4953,  0.3966],\n",
      "        [-0.6338, -0.4953, -0.4953, -1.1269, -0.8238, -0.4953, -0.4953, -0.6520,\n",
      "         -0.7980, -0.9812, -0.9812, -0.9812, -1.5343, -3.4560, -2.7950, -2.2917,\n",
      "         -1.5343, -0.9812, -0.4953, -0.7151, -0.6828, -0.4953, -0.4953,  0.4926,\n",
      "         -0.4953, -0.4953, -0.4953, -0.4953,  0.3966, -0.4953],\n",
      "        [-0.4953, -0.4953, -1.1269, -0.8238, -0.4953, -0.4953, -0.6520, -0.7980,\n",
      "         -0.9812, -0.9812, -0.9812, -1.5343, -3.4560, -2.7950, -2.2917, -1.5343,\n",
      "         -0.9812, -0.4953, -0.7151, -0.6828, -0.4953, -0.4953,  0.4926, -0.4953,\n",
      "         -0.4953, -0.4953, -0.4953,  0.3966, -0.4953, -0.4953],\n",
      "        [-0.4953, -1.1269, -0.8238, -0.4953, -0.4953, -0.6520, -0.7980, -0.9812,\n",
      "         -0.9812, -0.9812, -1.5343, -3.4560, -2.7950, -2.2917, -1.5343, -0.9812,\n",
      "         -0.4953, -0.7151, -0.6828, -0.4953, -0.4953,  0.4926, -0.4953, -0.4953,\n",
      "         -0.4953, -0.4953,  0.3966, -0.4953, -0.4953, -0.4953]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8,\n",
      "         8, 8, 7, 3, 0, 8],\n",
      "        [6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8,\n",
      "         8, 7, 3, 0, 8, 8],\n",
      "        [6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8,\n",
      "         7, 3, 0, 8, 8, 4],\n",
      "        [6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7,\n",
      "         3, 0, 8, 8, 4, 7],\n",
      "        [6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3,\n",
      "         0, 8, 8, 4, 7, 0],\n",
      "        [6, 5, 6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0,\n",
      "         8, 8, 4, 7, 0, 4],\n",
      "        [5, 6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8,\n",
      "         8, 4, 7, 0, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8,\n",
      "         4, 7, 0, 4, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4,\n",
      "         7, 0, 4, 4, 7, 4],\n",
      "        [6, 6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4, 7,\n",
      "         0, 4, 4, 7, 4, 4],\n",
      "        [6, 6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4, 7, 0,\n",
      "         4, 4, 7, 4, 4, 4],\n",
      "        [6, 6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4, 7, 0, 4,\n",
      "         4, 7, 4, 4, 4, 4],\n",
      "        [6, 6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4, 7, 0, 4, 4,\n",
      "         7, 4, 4, 4, 4, 7],\n",
      "        [6, 4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4, 7, 0, 4, 4, 7,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [4, 4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4, 7, 0, 4, 4, 7, 4,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [4, 7, 7, 4, 4, 2, 7, 8, 8, 8, 8, 7, 3, 0, 8, 8, 4, 7, 0, 4, 4, 7, 4, 4,\n",
      "         4, 4, 7, 4, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.6924, -1.5452, -1.4366, -1.3391, -1.2416, -1.1671, -1.4223, -1.4223,\n",
      "         -1.4223, -2.0000, -4.1578, -2.5108, -2.1209, -2.0000, -1.4223, -0.9290,\n",
      "         -1.0642, -1.1144, -0.8617, -0.7689, -0.6568, -0.5244, -0.5612, -0.4937,\n",
      "         -0.4937, -0.0855, -0.6063, -0.4937, -0.5406, -0.4937],\n",
      "        [-1.5452, -1.4366, -1.3391, -1.2416, -1.1671, -1.4223, -1.4223, -1.4223,\n",
      "         -2.0000, -4.1578, -2.5108, -2.1209, -2.0000, -1.4223, -0.9290, -1.0642,\n",
      "         -1.1144, -0.8617, -0.7689, -0.6568, -0.5244, -0.5612, -0.4937, -0.4937,\n",
      "         -0.0855, -0.6063, -0.4937, -0.5406, -0.4937, -0.2781],\n",
      "        [-1.4366, -1.3391, -1.2416, -1.1671, -1.4223, -1.4223, -1.4223, -2.0000,\n",
      "         -4.1578, -2.5108, -2.1209, -2.0000, -1.4223, -0.9290, -1.0642, -1.1144,\n",
      "         -0.8617, -0.7689, -0.6568, -0.5244, -0.5612, -0.4937, -0.4937, -0.0855,\n",
      "         -0.6063, -0.4937, -0.5406, -0.4937, -0.2781, -0.4937],\n",
      "        [-1.3391, -1.2416, -1.1671, -1.4223, -1.4223, -1.4223, -2.0000, -4.1578,\n",
      "         -2.5108, -2.1209, -2.0000, -1.4223, -0.9290, -1.0642, -1.1144, -0.8617,\n",
      "         -0.7689, -0.6568, -0.5244, -0.5612, -0.4937, -0.4937, -0.0855, -0.6063,\n",
      "         -0.4937, -0.5406, -0.4937, -0.2781, -0.4937, -0.4937],\n",
      "        [-1.2416, -1.1671, -1.4223, -1.4223, -1.4223, -2.0000, -4.1578, -2.5108,\n",
      "         -2.1209, -2.0000, -1.4223, -0.9290, -1.0642, -1.1144, -0.8617, -0.7689,\n",
      "         -0.6568, -0.5244, -0.5612, -0.4937, -0.4937, -0.0855, -0.6063, -0.4937,\n",
      "         -0.5406, -0.4937, -0.2781, -0.4937, -0.4937, -0.4937],\n",
      "        [-1.1671, -1.4223, -1.4223, -1.4223, -2.0000, -4.1578, -2.5108, -2.1209,\n",
      "         -2.0000, -1.4223, -0.9290, -1.0642, -1.1144, -0.8617, -0.7689, -0.6568,\n",
      "         -0.5244, -0.5612, -0.4937, -0.4937, -0.0855, -0.6063, -0.4937, -0.5406,\n",
      "         -0.4937, -0.2781, -0.4937, -0.4937, -0.4937, -0.4937],\n",
      "        [-1.4223, -1.4223, -1.4223, -2.0000, -4.1578, -2.5108, -2.1209, -2.0000,\n",
      "         -1.4223, -0.9290, -1.0642, -1.1144, -0.8617, -0.7689, -0.6568, -0.5244,\n",
      "         -0.5612, -0.4937, -0.4937, -0.0855, -0.6063, -0.4937, -0.5406, -0.4937,\n",
      "         -0.2781, -0.4937, -0.4937, -0.4937, -0.4937,  0.2003],\n",
      "        [-1.4223, -1.4223, -2.0000, -4.1578, -2.5108, -2.1209, -2.0000, -1.4223,\n",
      "         -0.9290, -1.0642, -1.1144, -0.8617, -0.7689, -0.6568, -0.5244, -0.5612,\n",
      "         -0.4937, -0.4937, -0.0855, -0.6063, -0.4937, -0.5406, -0.4937, -0.2781,\n",
      "         -0.4937, -0.4937, -0.4937, -0.4937,  0.2003, -1.1325],\n",
      "        [-1.4223, -2.0000, -4.1578, -2.5108, -2.1209, -2.0000, -1.4223, -0.9290,\n",
      "         -1.0642, -1.1144, -0.8617, -0.7689, -0.6568, -0.5244, -0.5612, -0.4937,\n",
      "         -0.4937, -0.0855, -0.6063, -0.4937, -0.5406, -0.4937, -0.2781, -0.4937,\n",
      "         -0.4937, -0.4937, -0.4937,  0.2003, -1.1325, -0.4937],\n",
      "        [-2.0000, -4.1578, -2.5108, -2.1209, -2.0000, -1.4223, -0.9290, -1.0642,\n",
      "         -1.1144, -0.8617, -0.7689, -0.6568, -0.5244, -0.5612, -0.4937, -0.4937,\n",
      "         -0.0855, -0.6063, -0.4937, -0.5406, -0.4937, -0.2781, -0.4937, -0.4937,\n",
      "         -0.4937, -0.4937,  0.2003, -1.1325, -0.4937, -0.4937],\n",
      "        [-4.1578, -2.5108, -2.1209, -2.0000, -1.4223, -0.9290, -1.0642, -1.1144,\n",
      "         -0.8617, -0.7689, -0.6568, -0.5244, -0.5612, -0.4937, -0.4937, -0.0855,\n",
      "         -0.6063, -0.4937, -0.5406, -0.4937, -0.2781, -0.4937, -0.4937, -0.4937,\n",
      "         -0.4937,  0.2003, -1.1325, -0.4937, -0.4937, -0.4937],\n",
      "        [-2.5108, -2.1209, -2.0000, -1.4223, -0.9290, -1.0642, -1.1144, -0.8617,\n",
      "         -0.7689, -0.6568, -0.5244, -0.5612, -0.4937, -0.4937, -0.0855, -0.6063,\n",
      "         -0.4937, -0.5406, -0.4937, -0.2781, -0.4937, -0.4937, -0.4937, -0.4937,\n",
      "          0.2003, -1.1325, -0.4937, -0.4937, -0.4937, -0.3840],\n",
      "        [-2.1209, -2.0000, -1.4223, -0.9290, -1.0642, -1.1144, -0.8617, -0.7689,\n",
      "         -0.6568, -0.5244, -0.5612, -0.4937, -0.4937, -0.0855, -0.6063, -0.4937,\n",
      "         -0.5406, -0.4937, -0.2781, -0.4937, -0.4937, -0.4937, -0.4937,  0.2003,\n",
      "         -1.1325, -0.4937, -0.4937, -0.4937, -0.3840, -0.4937],\n",
      "        [-2.0000, -1.4223, -0.9290, -1.0642, -1.1144, -0.8617, -0.7689, -0.6568,\n",
      "         -0.5244, -0.5612, -0.4937, -0.4937, -0.0855, -0.6063, -0.4937, -0.5406,\n",
      "         -0.4937, -0.2781, -0.4937, -0.4937, -0.4937, -0.4937,  0.2003, -1.1325,\n",
      "         -0.4937, -0.4937, -0.4937, -0.3840, -0.4937, -0.6353],\n",
      "        [-1.4223, -0.9290, -1.0642, -1.1144, -0.8617, -0.7689, -0.6568, -0.5244,\n",
      "         -0.5612, -0.4937, -0.4937, -0.0855, -0.6063, -0.4937, -0.5406, -0.4937,\n",
      "         -0.2781, -0.4937, -0.4937, -0.4937, -0.4937,  0.2003, -1.1325, -0.4937,\n",
      "         -0.4937, -0.4937, -0.3840, -0.4937, -0.6353, -0.4937],\n",
      "        [-0.9290, -1.0642, -1.1144, -0.8617, -0.7689, -0.6568, -0.5244, -0.5612,\n",
      "         -0.4937, -0.4937, -0.0855, -0.6063, -0.4937, -0.5406, -0.4937, -0.2781,\n",
      "         -0.4937, -0.4937, -0.4937, -0.4937,  0.2003, -1.1325, -0.4937, -0.4937,\n",
      "         -0.4937, -0.3840, -0.4937, -0.6353, -0.4937, -0.4937]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 3, 8, 8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4,\n",
      "         4, 6, 7, 4, 7, 4],\n",
      "        [6, 6, 6, 6, 3, 8, 8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4,\n",
      "         6, 7, 4, 7, 4, 7],\n",
      "        [6, 6, 6, 3, 8, 8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6,\n",
      "         7, 4, 7, 4, 7, 4],\n",
      "        [6, 6, 3, 8, 8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [6, 3, 8, 8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4,\n",
      "         7, 4, 7, 4, 4, 4],\n",
      "        [3, 8, 8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7,\n",
      "         4, 7, 4, 4, 4, 4],\n",
      "        [8, 8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4,\n",
      "         7, 4, 4, 4, 4, 7],\n",
      "        [8, 8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7,\n",
      "         4, 4, 4, 4, 7, 7],\n",
      "        [8, 8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4,\n",
      "         4, 4, 4, 7, 7, 4],\n",
      "        [8, 7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4, 4,\n",
      "         4, 4, 7, 7, 4, 4],\n",
      "        [7, 3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4, 4, 4,\n",
      "         4, 7, 7, 4, 4, 4],\n",
      "        [3, 0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4, 4, 4, 4,\n",
      "         7, 7, 4, 4, 4, 7],\n",
      "        [0, 8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7,\n",
      "         7, 4, 4, 4, 7, 4],\n",
      "        [8, 8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 7,\n",
      "         4, 4, 4, 7, 4, 7],\n",
      "        [8, 5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 7, 4,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [5, 1, 0, 5, 5, 5, 5, 7, 4, 4, 6, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 7, 4, 4,\n",
      "         4, 7, 4, 7, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-4.1684, -4.3421, -3.5215, -3.0496, -2.2081, -1.7649, -1.9293, -1.6044,\n",
      "         -1.6371, -1.5043, -1.5541, -1.1838, -1.0945, -0.9849, -0.9228, -0.8791,\n",
      "         -0.8791, -0.8791, -0.8791, -0.8791, -2.2775, -0.8791, -0.8791, -0.4947,\n",
      "         -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,  0.5889],\n",
      "        [-4.3421, -3.5215, -3.0496, -2.2081, -1.7649, -1.9293, -1.6044, -1.6371,\n",
      "         -1.5043, -1.5541, -1.1838, -1.0945, -0.9849, -0.9228, -0.8791, -0.8791,\n",
      "         -0.8791, -0.8791, -0.8791, -2.2775, -0.8791, -0.8791, -0.4947, -0.6687,\n",
      "         -0.4947, -1.2087, -0.4947, -0.4947,  0.5889, -1.7943],\n",
      "        [-3.5215, -3.0496, -2.2081, -1.7649, -1.9293, -1.6044, -1.6371, -1.5043,\n",
      "         -1.5541, -1.1838, -1.0945, -0.9849, -0.9228, -0.8791, -0.8791, -0.8791,\n",
      "         -0.8791, -0.8791, -2.2775, -0.8791, -0.8791, -0.4947, -0.6687, -0.4947,\n",
      "         -1.2087, -0.4947, -0.4947,  0.5889, -1.7943, -0.4947],\n",
      "        [-3.0496, -2.2081, -1.7649, -1.9293, -1.6044, -1.6371, -1.5043, -1.5541,\n",
      "         -1.1838, -1.0945, -0.9849, -0.9228, -0.8791, -0.8791, -0.8791, -0.8791,\n",
      "         -0.8791, -2.2775, -0.8791, -0.8791, -0.4947, -0.6687, -0.4947, -1.2087,\n",
      "         -0.4947, -0.4947,  0.5889, -1.7943, -0.4947, -0.4947],\n",
      "        [-2.2081, -1.7649, -1.9293, -1.6044, -1.6371, -1.5043, -1.5541, -1.1838,\n",
      "         -1.0945, -0.9849, -0.9228, -0.8791, -0.8791, -0.8791, -0.8791, -0.8791,\n",
      "         -2.2775, -0.8791, -0.8791, -0.4947, -0.6687, -0.4947, -1.2087, -0.4947,\n",
      "         -0.4947,  0.5889, -1.7943, -0.4947, -0.4947, -0.4947],\n",
      "        [-1.7649, -1.9293, -1.6044, -1.6371, -1.5043, -1.5541, -1.1838, -1.0945,\n",
      "         -0.9849, -0.9228, -0.8791, -0.8791, -0.8791, -0.8791, -0.8791, -2.2775,\n",
      "         -0.8791, -0.8791, -0.4947, -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,\n",
      "          0.5889, -1.7943, -0.4947, -0.4947, -0.4947, -0.8791],\n",
      "        [-1.9293, -1.6044, -1.6371, -1.5043, -1.5541, -1.1838, -1.0945, -0.9849,\n",
      "         -0.9228, -0.8791, -0.8791, -0.8791, -0.8791, -0.8791, -2.2775, -0.8791,\n",
      "         -0.8791, -0.4947, -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,  0.5889,\n",
      "         -1.7943, -0.4947, -0.4947, -0.4947, -0.8791, -0.4947],\n",
      "        [-1.6044, -1.6371, -1.5043, -1.5541, -1.1838, -1.0945, -0.9849, -0.9228,\n",
      "         -0.8791, -0.8791, -0.8791, -0.8791, -0.8791, -2.2775, -0.8791, -0.8791,\n",
      "         -0.4947, -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,  0.5889, -1.7943,\n",
      "         -0.4947, -0.4947, -0.4947, -0.8791, -0.4947, -2.1070],\n",
      "        [-1.6371, -1.5043, -1.5541, -1.1838, -1.0945, -0.9849, -0.9228, -0.8791,\n",
      "         -0.8791, -0.8791, -0.8791, -0.8791, -2.2775, -0.8791, -0.8791, -0.4947,\n",
      "         -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,  0.5889, -1.7943, -0.4947,\n",
      "         -0.4947, -0.4947, -0.8791, -0.4947, -2.1070, -0.8791],\n",
      "        [-1.5043, -1.5541, -1.1838, -1.0945, -0.9849, -0.9228, -0.8791, -0.8791,\n",
      "         -0.8791, -0.8791, -0.8791, -2.2775, -0.8791, -0.8791, -0.4947, -0.6687,\n",
      "         -0.4947, -1.2087, -0.4947, -0.4947,  0.5889, -1.7943, -0.4947, -0.4947,\n",
      "         -0.4947, -0.8791, -0.4947, -2.1070, -0.8791, -2.3329],\n",
      "        [-1.5541, -1.1838, -1.0945, -0.9849, -0.9228, -0.8791, -0.8791, -0.8791,\n",
      "         -0.8791, -0.8791, -2.2775, -0.8791, -0.8791, -0.4947, -0.6687, -0.4947,\n",
      "         -1.2087, -0.4947, -0.4947,  0.5889, -1.7943, -0.4947, -0.4947, -0.4947,\n",
      "         -0.8791, -0.4947, -2.1070, -0.8791, -2.3329, -0.8791],\n",
      "        [-1.1838, -1.0945, -0.9849, -0.9228, -0.8791, -0.8791, -0.8791, -0.8791,\n",
      "         -0.8791, -2.2775, -0.8791, -0.8791, -0.4947, -0.6687, -0.4947, -1.2087,\n",
      "         -0.4947, -0.4947,  0.5889, -1.7943, -0.4947, -0.4947, -0.4947, -0.8791,\n",
      "         -0.4947, -2.1070, -0.8791, -2.3329, -0.8791, -0.8791],\n",
      "        [-1.0945, -0.9849, -0.9228, -0.8791, -0.8791, -0.8791, -0.8791, -0.8791,\n",
      "         -2.2775, -0.8791, -0.8791, -0.4947, -0.6687, -0.4947, -1.2087, -0.4947,\n",
      "         -0.4947,  0.5889, -1.7943, -0.4947, -0.4947, -0.4947, -0.8791, -0.4947,\n",
      "         -2.1070, -0.8791, -2.3329, -0.8791, -0.8791, -0.8791],\n",
      "        [-0.9849, -0.9228, -0.8791, -0.8791, -0.8791, -0.8791, -0.8791, -2.2775,\n",
      "         -0.8791, -0.8791, -0.4947, -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,\n",
      "          0.5889, -1.7943, -0.4947, -0.4947, -0.4947, -0.8791, -0.4947, -2.1070,\n",
      "         -0.8791, -2.3329, -0.8791, -0.8791, -0.8791, -2.3329],\n",
      "        [-0.9228, -0.8791, -0.8791, -0.8791, -0.8791, -0.8791, -2.2775, -0.8791,\n",
      "         -0.8791, -0.4947, -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,  0.5889,\n",
      "         -1.7943, -0.4947, -0.4947, -0.4947, -0.8791, -0.4947, -2.1070, -0.8791,\n",
      "         -2.3329, -0.8791, -0.8791, -0.8791, -2.3329, -2.3329],\n",
      "        [-0.8791, -0.8791, -0.8791, -0.8791, -0.8791, -2.2775, -0.8791, -0.8791,\n",
      "         -0.4947, -0.6687, -0.4947, -1.2087, -0.4947, -0.4947,  0.5889, -1.7943,\n",
      "         -0.4947, -0.4947, -0.4947, -0.8791, -0.4947, -2.1070, -0.8791, -2.3329,\n",
      "         -0.8791, -0.8791, -0.8791, -2.3329, -2.3329, -2.3329]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[3, 0, 0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4,\n",
      "         7, 4, 7, 4, 4, 6],\n",
      "        [0, 0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7,\n",
      "         4, 7, 4, 4, 6, 7],\n",
      "        [0, 0, 0, 1, 3, 1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4,\n",
      "         7, 4, 4, 6, 7, 4],\n",
      "        [0, 0, 1, 3, 1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7,\n",
      "         4, 4, 6, 7, 4, 4],\n",
      "        [0, 1, 3, 1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4,\n",
      "         4, 6, 7, 4, 4, 4],\n",
      "        [1, 3, 1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4,\n",
      "         6, 7, 4, 4, 4, 8],\n",
      "        [3, 1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6,\n",
      "         7, 4, 4, 4, 8, 4],\n",
      "        [1, 3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7,\n",
      "         4, 4, 4, 8, 4, 7],\n",
      "        [3, 0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4,\n",
      "         4, 4, 8, 4, 7, 8],\n",
      "        [0, 3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4, 4,\n",
      "         4, 8, 4, 7, 8, 8],\n",
      "        [3, 0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4, 4, 4,\n",
      "         8, 4, 7, 8, 8, 8],\n",
      "        [0, 3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4, 4, 4, 8,\n",
      "         4, 7, 8, 8, 8, 8],\n",
      "        [3, 0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4, 4, 4, 8, 4,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [0, 1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4, 4, 4, 8, 4, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [1, 8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4, 4, 4, 8, 4, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [8, 8, 8, 8, 8, 7, 8, 8, 4, 7, 4, 7, 4, 4, 6, 7, 4, 4, 4, 8, 4, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.0105, -2.7168, -2.3675, -2.2216, -2.3702, -2.7304, -2.2702, -1.7058,\n",
      "         -1.5637, -1.4345, -1.3246, -1.2301, -1.1166, -0.9927, -1.0069, -0.7399,\n",
      "         -0.6231, -0.5180, -0.4014, -0.4936, -1.2110, -0.4936, -1.0730, -0.0562,\n",
      "         -0.4936, -0.7894, -1.0730, -1.0730, -1.0730, -0.4936],\n",
      "        [-2.7168, -2.3675, -2.2216, -2.3702, -2.7304, -2.2702, -1.7058, -1.5637,\n",
      "         -1.4345, -1.3246, -1.2301, -1.1166, -0.9927, -1.0069, -0.7399, -0.6231,\n",
      "         -0.5180, -0.4014, -0.4936, -1.2110, -0.4936, -1.0730, -0.0562, -0.4936,\n",
      "         -0.7894, -1.0730, -1.0730, -1.0730, -0.4936, -0.7216],\n",
      "        [-2.3675, -2.2216, -2.3702, -2.7304, -2.2702, -1.7058, -1.5637, -1.4345,\n",
      "         -1.3246, -1.2301, -1.1166, -0.9927, -1.0069, -0.7399, -0.6231, -0.5180,\n",
      "         -0.4014, -0.4936, -1.2110, -0.4936, -1.0730, -0.0562, -0.4936, -0.7894,\n",
      "         -1.0730, -1.0730, -1.0730, -0.4936, -0.7216, -3.6982],\n",
      "        [-2.2216, -2.3702, -2.7304, -2.2702, -1.7058, -1.5637, -1.4345, -1.3246,\n",
      "         -1.2301, -1.1166, -0.9927, -1.0069, -0.7399, -0.6231, -0.5180, -0.4014,\n",
      "         -0.4936, -1.2110, -0.4936, -1.0730, -0.0562, -0.4936, -0.7894, -1.0730,\n",
      "         -1.0730, -1.0730, -0.4936, -0.7216, -3.6982, -3.2560],\n",
      "        [-2.3702, -2.7304, -2.2702, -1.7058, -1.5637, -1.4345, -1.3246, -1.2301,\n",
      "         -1.1166, -0.9927, -1.0069, -0.7399, -0.6231, -0.5180, -0.4014, -0.4936,\n",
      "         -1.2110, -0.4936, -1.0730, -0.0562, -0.4936, -0.7894, -1.0730, -1.0730,\n",
      "         -1.0730, -0.4936, -0.7216, -3.6982, -3.2560, -1.9106],\n",
      "        [-2.7304, -2.2702, -1.7058, -1.5637, -1.4345, -1.3246, -1.2301, -1.1166,\n",
      "         -0.9927, -1.0069, -0.7399, -0.6231, -0.5180, -0.4014, -0.4936, -1.2110,\n",
      "         -0.4936, -1.0730, -0.0562, -0.4936, -0.7894, -1.0730, -1.0730, -1.0730,\n",
      "         -0.4936, -0.7216, -3.6982, -3.2560, -1.9106, -2.0898],\n",
      "        [-2.2702, -1.7058, -1.5637, -1.4345, -1.3246, -1.2301, -1.1166, -0.9927,\n",
      "         -1.0069, -0.7399, -0.6231, -0.5180, -0.4014, -0.4936, -1.2110, -0.4936,\n",
      "         -1.0730, -0.0562, -0.4936, -0.7894, -1.0730, -1.0730, -1.0730, -0.4936,\n",
      "         -0.7216, -3.6982, -3.2560, -1.9106, -2.0898, -1.2084],\n",
      "        [-1.7058, -1.5637, -1.4345, -1.3246, -1.2301, -1.1166, -0.9927, -1.0069,\n",
      "         -0.7399, -0.6231, -0.5180, -0.4014, -0.4936, -1.2110, -0.4936, -1.0730,\n",
      "         -0.0562, -0.4936, -0.7894, -1.0730, -1.0730, -1.0730, -0.4936, -0.7216,\n",
      "         -3.6982, -3.2560, -1.9106, -2.0898, -1.2084, -0.4936],\n",
      "        [-1.5637, -1.4345, -1.3246, -1.2301, -1.1166, -0.9927, -1.0069, -0.7399,\n",
      "         -0.6231, -0.5180, -0.4014, -0.4936, -1.2110, -0.4936, -1.0730, -0.0562,\n",
      "         -0.4936, -0.7894, -1.0730, -1.0730, -1.0730, -0.4936, -0.7216, -3.6982,\n",
      "         -3.2560, -1.9106, -2.0898, -1.2084, -0.4936, -1.0730],\n",
      "        [-1.4345, -1.3246, -1.2301, -1.1166, -0.9927, -1.0069, -0.7399, -0.6231,\n",
      "         -0.5180, -0.4014, -0.4936, -1.2110, -0.4936, -1.0730, -0.0562, -0.4936,\n",
      "         -0.7894, -1.0730, -1.0730, -1.0730, -0.4936, -0.7216, -3.6982, -3.2560,\n",
      "         -1.9106, -2.0898, -1.2084, -0.4936, -1.0730, -2.0898],\n",
      "        [-1.3246, -1.2301, -1.1166, -0.9927, -1.0069, -0.7399, -0.6231, -0.5180,\n",
      "         -0.4014, -0.4936, -1.2110, -0.4936, -1.0730, -0.0562, -0.4936, -0.7894,\n",
      "         -1.0730, -1.0730, -1.0730, -0.4936, -0.7216, -3.6982, -3.2560, -1.9106,\n",
      "         -2.0898, -1.2084, -0.4936, -1.0730, -2.0898, -1.0730],\n",
      "        [-1.2301, -1.1166, -0.9927, -1.0069, -0.7399, -0.6231, -0.5180, -0.4014,\n",
      "         -0.4936, -1.2110, -0.4936, -1.0730, -0.0562, -0.4936, -0.7894, -1.0730,\n",
      "         -1.0730, -1.0730, -0.4936, -0.7216, -3.6982, -3.2560, -1.9106, -2.0898,\n",
      "         -1.2084, -0.4936, -1.0730, -2.0898, -1.0730, -0.4936],\n",
      "        [-1.1166, -0.9927, -1.0069, -0.7399, -0.6231, -0.5180, -0.4014, -0.4936,\n",
      "         -1.2110, -0.4936, -1.0730, -0.0562, -0.4936, -0.7894, -1.0730, -1.0730,\n",
      "         -1.0730, -0.4936, -0.7216, -3.6982, -3.2560, -1.9106, -2.0898, -1.2084,\n",
      "         -0.4936, -1.0730, -2.0898, -1.0730, -0.4936, -0.9758],\n",
      "        [-0.9927, -1.0069, -0.7399, -0.6231, -0.5180, -0.4014, -0.4936, -1.2110,\n",
      "         -0.4936, -1.0730, -0.0562, -0.4936, -0.7894, -1.0730, -1.0730, -1.0730,\n",
      "         -0.4936, -0.7216, -3.6982, -3.2560, -1.9106, -2.0898, -1.2084, -0.4936,\n",
      "         -1.0730, -2.0898, -1.0730, -0.4936, -0.9758, -1.3711],\n",
      "        [-1.0069, -0.7399, -0.6231, -0.5180, -0.4014, -0.4936, -1.2110, -0.4936,\n",
      "         -1.0730, -0.0562, -0.4936, -0.7894, -1.0730, -1.0730, -1.0730, -0.4936,\n",
      "         -0.7216, -3.6982, -3.2560, -1.9106, -2.0898, -1.2084, -0.4936, -1.0730,\n",
      "         -2.0898, -1.0730, -0.4936, -0.9758, -1.3711, -2.0898],\n",
      "        [-0.7399, -0.6231, -0.5180, -0.4014, -0.4936, -1.2110, -0.4936, -1.0730,\n",
      "         -0.0562, -0.4936, -0.7894, -1.0730, -1.0730, -1.0730, -0.4936, -0.7216,\n",
      "         -3.6982, -3.2560, -1.9106, -2.0898, -1.2084, -0.4936, -1.0730, -2.0898,\n",
      "         -1.0730, -0.4936, -0.9758, -1.3711, -2.0898, -2.0898]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[1, 1, 5, 5, 3, 1, 1, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8,\n",
      "         4, 1, 8, 8, 8, 4],\n",
      "        [1, 5, 5, 3, 1, 1, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4,\n",
      "         1, 8, 8, 8, 4, 7],\n",
      "        [5, 5, 3, 1, 1, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1,\n",
      "         8, 8, 8, 4, 7, 7],\n",
      "        [5, 3, 1, 1, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8,\n",
      "         8, 8, 4, 7, 7, 0],\n",
      "        [3, 1, 1, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8,\n",
      "         8, 4, 7, 7, 0, 3],\n",
      "        [1, 1, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8,\n",
      "         4, 7, 7, 0, 3, 8],\n",
      "        [1, 5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4,\n",
      "         7, 7, 0, 3, 8, 0],\n",
      "        [5, 5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7,\n",
      "         7, 0, 3, 8, 0, 4],\n",
      "        [5, 6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7,\n",
      "         0, 3, 8, 0, 4, 8],\n",
      "        [6, 6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7, 0,\n",
      "         3, 8, 0, 4, 8, 8],\n",
      "        [6, 6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7, 0, 3,\n",
      "         8, 0, 4, 8, 8, 8],\n",
      "        [6, 6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7, 0, 3, 8,\n",
      "         0, 4, 8, 8, 8, 4],\n",
      "        [6, 6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7, 0, 3, 8, 0,\n",
      "         4, 8, 8, 8, 4, 7],\n",
      "        [6, 7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7, 0, 3, 8, 0, 4,\n",
      "         8, 8, 8, 4, 7, 7],\n",
      "        [7, 6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7, 0, 3, 8, 0, 4, 8,\n",
      "         8, 8, 4, 7, 7, 8],\n",
      "        [6, 6, 6, 6, 4, 7, 4, 8, 8, 4, 1, 8, 8, 8, 4, 7, 7, 0, 3, 8, 0, 4, 8, 8,\n",
      "         8, 4, 7, 7, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.5384, -2.3778, -2.2173, -2.0502, -1.9196, -1.7969, -1.6729, -1.5427,\n",
      "         -1.4234, -1.3513, -1.1991, -1.0702, -0.9258, -0.7833, -0.6929, -3.0701,\n",
      "         -2.9592, -2.0076, -1.7931, -1.4541, -0.6676, -0.4234, -0.9170, -0.4947,\n",
      "         -0.4947, -0.7912, -1.1221, -0.9170, -0.9170, -1.1481],\n",
      "        [-2.3778, -2.2173, -2.0502, -1.9196, -1.7969, -1.6729, -1.5427, -1.4234,\n",
      "         -1.3513, -1.1991, -1.0702, -0.9258, -0.7833, -0.6929, -3.0701, -2.9592,\n",
      "         -2.0076, -1.7931, -1.4541, -0.6676, -0.4234, -0.9170, -0.4947, -0.4947,\n",
      "         -0.7912, -1.1221, -0.9170, -0.9170, -1.1481, -0.4947],\n",
      "        [-2.2173, -2.0502, -1.9196, -1.7969, -1.6729, -1.5427, -1.4234, -1.3513,\n",
      "         -1.1991, -1.0702, -0.9258, -0.7833, -0.6929, -3.0701, -2.9592, -2.0076,\n",
      "         -1.7931, -1.4541, -0.6676, -0.4234, -0.9170, -0.4947, -0.4947, -0.7912,\n",
      "         -1.1221, -0.9170, -0.9170, -1.1481, -0.4947, -0.2743],\n",
      "        [-2.0502, -1.9196, -1.7969, -1.6729, -1.5427, -1.4234, -1.3513, -1.1991,\n",
      "         -1.0702, -0.9258, -0.7833, -0.6929, -3.0701, -2.9592, -2.0076, -1.7931,\n",
      "         -1.4541, -0.6676, -0.4234, -0.9170, -0.4947, -0.4947, -0.7912, -1.1221,\n",
      "         -0.9170, -0.9170, -1.1481, -0.4947, -0.2743, -0.4947],\n",
      "        [-1.9196, -1.7969, -1.6729, -1.5427, -1.4234, -1.3513, -1.1991, -1.0702,\n",
      "         -0.9258, -0.7833, -0.6929, -3.0701, -2.9592, -2.0076, -1.7931, -1.4541,\n",
      "         -0.6676, -0.4234, -0.9170, -0.4947, -0.4947, -0.7912, -1.1221, -0.9170,\n",
      "         -0.9170, -1.1481, -0.4947, -0.2743, -0.4947, -0.9170],\n",
      "        [-1.7969, -1.6729, -1.5427, -1.4234, -1.3513, -1.1991, -1.0702, -0.9258,\n",
      "         -0.7833, -0.6929, -3.0701, -2.9592, -2.0076, -1.7931, -1.4541, -0.6676,\n",
      "         -0.4234, -0.9170, -0.4947, -0.4947, -0.7912, -1.1221, -0.9170, -0.9170,\n",
      "         -1.1481, -0.4947, -0.2743, -0.4947, -0.9170, -0.9170],\n",
      "        [-1.6729, -1.5427, -1.4234, -1.3513, -1.1991, -1.0702, -0.9258, -0.7833,\n",
      "         -0.6929, -3.0701, -2.9592, -2.0076, -1.7931, -1.4541, -0.6676, -0.4234,\n",
      "         -0.9170, -0.4947, -0.4947, -0.7912, -1.1221, -0.9170, -0.9170, -1.1481,\n",
      "         -0.4947, -0.2743, -0.4947, -0.9170, -0.9170, -0.9170],\n",
      "        [-1.5427, -1.4234, -1.3513, -1.1991, -1.0702, -0.9258, -0.7833, -0.6929,\n",
      "         -3.0701, -2.9592, -2.0076, -1.7931, -1.4541, -0.6676, -0.4234, -0.9170,\n",
      "         -0.4947, -0.4947, -0.7912, -1.1221, -0.9170, -0.9170, -1.1481, -0.4947,\n",
      "         -0.2743, -0.4947, -0.9170, -0.9170, -0.9170, -0.9170],\n",
      "        [-1.4234, -1.3513, -1.1991, -1.0702, -0.9258, -0.7833, -0.6929, -3.0701,\n",
      "         -2.9592, -2.0076, -1.7931, -1.4541, -0.6676, -0.4234, -0.9170, -0.4947,\n",
      "         -0.4947, -0.7912, -1.1221, -0.9170, -0.9170, -1.1481, -0.4947, -0.2743,\n",
      "         -0.4947, -0.9170, -0.9170, -0.9170, -0.9170, -1.8898],\n",
      "        [-1.3513, -1.1991, -1.0702, -0.9258, -0.7833, -0.6929, -3.0701, -2.9592,\n",
      "         -2.0076, -1.7931, -1.4541, -0.6676, -0.4234, -0.9170, -0.4947, -0.4947,\n",
      "         -0.7912, -1.1221, -0.9170, -0.9170, -1.1481, -0.4947, -0.2743, -0.4947,\n",
      "         -0.9170, -0.9170, -0.9170, -0.9170, -1.8898, -1.9443],\n",
      "        [-1.1991, -1.0702, -0.9258, -0.7833, -0.6929, -3.0701, -2.9592, -2.0076,\n",
      "         -1.7931, -1.4541, -0.6676, -0.4234, -0.9170, -0.4947, -0.4947, -0.7912,\n",
      "         -1.1221, -0.9170, -0.9170, -1.1481, -0.4947, -0.2743, -0.4947, -0.9170,\n",
      "         -0.9170, -0.9170, -0.9170, -1.8898, -1.9443, -2.9716],\n",
      "        [-1.0702, -0.9258, -0.7833, -0.6929, -3.0701, -2.9592, -2.0076, -1.7931,\n",
      "         -1.4541, -0.6676, -0.4234, -0.9170, -0.4947, -0.4947, -0.7912, -1.1221,\n",
      "         -0.9170, -0.9170, -1.1481, -0.4947, -0.2743, -0.4947, -0.9170, -0.9170,\n",
      "         -0.9170, -0.9170, -1.8898, -1.9443, -2.9716, -2.9716],\n",
      "        [-0.9258, -0.7833, -0.6929, -3.0701, -2.9592, -2.0076, -1.7931, -1.4541,\n",
      "         -0.6676, -0.4234, -0.9170, -0.4947, -0.4947, -0.7912, -1.1221, -0.9170,\n",
      "         -0.9170, -1.1481, -0.4947, -0.2743, -0.4947, -0.9170, -0.9170, -0.9170,\n",
      "         -0.9170, -1.8898, -1.9443, -2.9716, -2.9716, -1.9443],\n",
      "        [-0.7833, -0.6929, -3.0701, -2.9592, -2.0076, -1.7931, -1.4541, -0.6676,\n",
      "         -0.4234, -0.9170, -0.4947, -0.4947, -0.7912, -1.1221, -0.9170, -0.9170,\n",
      "         -1.1481, -0.4947, -0.2743, -0.4947, -0.9170, -0.9170, -0.9170, -0.9170,\n",
      "         -1.8898, -1.9443, -2.9716, -2.9716, -1.9443, -2.9716],\n",
      "        [-0.6929, -3.0701, -2.9592, -2.0076, -1.7931, -1.4541, -0.6676, -0.4234,\n",
      "         -0.9170, -0.4947, -0.4947, -0.7912, -1.1221, -0.9170, -0.9170, -1.1481,\n",
      "         -0.4947, -0.2743, -0.4947, -0.9170, -0.9170, -0.9170, -0.9170, -1.8898,\n",
      "         -1.9443, -2.9716, -2.9716, -1.9443, -2.9716, -2.9716],\n",
      "        [-3.0701, -2.9592, -2.0076, -1.7931, -1.4541, -0.6676, -0.4234, -0.9170,\n",
      "         -0.4947, -0.4947, -0.7912, -1.1221, -0.9170, -0.9170, -1.1481, -0.4947,\n",
      "         -0.2743, -0.4947, -0.9170, -0.9170, -0.9170, -0.9170, -1.8898, -1.9443,\n",
      "         -2.9716, -2.9716, -1.9443, -2.9716, -2.9716, -1.9443]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4,\n",
      "         4, 7, 7, 8, 8, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4,\n",
      "         7, 7, 8, 8, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7,\n",
      "         7, 8, 8, 7, 4, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7,\n",
      "         8, 8, 7, 4, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8,\n",
      "         8, 7, 4, 7, 4, 8],\n",
      "        [5, 5, 5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8,\n",
      "         7, 4, 7, 4, 8, 8],\n",
      "        [5, 5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7,\n",
      "         4, 7, 4, 8, 8, 8],\n",
      "        [5, 5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4,\n",
      "         7, 4, 8, 8, 8, 8],\n",
      "        [5, 1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7,\n",
      "         4, 8, 8, 8, 8, 7],\n",
      "        [1, 5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7, 4,\n",
      "         8, 8, 8, 8, 7, 8],\n",
      "        [5, 5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7, 4, 8,\n",
      "         8, 8, 8, 7, 8, 8],\n",
      "        [5, 5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7, 4, 8, 8,\n",
      "         8, 8, 7, 8, 8, 8],\n",
      "        [5, 6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7, 4, 8, 8, 8,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [6, 6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7, 4, 8, 8, 8, 8,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [6, 7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7, 4, 8, 8, 8, 8, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [7, 0, 3, 1, 0, 1, 3, 8, 4, 4, 7, 7, 8, 8, 7, 4, 7, 4, 8, 8, 8, 8, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.9210, -2.8584, -2.7759, -2.6067, -2.4485, -2.3063, -2.1609, -1.9567,\n",
      "         -1.7064, -1.5033, -1.3727, -1.2602, -1.1225, -1.3176, -0.8753, -0.7448,\n",
      "         -0.6382, -0.4928, -0.4928, -0.4928,  0.0246, -2.2194, -0.4928, -1.1574,\n",
      "         -1.1574, -1.0654, -1.1574, -1.1574, -0.4928, -1.1574],\n",
      "        [-2.8584, -2.7759, -2.6067, -2.4485, -2.3063, -2.1609, -1.9567, -1.7064,\n",
      "         -1.5033, -1.3727, -1.2602, -1.1225, -1.3176, -0.8753, -0.7448, -0.6382,\n",
      "         -0.4928, -0.4928, -0.4928,  0.0246, -2.2194, -0.4928, -1.1574, -1.1574,\n",
      "         -1.0654, -1.1574, -1.1574, -0.4928, -1.1574, -0.3745],\n",
      "        [-2.7759, -2.6067, -2.4485, -2.3063, -2.1609, -1.9567, -1.7064, -1.5033,\n",
      "         -1.3727, -1.2602, -1.1225, -1.3176, -0.8753, -0.7448, -0.6382, -0.4928,\n",
      "         -0.4928, -0.4928,  0.0246, -2.2194, -0.4928, -1.1574, -1.1574, -1.0654,\n",
      "         -1.1574, -1.1574, -0.4928, -1.1574, -0.3745, -0.6799],\n",
      "        [-2.6067, -2.4485, -2.3063, -2.1609, -1.9567, -1.7064, -1.5033, -1.3727,\n",
      "         -1.2602, -1.1225, -1.3176, -0.8753, -0.7448, -0.6382, -0.4928, -0.4928,\n",
      "         -0.4928,  0.0246, -2.2194, -0.4928, -1.1574, -1.1574, -1.0654, -1.1574,\n",
      "         -1.1574, -0.4928, -1.1574, -0.3745, -0.6799, -0.8659],\n",
      "        [-2.4485, -2.3063, -2.1609, -1.9567, -1.7064, -1.5033, -1.3727, -1.2602,\n",
      "         -1.1225, -1.3176, -0.8753, -0.7448, -0.6382, -0.4928, -0.4928, -0.4928,\n",
      "          0.0246, -2.2194, -0.4928, -1.1574, -1.1574, -1.0654, -1.1574, -1.1574,\n",
      "         -0.4928, -1.1574, -0.3745, -0.6799, -0.8659, -0.8984],\n",
      "        [-2.3063, -2.1609, -1.9567, -1.7064, -1.5033, -1.3727, -1.2602, -1.1225,\n",
      "         -1.3176, -0.8753, -0.7448, -0.6382, -0.4928, -0.4928, -0.4928,  0.0246,\n",
      "         -2.2194, -0.4928, -1.1574, -1.1574, -1.0654, -1.1574, -1.1574, -0.4928,\n",
      "         -1.1574, -0.3745, -0.6799, -0.8659, -0.8984, -1.0572],\n",
      "        [-2.1609, -1.9567, -1.7064, -1.5033, -1.3727, -1.2602, -1.1225, -1.3176,\n",
      "         -0.8753, -0.7448, -0.6382, -0.4928, -0.4928, -0.4928,  0.0246, -2.2194,\n",
      "         -0.4928, -1.1574, -1.1574, -1.0654, -1.1574, -1.1574, -0.4928, -1.1574,\n",
      "         -0.3745, -0.6799, -0.8659, -0.8984, -1.0572, -1.3181],\n",
      "        [-1.9567, -1.7064, -1.5033, -1.3727, -1.2602, -1.1225, -1.3176, -0.8753,\n",
      "         -0.7448, -0.6382, -0.4928, -0.4928, -0.4928,  0.0246, -2.2194, -0.4928,\n",
      "         -1.1574, -1.1574, -1.0654, -1.1574, -1.1574, -0.4928, -1.1574, -0.3745,\n",
      "         -0.6799, -0.8659, -0.8984, -1.0572, -1.3181, -2.0318],\n",
      "        [-1.7064, -1.5033, -1.3727, -1.2602, -1.1225, -1.3176, -0.8753, -0.7448,\n",
      "         -0.6382, -0.4928, -0.4928, -0.4928,  0.0246, -2.2194, -0.4928, -1.1574,\n",
      "         -1.1574, -1.0654, -1.1574, -1.1574, -0.4928, -1.1574, -0.3745, -0.6799,\n",
      "         -0.8659, -0.8984, -1.0572, -1.3181, -2.0318, -2.4801],\n",
      "        [-1.5033, -1.3727, -1.2602, -1.1225, -1.3176, -0.8753, -0.7448, -0.6382,\n",
      "         -0.4928, -0.4928, -0.4928,  0.0246, -2.2194, -0.4928, -1.1574, -1.1574,\n",
      "         -1.0654, -1.1574, -1.1574, -0.4928, -1.1574, -0.3745, -0.6799, -0.8659,\n",
      "         -0.8984, -1.0572, -1.3181, -2.0318, -2.4801, -3.2739],\n",
      "        [-1.3727, -1.2602, -1.1225, -1.3176, -0.8753, -0.7448, -0.6382, -0.4928,\n",
      "         -0.4928, -0.4928,  0.0246, -2.2194, -0.4928, -1.1574, -1.1574, -1.0654,\n",
      "         -1.1574, -1.1574, -0.4928, -1.1574, -0.3745, -0.6799, -0.8659, -0.8984,\n",
      "         -1.0572, -1.3181, -2.0318, -2.4801, -3.2739, -3.9389],\n",
      "        [-1.2602, -1.1225, -1.3176, -0.8753, -0.7448, -0.6382, -0.4928, -0.4928,\n",
      "         -0.4928,  0.0246, -2.2194, -0.4928, -1.1574, -1.1574, -1.0654, -1.1574,\n",
      "         -1.1574, -0.4928, -1.1574, -0.3745, -0.6799, -0.8659, -0.8984, -1.0572,\n",
      "         -1.3181, -2.0318, -2.4801, -3.2739, -3.9389, -2.2797],\n",
      "        [-1.1225, -1.3176, -0.8753, -0.7448, -0.6382, -0.4928, -0.4928, -0.4928,\n",
      "          0.0246, -2.2194, -0.4928, -1.1574, -1.1574, -1.0654, -1.1574, -1.1574,\n",
      "         -0.4928, -1.1574, -0.3745, -0.6799, -0.8659, -0.8984, -1.0572, -1.3181,\n",
      "         -2.0318, -2.4801, -3.2739, -3.9389, -2.2797, -1.9403],\n",
      "        [-1.3176, -0.8753, -0.7448, -0.6382, -0.4928, -0.4928, -0.4928,  0.0246,\n",
      "         -2.2194, -0.4928, -1.1574, -1.1574, -1.0654, -1.1574, -1.1574, -0.4928,\n",
      "         -1.1574, -0.3745, -0.6799, -0.8659, -0.8984, -1.0572, -1.3181, -2.0318,\n",
      "         -2.4801, -3.2739, -3.9389, -2.2797, -1.9403, -2.0188],\n",
      "        [-0.8753, -0.7448, -0.6382, -0.4928, -0.4928, -0.4928,  0.0246, -2.2194,\n",
      "         -0.4928, -1.1574, -1.1574, -1.0654, -1.1574, -1.1574, -0.4928, -1.1574,\n",
      "         -0.3745, -0.6799, -0.8659, -0.8984, -1.0572, -1.3181, -2.0318, -2.4801,\n",
      "         -3.2739, -3.9389, -2.2797, -1.9403, -2.0188, -1.4756],\n",
      "        [-0.7448, -0.6382, -0.4928, -0.4928, -0.4928,  0.0246, -2.2194, -0.4928,\n",
      "         -1.1574, -1.1574, -1.0654, -1.1574, -1.1574, -0.4928, -1.1574, -0.3745,\n",
      "         -0.6799, -0.8659, -0.8984, -1.0572, -1.3181, -2.0318, -2.4801, -3.2739,\n",
      "         -3.9389, -2.2797, -1.9403, -2.0188, -1.4756, -1.9403]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8,\n",
      "         8, 1, 8, 8, 4, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8,\n",
      "         1, 8, 8, 4, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1,\n",
      "         8, 8, 4, 8, 8, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8,\n",
      "         8, 4, 8, 8, 7, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8,\n",
      "         4, 8, 8, 7, 7, 7],\n",
      "        [5, 5, 5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4,\n",
      "         8, 8, 7, 7, 7, 3],\n",
      "        [5, 5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8,\n",
      "         8, 7, 7, 7, 3, 1],\n",
      "        [5, 5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8,\n",
      "         7, 7, 7, 3, 1, 2],\n",
      "        [5, 5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7,\n",
      "         7, 7, 3, 1, 2, 3],\n",
      "        [5, 6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7, 7,\n",
      "         7, 3, 1, 2, 3, 3],\n",
      "        [6, 6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7, 7, 7,\n",
      "         3, 1, 2, 3, 3, 0],\n",
      "        [6, 6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7, 7, 7, 3,\n",
      "         1, 2, 3, 3, 0, 0],\n",
      "        [6, 7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7, 7, 7, 3, 1,\n",
      "         2, 3, 3, 0, 0, 8],\n",
      "        [7, 6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7, 7, 7, 3, 1, 2,\n",
      "         3, 3, 0, 0, 8, 0],\n",
      "        [6, 6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7, 7, 7, 3, 1, 2, 3,\n",
      "         3, 0, 0, 8, 0, 2],\n",
      "        [6, 6, 4, 4, 4, 6, 7, 4, 8, 8, 1, 8, 8, 4, 8, 8, 7, 7, 7, 3, 1, 2, 3, 3,\n",
      "         0, 0, 8, 0, 2, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-4.6480, -4.2070, -3.6600, -3.1938, -2.8047, -2.4363, -2.1450, -1.8296,\n",
      "         -1.5611, -1.3053, -1.1211, -0.9276, -0.7581, -0.5791, -0.4098, -0.7102,\n",
      "         -0.8777, -0.9069, -0.6962, -0.7854, -1.2089, -1.6132, -2.1798, -2.5659,\n",
      "         -1.3937, -1.1342, -1.2094, -1.1062, -1.1342, -1.1342],\n",
      "        [-4.2070, -3.6600, -3.1938, -2.8047, -2.4363, -2.1450, -1.8296, -1.5611,\n",
      "         -1.3053, -1.1211, -0.9276, -0.7581, -0.5791, -0.4098, -0.7102, -0.8777,\n",
      "         -0.9069, -0.6962, -0.7854, -1.2089, -1.6132, -2.1798, -2.5659, -1.3937,\n",
      "         -1.1342, -1.2094, -1.1062, -1.1342, -1.1342, -1.1342],\n",
      "        [-3.6600, -3.1938, -2.8047, -2.4363, -2.1450, -1.8296, -1.5611, -1.3053,\n",
      "         -1.1211, -0.9276, -0.7581, -0.5791, -0.4098, -0.7102, -0.8777, -0.9069,\n",
      "         -0.6962, -0.7854, -1.2089, -1.6132, -2.1798, -2.5659, -1.3937, -1.1342,\n",
      "         -1.2094, -1.1062, -1.1342, -1.1342, -1.1342, -0.5188],\n",
      "        [-3.1938, -2.8047, -2.4363, -2.1450, -1.8296, -1.5611, -1.3053, -1.1211,\n",
      "         -0.9276, -0.7581, -0.5791, -0.4098, -0.7102, -0.8777, -0.9069, -0.6962,\n",
      "         -0.7854, -1.2089, -1.6132, -2.1798, -2.5659, -1.3937, -1.1342, -1.2094,\n",
      "         -1.1062, -1.1342, -1.1342, -1.1342, -0.5188, -0.5188],\n",
      "        [-2.8047, -2.4363, -2.1450, -1.8296, -1.5611, -1.3053, -1.1211, -0.9276,\n",
      "         -0.7581, -0.5791, -0.4098, -0.7102, -0.8777, -0.9069, -0.6962, -0.7854,\n",
      "         -1.2089, -1.6132, -2.1798, -2.5659, -1.3937, -1.1342, -1.2094, -1.1062,\n",
      "         -1.1342, -1.1342, -1.1342, -0.5188, -0.5188, -0.5188],\n",
      "        [-2.4363, -2.1450, -1.8296, -1.5611, -1.3053, -1.1211, -0.9276, -0.7581,\n",
      "         -0.5791, -0.4098, -0.7102, -0.8777, -0.9069, -0.6962, -0.7854, -1.2089,\n",
      "         -1.6132, -2.1798, -2.5659, -1.3937, -1.1342, -1.2094, -1.1062, -1.1342,\n",
      "         -1.1342, -1.1342, -0.5188, -0.5188, -0.5188,  0.7368],\n",
      "        [-2.1450, -1.8296, -1.5611, -1.3053, -1.1211, -0.9276, -0.7581, -0.5791,\n",
      "         -0.4098, -0.7102, -0.8777, -0.9069, -0.6962, -0.7854, -1.2089, -1.6132,\n",
      "         -2.1798, -2.5659, -1.3937, -1.1342, -1.2094, -1.1062, -1.1342, -1.1342,\n",
      "         -1.1342, -0.5188, -0.5188, -0.5188,  0.7368, -0.5188],\n",
      "        [-1.8296, -1.5611, -1.3053, -1.1211, -0.9276, -0.7581, -0.5791, -0.4098,\n",
      "         -0.7102, -0.8777, -0.9069, -0.6962, -0.7854, -1.2089, -1.6132, -2.1798,\n",
      "         -2.5659, -1.3937, -1.1342, -1.2094, -1.1062, -1.1342, -1.1342, -1.1342,\n",
      "         -0.5188, -0.5188, -0.5188,  0.7368, -0.5188, -0.5188],\n",
      "        [-1.5611, -1.3053, -1.1211, -0.9276, -0.7581, -0.5791, -0.4098, -0.7102,\n",
      "         -0.8777, -0.9069, -0.6962, -0.7854, -1.2089, -1.6132, -2.1798, -2.5659,\n",
      "         -1.3937, -1.1342, -1.2094, -1.1062, -1.1342, -1.1342, -1.1342, -0.5188,\n",
      "         -0.5188, -0.5188,  0.7368, -0.5188, -0.5188,  0.4067],\n",
      "        [-1.3053, -1.1211, -0.9276, -0.7581, -0.5791, -0.4098, -0.7102, -0.8777,\n",
      "         -0.9069, -0.6962, -0.7854, -1.2089, -1.6132, -2.1798, -2.5659, -1.3937,\n",
      "         -1.1342, -1.2094, -1.1062, -1.1342, -1.1342, -1.1342, -0.5188, -0.5188,\n",
      "         -0.5188,  0.7368, -0.5188, -0.5188,  0.4067, -0.8022],\n",
      "        [-1.1211, -0.9276, -0.7581, -0.5791, -0.4098, -0.7102, -0.8777, -0.9069,\n",
      "         -0.6962, -0.7854, -1.2089, -1.6132, -2.1798, -2.5659, -1.3937, -1.1342,\n",
      "         -1.2094, -1.1062, -1.1342, -1.1342, -1.1342, -0.5188, -0.5188, -0.5188,\n",
      "          0.7368, -0.5188, -0.5188,  0.4067, -0.8022, -0.5188],\n",
      "        [-0.9276, -0.7581, -0.5791, -0.4098, -0.7102, -0.8777, -0.9069, -0.6962,\n",
      "         -0.7854, -1.2089, -1.6132, -2.1798, -2.5659, -1.3937, -1.1342, -1.2094,\n",
      "         -1.1062, -1.1342, -1.1342, -1.1342, -0.5188, -0.5188, -0.5188,  0.7368,\n",
      "         -0.5188, -0.5188,  0.4067, -0.8022, -0.5188, -1.4555],\n",
      "        [-0.7581, -0.5791, -0.4098, -0.7102, -0.8777, -0.9069, -0.6962, -0.7854,\n",
      "         -1.2089, -1.6132, -2.1798, -2.5659, -1.3937, -1.1342, -1.2094, -1.1062,\n",
      "         -1.1342, -1.1342, -1.1342, -0.5188, -0.5188, -0.5188,  0.7368, -0.5188,\n",
      "         -0.5188,  0.4067, -0.8022, -0.5188, -1.4555, -1.8638],\n",
      "        [-0.5791, -0.4098, -0.7102, -0.8777, -0.9069, -0.6962, -0.7854, -1.2089,\n",
      "         -1.6132, -2.1798, -2.5659, -1.3937, -1.1342, -1.2094, -1.1062, -1.1342,\n",
      "         -1.1342, -1.1342, -0.5188, -0.5188, -0.5188,  0.7368, -0.5188, -0.5188,\n",
      "          0.4067, -0.8022, -0.5188, -1.4555, -1.8638, -0.5188],\n",
      "        [-0.4098, -0.7102, -0.8777, -0.9069, -0.6962, -0.7854, -1.2089, -1.6132,\n",
      "         -2.1798, -2.5659, -1.3937, -1.1342, -1.2094, -1.1062, -1.1342, -1.1342,\n",
      "         -1.1342, -0.5188, -0.5188, -0.5188,  0.7368, -0.5188, -0.5188,  0.4067,\n",
      "         -0.8022, -0.5188, -1.4555, -1.8638, -0.5188,  0.5223],\n",
      "        [-0.7102, -0.8777, -0.9069, -0.6962, -0.7854, -1.2089, -1.6132, -2.1798,\n",
      "         -2.5659, -1.3937, -1.1342, -1.2094, -1.1062, -1.1342, -1.1342, -1.1342,\n",
      "         -0.5188, -0.5188, -0.5188,  0.7368, -0.5188, -0.5188,  0.4067, -0.8022,\n",
      "         -0.5188, -1.4555, -1.8638, -0.5188,  0.5223, -0.5188]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0,\n",
      "         0, 8, 0, 7, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0,\n",
      "         8, 0, 7, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8,\n",
      "         0, 7, 8, 8, 8, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0,\n",
      "         7, 8, 8, 8, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7,\n",
      "         8, 8, 8, 4, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8,\n",
      "         8, 8, 4, 4, 4, 6],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8,\n",
      "         8, 4, 4, 4, 6, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8,\n",
      "         4, 4, 4, 6, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4,\n",
      "         4, 4, 6, 4, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4, 4,\n",
      "         4, 6, 4, 4, 7, 7],\n",
      "        [6, 6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4, 4, 4,\n",
      "         6, 4, 4, 7, 7, 4],\n",
      "        [6, 6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4, 4, 4, 6,\n",
      "         4, 4, 7, 7, 4, 7],\n",
      "        [6, 6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4, 4, 4, 6, 4,\n",
      "         4, 7, 7, 4, 7, 7],\n",
      "        [6, 6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4, 4, 4, 6, 4, 4,\n",
      "         7, 7, 4, 7, 7, 4],\n",
      "        [6, 7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4, 4, 4, 6, 4, 4, 7,\n",
      "         7, 4, 7, 7, 4, 0],\n",
      "        [7, 7, 7, 7, 1, 2, 3, 3, 0, 0, 8, 0, 7, 8, 8, 8, 4, 4, 4, 6, 4, 4, 7, 7,\n",
      "         4, 7, 7, 4, 0, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.4904, -1.3046, -1.3699, -1.5049, -1.7594, -2.1972, -2.6588, -2.8323,\n",
      "         -1.9110, -1.6689, -1.7661, -1.4527, -1.6689, -1.6689, -1.6689, -1.1802,\n",
      "         -0.8308, -0.7259, -0.6177, -0.5392, -0.5392, -0.2582, -1.0090, -0.5392,\n",
      "         -1.6911, -2.1174, -0.8013, -0.4050, -0.5392, -0.5392],\n",
      "        [-1.3046, -1.3699, -1.5049, -1.7594, -2.1972, -2.6588, -2.8323, -1.9110,\n",
      "         -1.6689, -1.7661, -1.4527, -1.6689, -1.6689, -1.6689, -1.1802, -0.8308,\n",
      "         -0.7259, -0.6177, -0.5392, -0.5392, -0.2582, -1.0090, -0.5392, -1.6911,\n",
      "         -2.1174, -0.8013, -0.4050, -0.5392, -0.5392, -0.5392],\n",
      "        [-1.3699, -1.5049, -1.7594, -2.1972, -2.6588, -2.8323, -1.9110, -1.6689,\n",
      "         -1.7661, -1.4527, -1.6689, -1.6689, -1.6689, -1.1802, -0.8308, -0.7259,\n",
      "         -0.6177, -0.5392, -0.5392, -0.2582, -1.0090, -0.5392, -1.6911, -2.1174,\n",
      "         -0.8013, -0.4050, -0.5392, -0.5392, -0.5392, -0.5392],\n",
      "        [-1.5049, -1.7594, -2.1972, -2.6588, -2.8323, -1.9110, -1.6689, -1.7661,\n",
      "         -1.4527, -1.6689, -1.6689, -1.6689, -1.1802, -0.8308, -0.7259, -0.6177,\n",
      "         -0.5392, -0.5392, -0.2582, -1.0090, -0.5392, -1.6911, -2.1174, -0.8013,\n",
      "         -0.4050, -0.5392, -0.5392, -0.5392, -0.5392, -1.0573],\n",
      "        [-1.7594, -2.1972, -2.6588, -2.8323, -1.9110, -1.6689, -1.7661, -1.4527,\n",
      "         -1.6689, -1.6689, -1.6689, -1.1802, -0.8308, -0.7259, -0.6177, -0.5392,\n",
      "         -0.5392, -0.2582, -1.0090, -0.5392, -1.6911, -2.1174, -0.8013, -0.4050,\n",
      "         -0.5392, -0.5392, -0.5392, -0.5392, -1.0573, -0.5392],\n",
      "        [-2.1972, -2.6588, -2.8323, -1.9110, -1.6689, -1.7661, -1.4527, -1.6689,\n",
      "         -1.6689, -1.6689, -1.1802, -0.8308, -0.7259, -0.6177, -0.5392, -0.5392,\n",
      "         -0.2582, -1.0090, -0.5392, -1.6911, -2.1174, -0.8013, -0.4050, -0.5392,\n",
      "         -0.5392, -0.5392, -0.5392, -1.0573, -0.5392, -0.9320],\n",
      "        [-2.6588, -2.8323, -1.9110, -1.6689, -1.7661, -1.4527, -1.6689, -1.6689,\n",
      "         -1.6689, -1.1802, -0.8308, -0.7259, -0.6177, -0.5392, -0.5392, -0.2582,\n",
      "         -1.0090, -0.5392, -1.6911, -2.1174, -0.8013, -0.4050, -0.5392, -0.5392,\n",
      "         -0.5392, -0.5392, -1.0573, -0.5392, -0.9320, -0.5392],\n",
      "        [-2.8323, -1.9110, -1.6689, -1.7661, -1.4527, -1.6689, -1.6689, -1.6689,\n",
      "         -1.1802, -0.8308, -0.7259, -0.6177, -0.5392, -0.5392, -0.2582, -1.0090,\n",
      "         -0.5392, -1.6911, -2.1174, -0.8013, -0.4050, -0.5392, -0.5392, -0.5392,\n",
      "         -0.5392, -1.0573, -0.5392, -0.9320, -0.5392, -0.7370],\n",
      "        [-1.9110, -1.6689, -1.7661, -1.4527, -1.6689, -1.6689, -1.6689, -1.1802,\n",
      "         -0.8308, -0.7259, -0.6177, -0.5392, -0.5392, -0.2582, -1.0090, -0.5392,\n",
      "         -1.6911, -2.1174, -0.8013, -0.4050, -0.5392, -0.5392, -0.5392, -0.5392,\n",
      "         -1.0573, -0.5392, -0.9320, -0.5392, -0.7370,  0.3064],\n",
      "        [-1.6689, -1.7661, -1.4527, -1.6689, -1.6689, -1.6689, -1.1802, -0.8308,\n",
      "         -0.7259, -0.6177, -0.5392, -0.5392, -0.2582, -1.0090, -0.5392, -1.6911,\n",
      "         -2.1174, -0.8013, -0.4050, -0.5392, -0.5392, -0.5392, -0.5392, -1.0573,\n",
      "         -0.5392, -0.9320, -0.5392, -0.7370,  0.3064, -0.5392],\n",
      "        [-1.7661, -1.4527, -1.6689, -1.6689, -1.6689, -1.1802, -0.8308, -0.7259,\n",
      "         -0.6177, -0.5392, -0.5392, -0.2582, -1.0090, -0.5392, -1.6911, -2.1174,\n",
      "         -0.8013, -0.4050, -0.5392, -0.5392, -0.5392, -0.5392, -1.0573, -0.5392,\n",
      "         -0.9320, -0.5392, -0.7370,  0.3064, -0.5392, -0.5495],\n",
      "        [-1.4527, -1.6689, -1.6689, -1.6689, -1.1802, -0.8308, -0.7259, -0.6177,\n",
      "         -0.5392, -0.5392, -0.2582, -1.0090, -0.5392, -1.6911, -2.1174, -0.8013,\n",
      "         -0.4050, -0.5392, -0.5392, -0.5392, -0.5392, -1.0573, -0.5392, -0.9320,\n",
      "         -0.5392, -0.7370,  0.3064, -0.5392, -0.5495, -0.8498],\n",
      "        [-1.6689, -1.6689, -1.6689, -1.1802, -0.8308, -0.7259, -0.6177, -0.5392,\n",
      "         -0.5392, -0.2582, -1.0090, -0.5392, -1.6911, -2.1174, -0.8013, -0.4050,\n",
      "         -0.5392, -0.5392, -0.5392, -0.5392, -1.0573, -0.5392, -0.9320, -0.5392,\n",
      "         -0.7370,  0.3064, -0.5392, -0.5495, -0.8498, -0.5392],\n",
      "        [-1.6689, -1.6689, -1.1802, -0.8308, -0.7259, -0.6177, -0.5392, -0.5392,\n",
      "         -0.2582, -1.0090, -0.5392, -1.6911, -2.1174, -0.8013, -0.4050, -0.5392,\n",
      "         -0.5392, -0.5392, -0.5392, -1.0573, -0.5392, -0.9320, -0.5392, -0.7370,\n",
      "          0.3064, -0.5392, -0.5495, -0.8498, -0.5392,  0.4231],\n",
      "        [-1.6689, -1.1802, -0.8308, -0.7259, -0.6177, -0.5392, -0.5392, -0.2582,\n",
      "         -1.0090, -0.5392, -1.6911, -2.1174, -0.8013, -0.4050, -0.5392, -0.5392,\n",
      "         -0.5392, -0.5392, -1.0573, -0.5392, -0.9320, -0.5392, -0.7370,  0.3064,\n",
      "         -0.5392, -0.5495, -0.8498, -0.5392,  0.4231, -1.4990],\n",
      "        [-1.1802, -0.8308, -0.7259, -0.6177, -0.5392, -0.5392, -0.2582, -1.0090,\n",
      "         -0.5392, -1.6911, -2.1174, -0.8013, -0.4050, -0.5392, -0.5392, -0.5392,\n",
      "         -0.5392, -1.0573, -0.5392, -0.9320, -0.5392, -0.7370,  0.3064, -0.5392,\n",
      "         -0.5495, -0.8498, -0.5392,  0.4231, -1.4990, -0.5392]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 3, 1, 2, 3, 3, 0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4,\n",
      "         7, 7, 1, 0, 4, 4],\n",
      "        [6, 3, 1, 2, 3, 3, 0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7,\n",
      "         7, 1, 0, 4, 4, 4],\n",
      "        [3, 1, 2, 3, 3, 0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7,\n",
      "         1, 0, 4, 4, 4, 4],\n",
      "        [1, 2, 3, 3, 0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1,\n",
      "         0, 4, 4, 4, 4, 7],\n",
      "        [2, 3, 3, 0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [3, 3, 0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4,\n",
      "         4, 4, 4, 7, 4, 7],\n",
      "        [3, 0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [0, 0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4,\n",
      "         4, 7, 4, 7, 4, 7],\n",
      "        [0, 8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4,\n",
      "         7, 4, 7, 4, 7, 7],\n",
      "        [8, 0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4, 7,\n",
      "         4, 7, 4, 7, 7, 4],\n",
      "        [0, 2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4, 7, 4,\n",
      "         7, 4, 7, 7, 4, 7],\n",
      "        [2, 8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4, 7, 4, 7,\n",
      "         4, 7, 7, 4, 7, 7],\n",
      "        [8, 8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4, 7, 4, 7, 4,\n",
      "         7, 7, 4, 7, 7, 4],\n",
      "        [8, 8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4, 7, 4, 7, 4, 7,\n",
      "         7, 4, 7, 7, 4, 7],\n",
      "        [8, 8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4, 7, 4, 7, 4, 7, 7,\n",
      "         4, 7, 7, 4, 7, 7],\n",
      "        [8, 5, 5, 6, 4, 4, 6, 7, 4, 7, 7, 1, 0, 4, 4, 4, 4, 7, 4, 7, 4, 7, 7, 4,\n",
      "         7, 7, 4, 7, 7, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.8599, -1.9586, -1.8504, -1.7338, -1.6245, -1.5063, -1.4118, -1.3127,\n",
      "         -1.9285, -2.5927, -2.7319, -2.2190, -1.8605, -1.6630, -0.9582, -0.8582,\n",
      "         -1.1767, -0.6438, -1.0280, -0.5186, -0.7967, -0.2707, -0.5186, -0.5744,\n",
      "         -0.9305, -0.5186,  0.3543, -1.7006, -0.7171, -1.7885],\n",
      "        [-1.9586, -1.8504, -1.7338, -1.6245, -1.5063, -1.4118, -1.3127, -1.9285,\n",
      "         -2.5927, -2.7319, -2.2190, -1.8605, -1.6630, -0.9582, -0.8582, -1.1767,\n",
      "         -0.6438, -1.0280, -0.5186, -0.7967, -0.2707, -0.5186, -0.5744, -0.9305,\n",
      "         -0.5186,  0.3543, -1.7006, -0.7171, -1.7885, -2.8599],\n",
      "        [-1.8504, -1.7338, -1.6245, -1.5063, -1.4118, -1.3127, -1.9285, -2.5927,\n",
      "         -2.7319, -2.2190, -1.8605, -1.6630, -0.9582, -0.8582, -1.1767, -0.6438,\n",
      "         -1.0280, -0.5186, -0.7967, -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,\n",
      "          0.3543, -1.7006, -0.7171, -1.7885, -2.8599, -1.7885],\n",
      "        [-1.7338, -1.6245, -1.5063, -1.4118, -1.3127, -1.9285, -2.5927, -2.7319,\n",
      "         -2.2190, -1.8605, -1.6630, -0.9582, -0.8582, -1.1767, -0.6438, -1.0280,\n",
      "         -0.5186, -0.7967, -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,  0.3543,\n",
      "         -1.7006, -0.7171, -1.7885, -2.8599, -1.7885, -1.7885],\n",
      "        [-1.6245, -1.5063, -1.4118, -1.3127, -1.9285, -2.5927, -2.7319, -2.2190,\n",
      "         -1.8605, -1.6630, -0.9582, -0.8582, -1.1767, -0.6438, -1.0280, -0.5186,\n",
      "         -0.7967, -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,  0.3543, -1.7006,\n",
      "         -0.7171, -1.7885, -2.8599, -1.7885, -1.7885, -0.7171],\n",
      "        [-1.5063, -1.4118, -1.3127, -1.9285, -2.5927, -2.7319, -2.2190, -1.8605,\n",
      "         -1.6630, -0.9582, -0.8582, -1.1767, -0.6438, -1.0280, -0.5186, -0.7967,\n",
      "         -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,  0.3543, -1.7006, -0.7171,\n",
      "         -1.7885, -2.8599, -1.7885, -1.7885, -0.7171, -0.7171],\n",
      "        [-1.4118, -1.3127, -1.9285, -2.5927, -2.7319, -2.2190, -1.8605, -1.6630,\n",
      "         -0.9582, -0.8582, -1.1767, -0.6438, -1.0280, -0.5186, -0.7967, -0.2707,\n",
      "         -0.5186, -0.5744, -0.9305, -0.5186,  0.3543, -1.7006, -0.7171, -1.7885,\n",
      "         -2.8599, -1.7885, -1.7885, -0.7171, -0.7171, -0.5186],\n",
      "        [-1.3127, -1.9285, -2.5927, -2.7319, -2.2190, -1.8605, -1.6630, -0.9582,\n",
      "         -0.8582, -1.1767, -0.6438, -1.0280, -0.5186, -0.7967, -0.2707, -0.5186,\n",
      "         -0.5744, -0.9305, -0.5186,  0.3543, -1.7006, -0.7171, -1.7885, -2.8599,\n",
      "         -1.7885, -1.7885, -0.7171, -0.7171, -0.5186, -0.5186],\n",
      "        [-1.9285, -2.5927, -2.7319, -2.2190, -1.8605, -1.6630, -0.9582, -0.8582,\n",
      "         -1.1767, -0.6438, -1.0280, -0.5186, -0.7967, -0.2707, -0.5186, -0.5744,\n",
      "         -0.9305, -0.5186,  0.3543, -1.7006, -0.7171, -1.7885, -2.8599, -1.7885,\n",
      "         -1.7885, -0.7171, -0.7171, -0.5186, -0.5186, -0.6874],\n",
      "        [-2.5927, -2.7319, -2.2190, -1.8605, -1.6630, -0.9582, -0.8582, -1.1767,\n",
      "         -0.6438, -1.0280, -0.5186, -0.7967, -0.2707, -0.5186, -0.5744, -0.9305,\n",
      "         -0.5186,  0.3543, -1.7006, -0.7171, -1.7885, -2.8599, -1.7885, -1.7885,\n",
      "         -0.7171, -0.7171, -0.5186, -0.5186, -0.6874, -0.5186],\n",
      "        [-2.7319, -2.2190, -1.8605, -1.6630, -0.9582, -0.8582, -1.1767, -0.6438,\n",
      "         -1.0280, -0.5186, -0.7967, -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,\n",
      "          0.3543, -1.7006, -0.7171, -1.7885, -2.8599, -1.7885, -1.7885, -0.7171,\n",
      "         -0.7171, -0.5186, -0.5186, -0.6874, -0.5186, -1.2829],\n",
      "        [-2.2190, -1.8605, -1.6630, -0.9582, -0.8582, -1.1767, -0.6438, -1.0280,\n",
      "         -0.5186, -0.7967, -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,  0.3543,\n",
      "         -1.7006, -0.7171, -1.7885, -2.8599, -1.7885, -1.7885, -0.7171, -0.7171,\n",
      "         -0.5186, -0.5186, -0.6874, -0.5186, -1.2829, -0.5186],\n",
      "        [-1.8605, -1.6630, -0.9582, -0.8582, -1.1767, -0.6438, -1.0280, -0.5186,\n",
      "         -0.7967, -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,  0.3543, -1.7006,\n",
      "         -0.7171, -1.7885, -2.8599, -1.7885, -1.7885, -0.7171, -0.7171, -0.5186,\n",
      "         -0.5186, -0.6874, -0.5186, -1.2829, -0.5186, -0.6691],\n",
      "        [-1.6630, -0.9582, -0.8582, -1.1767, -0.6438, -1.0280, -0.5186, -0.7967,\n",
      "         -0.2707, -0.5186, -0.5744, -0.9305, -0.5186,  0.3543, -1.7006, -0.7171,\n",
      "         -1.7885, -2.8599, -1.7885, -1.7885, -0.7171, -0.7171, -0.5186, -0.5186,\n",
      "         -0.6874, -0.5186, -1.2829, -0.5186, -0.6691, -0.5186],\n",
      "        [-0.9582, -0.8582, -1.1767, -0.6438, -1.0280, -0.5186, -0.7967, -0.2707,\n",
      "         -0.5186, -0.5744, -0.9305, -0.5186,  0.3543, -1.7006, -0.7171, -1.7885,\n",
      "         -2.8599, -1.7885, -1.7885, -0.7171, -0.7171, -0.5186, -0.5186, -0.6874,\n",
      "         -0.5186, -1.2829, -0.5186, -0.6691, -0.5186, -0.2610],\n",
      "        [-0.8582, -1.1767, -0.6438, -1.0280, -0.5186, -0.7967, -0.2707, -0.5186,\n",
      "         -0.5744, -0.9305, -0.5186,  0.3543, -1.7006, -0.7171, -1.7885, -2.8599,\n",
      "         -1.7885, -1.7885, -0.7171, -0.7171, -0.5186, -0.5186, -0.6874, -0.5186,\n",
      "         -1.2829, -0.5186, -0.6691, -0.5186, -0.2610, -0.5186]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[8, 5, 5, 5, 5, 5, 5, 5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7,\n",
      "         7, 4, 8, 7, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7,\n",
      "         4, 8, 7, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [5, 5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 4],\n",
      "        [5, 7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 4, 4],\n",
      "        [7, 3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 4, 4, 7],\n",
      "        [3, 1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 4, 4, 7, 4],\n",
      "        [1, 0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8, 8, 8,\n",
      "         8, 4, 4, 7, 4, 7],\n",
      "        [0, 1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8, 8, 8, 8,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [1, 0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8, 8, 8, 8, 4,\n",
      "         4, 7, 4, 7, 4, 7],\n",
      "        [0, 6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4,\n",
      "         7, 4, 7, 4, 7, 4],\n",
      "        [6, 6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 7,\n",
      "         4, 7, 4, 7, 4, 7],\n",
      "        [6, 7, 6, 7, 4, 7, 6, 4, 7, 7, 4, 8, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 7, 4,\n",
      "         7, 4, 7, 4, 7, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.0439, -1.9331, -1.8407, -1.7399, -1.6530, -1.5575, -1.4501, -1.3529,\n",
      "         -1.2719, -1.3349, -1.0867, -2.0908, -1.4662, -2.0941, -2.6989, -1.6985,\n",
      "         -1.6985, -0.6981, -0.6981, -0.5092, -0.5092, -0.8883, -0.5092, -1.5950,\n",
      "         -0.5092, -0.8666, -0.5092, -0.3822, -0.5092, -0.5092],\n",
      "        [-1.9331, -1.8407, -1.7399, -1.6530, -1.5575, -1.4501, -1.3529, -1.2719,\n",
      "         -1.3349, -1.0867, -2.0908, -1.4662, -2.0941, -2.6989, -1.6985, -1.6985,\n",
      "         -0.6981, -0.6981, -0.5092, -0.5092, -0.8883, -0.5092, -1.5950, -0.5092,\n",
      "         -0.8666, -0.5092, -0.3822, -0.5092, -0.5092, -0.5092],\n",
      "        [-1.8407, -1.7399, -1.6530, -1.5575, -1.4501, -1.3529, -1.2719, -1.3349,\n",
      "         -1.0867, -2.0908, -1.4662, -2.0941, -2.6989, -1.6985, -1.6985, -0.6981,\n",
      "         -0.6981, -0.5092, -0.5092, -0.8883, -0.5092, -1.5950, -0.5092, -0.8666,\n",
      "         -0.5092, -0.3822, -0.5092, -0.5092, -0.5092, -0.5092],\n",
      "        [-1.7399, -1.6530, -1.5575, -1.4501, -1.3529, -1.2719, -1.3349, -1.0867,\n",
      "         -2.0908, -1.4662, -2.0941, -2.6989, -1.6985, -1.6985, -0.6981, -0.6981,\n",
      "         -0.5092, -0.5092, -0.8883, -0.5092, -1.5950, -0.5092, -0.8666, -0.5092,\n",
      "         -0.3822, -0.5092, -0.5092, -0.5092, -0.5092, -2.0242],\n",
      "        [-1.6530, -1.5575, -1.4501, -1.3529, -1.2719, -1.3349, -1.0867, -2.0908,\n",
      "         -1.4662, -2.0941, -2.6989, -1.6985, -1.6985, -0.6981, -0.6981, -0.5092,\n",
      "         -0.5092, -0.8883, -0.5092, -1.5950, -0.5092, -0.8666, -0.5092, -0.3822,\n",
      "         -0.5092, -0.5092, -0.5092, -0.5092, -2.0242, -0.6981],\n",
      "        [-1.5575, -1.4501, -1.3529, -1.2719, -1.3349, -1.0867, -2.0908, -1.4662,\n",
      "         -2.0941, -2.6989, -1.6985, -1.6985, -0.6981, -0.6981, -0.5092, -0.5092,\n",
      "         -0.8883, -0.5092, -1.5950, -0.5092, -0.8666, -0.5092, -0.3822, -0.5092,\n",
      "         -0.5092, -0.5092, -0.5092, -2.0242, -0.6981, -0.6981],\n",
      "        [-1.4501, -1.3529, -1.2719, -1.3349, -1.0867, -2.0908, -1.4662, -2.0941,\n",
      "         -2.6989, -1.6985, -1.6985, -0.6981, -0.6981, -0.5092, -0.5092, -0.8883,\n",
      "         -0.5092, -1.5950, -0.5092, -0.8666, -0.5092, -0.3822, -0.5092, -0.5092,\n",
      "         -0.5092, -0.5092, -2.0242, -0.6981, -0.6981, -0.6981],\n",
      "        [-1.3529, -1.2719, -1.3349, -1.0867, -2.0908, -1.4662, -2.0941, -2.6989,\n",
      "         -1.6985, -1.6985, -0.6981, -0.6981, -0.5092, -0.5092, -0.8883, -0.5092,\n",
      "         -1.5950, -0.5092, -0.8666, -0.5092, -0.3822, -0.5092, -0.5092, -0.5092,\n",
      "         -0.5092, -2.0242, -0.6981, -0.6981, -0.6981, -0.6981],\n",
      "        [-1.2719, -1.3349, -1.0867, -2.0908, -1.4662, -2.0941, -2.6989, -1.6985,\n",
      "         -1.6985, -0.6981, -0.6981, -0.5092, -0.5092, -0.8883, -0.5092, -1.5950,\n",
      "         -0.5092, -0.8666, -0.5092, -0.3822, -0.5092, -0.5092, -0.5092, -0.5092,\n",
      "         -2.0242, -0.6981, -0.6981, -0.6981, -0.6981, -0.6981],\n",
      "        [-1.3349, -1.0867, -2.0908, -1.4662, -2.0941, -2.6989, -1.6985, -1.6985,\n",
      "         -0.6981, -0.6981, -0.5092, -0.5092, -0.8883, -0.5092, -1.5950, -0.5092,\n",
      "         -0.8666, -0.5092, -0.3822, -0.5092, -0.5092, -0.5092, -0.5092, -2.0242,\n",
      "         -0.6981, -0.6981, -0.6981, -0.6981, -0.6981, -0.6981],\n",
      "        [-1.0867, -2.0908, -1.4662, -2.0941, -2.6989, -1.6985, -1.6985, -0.6981,\n",
      "         -0.6981, -0.5092, -0.5092, -0.8883, -0.5092, -1.5950, -0.5092, -0.8666,\n",
      "         -0.5092, -0.3822, -0.5092, -0.5092, -0.5092, -0.5092, -2.0242, -0.6981,\n",
      "         -0.6981, -0.6981, -0.6981, -0.6981, -0.6981, -0.6981],\n",
      "        [-2.0908, -1.4662, -2.0941, -2.6989, -1.6985, -1.6985, -0.6981, -0.6981,\n",
      "         -0.5092, -0.5092, -0.8883, -0.5092, -1.5950, -0.5092, -0.8666, -0.5092,\n",
      "         -0.3822, -0.5092, -0.5092, -0.5092, -0.5092, -2.0242, -0.6981, -0.6981,\n",
      "         -0.6981, -0.6981, -0.6981, -0.6981, -0.6981, -0.5092],\n",
      "        [-1.4662, -2.0941, -2.6989, -1.6985, -1.6985, -0.6981, -0.6981, -0.5092,\n",
      "         -0.5092, -0.8883, -0.5092, -1.5950, -0.5092, -0.8666, -0.5092, -0.3822,\n",
      "         -0.5092, -0.5092, -0.5092, -0.5092, -2.0242, -0.6981, -0.6981, -0.6981,\n",
      "         -0.6981, -0.6981, -0.6981, -0.6981, -0.5092, -0.5092],\n",
      "        [-2.0941, -2.6989, -1.6985, -1.6985, -0.6981, -0.6981, -0.5092, -0.5092,\n",
      "         -0.8883, -0.5092, -1.5950, -0.5092, -0.8666, -0.5092, -0.3822, -0.5092,\n",
      "         -0.5092, -0.5092, -0.5092, -2.0242, -0.6981, -0.6981, -0.6981, -0.6981,\n",
      "         -0.6981, -0.6981, -0.6981, -0.5092, -0.5092,  0.8019],\n",
      "        [-2.6989, -1.6985, -1.6985, -0.6981, -0.6981, -0.5092, -0.5092, -0.8883,\n",
      "         -0.5092, -1.5950, -0.5092, -0.8666, -0.5092, -0.3822, -0.5092, -0.5092,\n",
      "         -0.5092, -0.5092, -2.0242, -0.6981, -0.6981, -0.6981, -0.6981, -0.6981,\n",
      "         -0.6981, -0.6981, -0.5092, -0.5092,  0.8019, -0.5092],\n",
      "        [-1.6985, -1.6985, -0.6981, -0.6981, -0.5092, -0.5092, -0.8883, -0.5092,\n",
      "         -1.5950, -0.5092, -0.8666, -0.5092, -0.3822, -0.5092, -0.5092, -0.5092,\n",
      "         -0.5092, -2.0242, -0.6981, -0.6981, -0.6981, -0.6981, -0.6981, -0.6981,\n",
      "         -0.6981, -0.5092, -0.5092,  0.8019, -0.5092, -0.5092]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4,\n",
      "         7, 4, 7, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7,\n",
      "         4, 7, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4,\n",
      "         7, 4, 4, 4, 4, 7],\n",
      "        [5, 5, 5, 5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7,\n",
      "         4, 4, 4, 4, 7, 8],\n",
      "        [5, 5, 5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4,\n",
      "         4, 4, 4, 7, 8, 8],\n",
      "        [5, 5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4,\n",
      "         4, 4, 7, 8, 8, 8],\n",
      "        [5, 5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4,\n",
      "         4, 7, 8, 8, 8, 8],\n",
      "        [5, 0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [0, 5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [5, 7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [7, 1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 4],\n",
      "        [1, 7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 4, 4],\n",
      "        [7, 8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 4, 4, 7],\n",
      "        [8, 8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 4, 4, 7, 4],\n",
      "        [8, 8, 8, 8, 4, 4, 7, 4, 7, 4, 7, 4, 7, 4, 4, 4, 4, 7, 8, 8, 8, 8, 8, 8,\n",
      "         8, 4, 4, 7, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.3011, -1.8709, -1.7725, -1.6877, -1.6005, -1.7068, -1.4361, -1.8253,\n",
      "         -1.4820, -1.5231, -1.3853, -1.4724, -1.2281, -0.9422, -0.8499, -0.7579,\n",
      "         -2.2970, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -0.4959, -0.4959,  0.2167, -0.4959, -0.4959, -0.5793],\n",
      "        [-1.8709, -1.7725, -1.6877, -1.6005, -1.7068, -1.4361, -1.8253, -1.4820,\n",
      "         -1.5231, -1.3853, -1.4724, -1.2281, -0.9422, -0.8499, -0.7579, -2.2970,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -0.4959,\n",
      "         -0.4959,  0.2167, -0.4959, -0.4959, -0.5793, -0.4959],\n",
      "        [-1.7725, -1.6877, -1.6005, -1.7068, -1.4361, -1.8253, -1.4820, -1.5231,\n",
      "         -1.3853, -1.4724, -1.2281, -0.9422, -0.8499, -0.7579, -2.2970, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,\n",
      "          0.2167, -0.4959, -0.4959, -0.5793, -0.4959,  0.7094],\n",
      "        [-1.6877, -1.6005, -1.7068, -1.4361, -1.8253, -1.4820, -1.5231, -1.3853,\n",
      "         -1.4724, -1.2281, -0.9422, -0.8499, -0.7579, -2.2970, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,  0.2167,\n",
      "         -0.4959, -0.4959, -0.5793, -0.4959,  0.7094, -0.6108],\n",
      "        [-1.6005, -1.7068, -1.4361, -1.8253, -1.4820, -1.5231, -1.3853, -1.4724,\n",
      "         -1.2281, -0.9422, -0.8499, -0.7579, -2.2970, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,  0.2167, -0.4959,\n",
      "         -0.4959, -0.5793, -0.4959,  0.7094, -0.6108, -1.4105],\n",
      "        [-1.7068, -1.4361, -1.8253, -1.4820, -1.5231, -1.3853, -1.4724, -1.2281,\n",
      "         -0.9422, -0.8499, -0.7579, -2.2970, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,  0.2167, -0.4959, -0.4959,\n",
      "         -0.5793, -0.4959,  0.7094, -0.6108, -1.4105, -0.4959],\n",
      "        [-1.4361, -1.8253, -1.4820, -1.5231, -1.3853, -1.4724, -1.2281, -0.9422,\n",
      "         -0.8499, -0.7579, -2.2970, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -0.4959, -0.4959,  0.2167, -0.4959, -0.4959, -0.5793,\n",
      "         -0.4959,  0.7094, -0.6108, -1.4105, -0.4959,  0.2740],\n",
      "        [-1.8253, -1.4820, -1.5231, -1.3853, -1.4724, -1.2281, -0.9422, -0.8499,\n",
      "         -0.7579, -2.2970, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -0.4959, -0.4959,  0.2167, -0.4959, -0.4959, -0.5793, -0.4959,\n",
      "          0.7094, -0.6108, -1.4105, -0.4959,  0.2740, -1.8685],\n",
      "        [-1.4820, -1.5231, -1.3853, -1.4724, -1.2281, -0.9422, -0.8499, -0.7579,\n",
      "         -2.2970, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -0.4959, -0.4959,  0.2167, -0.4959, -0.4959, -0.5793, -0.4959,  0.7094,\n",
      "         -0.6108, -1.4105, -0.4959,  0.2740, -1.8685, -0.4959],\n",
      "        [-1.5231, -1.3853, -1.4724, -1.2281, -0.9422, -0.8499, -0.7579, -2.2970,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -0.4959,\n",
      "         -0.4959,  0.2167, -0.4959, -0.4959, -0.5793, -0.4959,  0.7094, -0.6108,\n",
      "         -1.4105, -0.4959,  0.2740, -1.8685, -0.4959, -2.1249],\n",
      "        [-1.3853, -1.4724, -1.2281, -0.9422, -0.8499, -0.7579, -2.2970, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,\n",
      "          0.2167, -0.4959, -0.4959, -0.5793, -0.4959,  0.7094, -0.6108, -1.4105,\n",
      "         -0.4959,  0.2740, -1.8685, -0.4959, -2.1249, -0.4959],\n",
      "        [-1.4724, -1.2281, -0.9422, -0.8499, -0.7579, -2.2970, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,  0.2167,\n",
      "         -0.4959, -0.4959, -0.5793, -0.4959,  0.7094, -0.6108, -1.4105, -0.4959,\n",
      "          0.2740, -1.8685, -0.4959, -2.1249, -0.4959, -1.2671],\n",
      "        [-1.2281, -0.9422, -0.8499, -0.7579, -2.2970, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,  0.2167, -0.4959,\n",
      "         -0.4959, -0.5793, -0.4959,  0.7094, -0.6108, -1.4105, -0.4959,  0.2740,\n",
      "         -1.8685, -0.4959, -2.1249, -0.4959, -1.2671, -1.2969],\n",
      "        [-0.9422, -0.8499, -0.7579, -2.2970, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -1.2969, -0.4959, -0.4959,  0.2167, -0.4959, -0.4959,\n",
      "         -0.5793, -0.4959,  0.7094, -0.6108, -1.4105, -0.4959,  0.2740, -1.8685,\n",
      "         -0.4959, -2.1249, -0.4959, -1.2671, -1.2969, -2.3011],\n",
      "        [-0.8499, -0.7579, -2.2970, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -1.2969, -0.4959, -0.4959,  0.2167, -0.4959, -0.4959, -0.5793,\n",
      "         -0.4959,  0.7094, -0.6108, -1.4105, -0.4959,  0.2740, -1.8685, -0.4959,\n",
      "         -2.1249, -0.4959, -1.2671, -1.2969, -2.3011, -2.3011],\n",
      "        [-0.7579, -2.2970, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969, -1.2969,\n",
      "         -1.2969, -0.4959, -0.4959,  0.2167, -0.4959, -0.4959, -0.5793, -0.4959,\n",
      "          0.7094, -0.6108, -1.4105, -0.4959,  0.2740, -1.8685, -0.4959, -2.1249,\n",
      "         -0.4959, -1.2671, -1.2969, -2.3011, -2.3011, -1.2969]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[8, 0, 5, 5, 5, 2, 5, 7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8,\n",
      "         4, 4, 6, 4, 4, 7],\n",
      "        [0, 5, 5, 5, 2, 5, 7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4,\n",
      "         4, 6, 4, 4, 7, 4],\n",
      "        [5, 5, 5, 2, 5, 7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4,\n",
      "         6, 4, 4, 7, 4, 7],\n",
      "        [5, 5, 2, 5, 7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6,\n",
      "         4, 4, 7, 4, 7, 7],\n",
      "        [5, 2, 5, 7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4,\n",
      "         4, 7, 4, 7, 7, 7],\n",
      "        [2, 5, 7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4,\n",
      "         7, 4, 7, 7, 7, 4],\n",
      "        [5, 7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7,\n",
      "         4, 7, 7, 7, 4, 7],\n",
      "        [7, 1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4,\n",
      "         7, 7, 7, 4, 7, 7],\n",
      "        [1, 3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7,\n",
      "         7, 7, 4, 7, 7, 4],\n",
      "        [3, 3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7, 7,\n",
      "         7, 4, 7, 7, 4, 7],\n",
      "        [3, 2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7, 7, 7,\n",
      "         4, 7, 7, 4, 7, 4],\n",
      "        [2, 0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7, 7, 7, 4,\n",
      "         7, 7, 4, 7, 4, 7],\n",
      "        [0, 6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7, 7, 7, 4, 7,\n",
      "         7, 4, 7, 4, 7, 8],\n",
      "        [6, 6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7, 7, 7, 4, 7, 7,\n",
      "         4, 7, 4, 7, 8, 8],\n",
      "        [6, 6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7, 7, 7, 4, 7, 7, 4,\n",
      "         7, 4, 7, 8, 8, 8],\n",
      "        [6, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 6, 4, 4, 7, 4, 7, 7, 7, 4, 7, 7, 4, 7,\n",
      "         4, 7, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.6189, -3.6608, -2.9909, -3.0927, -2.7625, -2.7415, -2.4929, -2.5100,\n",
      "         -2.0616, -1.5816, -1.3288, -1.2187, -1.0964, -0.9591, -0.8236, -0.6990,\n",
      "         -0.5776, -1.0420, -0.4977, -0.2446, -1.4283, -0.4977, -1.6446, -0.4977,\n",
      "         -0.9210, -1.0872, -1.9452, -1.9452, -1.0872, -1.0872],\n",
      "        [-3.6608, -2.9909, -3.0927, -2.7625, -2.7415, -2.4929, -2.5100, -2.0616,\n",
      "         -1.5816, -1.3288, -1.2187, -1.0964, -0.9591, -0.8236, -0.6990, -0.5776,\n",
      "         -1.0420, -0.4977, -0.2446, -1.4283, -0.4977, -1.6446, -0.4977, -0.9210,\n",
      "         -1.0872, -1.9452, -1.9452, -1.0872, -1.0872, -1.0872],\n",
      "        [-2.9909, -3.0927, -2.7625, -2.7415, -2.4929, -2.5100, -2.0616, -1.5816,\n",
      "         -1.3288, -1.2187, -1.0964, -0.9591, -0.8236, -0.6990, -0.5776, -1.0420,\n",
      "         -0.4977, -0.2446, -1.4283, -0.4977, -1.6446, -0.4977, -0.9210, -1.0872,\n",
      "         -1.9452, -1.9452, -1.0872, -1.0872, -1.0872, -1.0872],\n",
      "        [-3.0927, -2.7625, -2.7415, -2.4929, -2.5100, -2.0616, -1.5816, -1.3288,\n",
      "         -1.2187, -1.0964, -0.9591, -0.8236, -0.6990, -0.5776, -1.0420, -0.4977,\n",
      "         -0.2446, -1.4283, -0.4977, -1.6446, -0.4977, -0.9210, -1.0872, -1.9452,\n",
      "         -1.9452, -1.0872, -1.0872, -1.0872, -1.0872, -0.4977],\n",
      "        [-2.7625, -2.7415, -2.4929, -2.5100, -2.0616, -1.5816, -1.3288, -1.2187,\n",
      "         -1.0964, -0.9591, -0.8236, -0.6990, -0.5776, -1.0420, -0.4977, -0.2446,\n",
      "         -1.4283, -0.4977, -1.6446, -0.4977, -0.9210, -1.0872, -1.9452, -1.9452,\n",
      "         -1.0872, -1.0872, -1.0872, -1.0872, -0.4977, -0.4977],\n",
      "        [-2.7415, -2.4929, -2.5100, -2.0616, -1.5816, -1.3288, -1.2187, -1.0964,\n",
      "         -0.9591, -0.8236, -0.6990, -0.5776, -1.0420, -0.4977, -0.2446, -1.4283,\n",
      "         -0.4977, -1.6446, -0.4977, -0.9210, -1.0872, -1.9452, -1.9452, -1.0872,\n",
      "         -1.0872, -1.0872, -1.0872, -0.4977, -0.4977, -0.2293],\n",
      "        [-2.4929, -2.5100, -2.0616, -1.5816, -1.3288, -1.2187, -1.0964, -0.9591,\n",
      "         -0.8236, -0.6990, -0.5776, -1.0420, -0.4977, -0.2446, -1.4283, -0.4977,\n",
      "         -1.6446, -0.4977, -0.9210, -1.0872, -1.9452, -1.9452, -1.0872, -1.0872,\n",
      "         -1.0872, -1.0872, -0.4977, -0.4977, -0.2293, -3.8550],\n",
      "        [-2.5100, -2.0616, -1.5816, -1.3288, -1.2187, -1.0964, -0.9591, -0.8236,\n",
      "         -0.6990, -0.5776, -1.0420, -0.4977, -0.2446, -1.4283, -0.4977, -1.6446,\n",
      "         -0.4977, -0.9210, -1.0872, -1.9452, -1.9452, -1.0872, -1.0872, -1.0872,\n",
      "         -1.0872, -0.4977, -0.4977, -0.2293, -3.8550, -0.5332],\n",
      "        [-2.0616, -1.5816, -1.3288, -1.2187, -1.0964, -0.9591, -0.8236, -0.6990,\n",
      "         -0.5776, -1.0420, -0.4977, -0.2446, -1.4283, -0.4977, -1.6446, -0.4977,\n",
      "         -0.9210, -1.0872, -1.9452, -1.9452, -1.0872, -1.0872, -1.0872, -1.0872,\n",
      "         -0.4977, -0.4977, -0.2293, -3.8550, -0.5332, -0.4977],\n",
      "        [-1.5816, -1.3288, -1.2187, -1.0964, -0.9591, -0.8236, -0.6990, -0.5776,\n",
      "         -1.0420, -0.4977, -0.2446, -1.4283, -0.4977, -1.6446, -0.4977, -0.9210,\n",
      "         -1.0872, -1.9452, -1.9452, -1.0872, -1.0872, -1.0872, -1.0872, -0.4977,\n",
      "         -0.4977, -0.2293, -3.8550, -0.5332, -0.4977, -0.4977],\n",
      "        [-1.3288, -1.2187, -1.0964, -0.9591, -0.8236, -0.6990, -0.5776, -1.0420,\n",
      "         -0.4977, -0.2446, -1.4283, -0.4977, -1.6446, -0.4977, -0.9210, -1.0872,\n",
      "         -1.9452, -1.9452, -1.0872, -1.0872, -1.0872, -1.0872, -0.4977, -0.4977,\n",
      "         -0.2293, -3.8550, -0.5332, -0.4977, -0.4977, -0.7457],\n",
      "        [-1.2187, -1.0964, -0.9591, -0.8236, -0.6990, -0.5776, -1.0420, -0.4977,\n",
      "         -0.2446, -1.4283, -0.4977, -1.6446, -0.4977, -0.9210, -1.0872, -1.9452,\n",
      "         -1.9452, -1.0872, -1.0872, -1.0872, -1.0872, -0.4977, -0.4977, -0.2293,\n",
      "         -3.8550, -0.5332, -0.4977, -0.4977, -0.7457, -0.4977],\n",
      "        [-1.0964, -0.9591, -0.8236, -0.6990, -0.5776, -1.0420, -0.4977, -0.2446,\n",
      "         -1.4283, -0.4977, -1.6446, -0.4977, -0.9210, -1.0872, -1.9452, -1.9452,\n",
      "         -1.0872, -1.0872, -1.0872, -1.0872, -0.4977, -0.4977, -0.2293, -3.8550,\n",
      "         -0.5332, -0.4977, -0.4977, -0.7457, -0.4977, -0.4977],\n",
      "        [-0.9591, -0.8236, -0.6990, -0.5776, -1.0420, -0.4977, -0.2446, -1.4283,\n",
      "         -0.4977, -1.6446, -0.4977, -0.9210, -1.0872, -1.9452, -1.9452, -1.0872,\n",
      "         -1.0872, -1.0872, -1.0872, -0.4977, -0.4977, -0.2293, -3.8550, -0.5332,\n",
      "         -0.4977, -0.4977, -0.7457, -0.4977, -0.4977, -0.4977],\n",
      "        [-0.8236, -0.6990, -0.5776, -1.0420, -0.4977, -0.2446, -1.4283, -0.4977,\n",
      "         -1.6446, -0.4977, -0.9210, -1.0872, -1.9452, -1.9452, -1.0872, -1.0872,\n",
      "         -1.0872, -1.0872, -0.4977, -0.4977, -0.2293, -3.8550, -0.5332, -0.4977,\n",
      "         -0.4977, -0.7457, -0.4977, -0.4977, -0.4977, -0.4977],\n",
      "        [-0.6990, -0.5776, -1.0420, -0.4977, -0.2446, -1.4283, -0.4977, -1.6446,\n",
      "         -0.4977, -0.9210, -1.0872, -1.9452, -1.9452, -1.0872, -1.0872, -1.0872,\n",
      "         -1.0872, -0.4977, -0.4977, -0.2293, -3.8550, -0.5332, -0.4977, -0.4977,\n",
      "         -0.7457, -0.4977, -0.4977, -0.4977, -0.4977, -0.7674]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[2, 2, 3, 3, 1, 1, 3, 2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [2, 3, 3, 1, 1, 3, 2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [3, 3, 1, 1, 3, 2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [3, 1, 1, 3, 2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 4],\n",
      "        [1, 1, 3, 2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 4, 4],\n",
      "        [1, 3, 2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 4, 4, 8],\n",
      "        [3, 2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 4, 4, 8, 7],\n",
      "        [2, 0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8,\n",
      "         8, 4, 4, 8, 7, 0],\n",
      "        [0, 1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8,\n",
      "         4, 4, 8, 7, 0, 4],\n",
      "        [1, 6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 4,\n",
      "         4, 8, 7, 0, 4, 4],\n",
      "        [6, 6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4,\n",
      "         8, 7, 0, 4, 4, 0],\n",
      "        [6, 6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 8,\n",
      "         7, 0, 4, 4, 0, 4],\n",
      "        [6, 6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 8, 7,\n",
      "         0, 4, 4, 0, 4, 4],\n",
      "        [6, 5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 8, 7, 0,\n",
      "         4, 4, 0, 4, 4, 4],\n",
      "        [5, 6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 8, 7, 0, 4,\n",
      "         4, 0, 4, 4, 4, 4],\n",
      "        [6, 6, 7, 4, 6, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 4, 4, 8, 7, 0, 4, 4,\n",
      "         0, 4, 4, 4, 4, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.7781, -2.6137, -2.4486, -2.2787, -2.1352, -1.9502, -1.7957, -1.6403,\n",
      "         -1.5021, -1.3769, -1.5716, -1.5716, -1.0541, -0.9471, -0.8563, -0.8001,\n",
      "         -0.5831, -0.4950, -0.3148, -3.5933, -1.9697, -1.4107, -1.1036, -2.3367,\n",
      "         -0.7882, -0.4950, -0.4950, -0.4950, -0.6082, -0.4950],\n",
      "        [-2.6137, -2.4486, -2.2787, -2.1352, -1.9502, -1.7957, -1.6403, -1.5021,\n",
      "         -1.3769, -1.5716, -1.5716, -1.0541, -0.9471, -0.8563, -0.8001, -0.5831,\n",
      "         -0.4950, -0.3148, -3.5933, -1.9697, -1.4107, -1.1036, -2.3367, -0.7882,\n",
      "         -0.4950, -0.4950, -0.4950, -0.6082, -0.4950, -1.1704],\n",
      "        [-2.4486, -2.2787, -2.1352, -1.9502, -1.7957, -1.6403, -1.5021, -1.3769,\n",
      "         -1.5716, -1.5716, -1.0541, -0.9471, -0.8563, -0.8001, -0.5831, -0.4950,\n",
      "         -0.3148, -3.5933, -1.9697, -1.4107, -1.1036, -2.3367, -0.7882, -0.4950,\n",
      "         -0.4950, -0.4950, -0.6082, -0.4950, -1.1704, -0.4950],\n",
      "        [-2.2787, -2.1352, -1.9502, -1.7957, -1.6403, -1.5021, -1.3769, -1.5716,\n",
      "         -1.5716, -1.0541, -0.9471, -0.8563, -0.8001, -0.5831, -0.4950, -0.3148,\n",
      "         -3.5933, -1.9697, -1.4107, -1.1036, -2.3367, -0.7882, -0.4950, -0.4950,\n",
      "         -0.4950, -0.6082, -0.4950, -1.1704, -0.4950, -0.4950],\n",
      "        [-2.1352, -1.9502, -1.7957, -1.6403, -1.5021, -1.3769, -1.5716, -1.5716,\n",
      "         -1.0541, -0.9471, -0.8563, -0.8001, -0.5831, -0.4950, -0.3148, -3.5933,\n",
      "         -1.9697, -1.4107, -1.1036, -2.3367, -0.7882, -0.4950, -0.4950, -0.4950,\n",
      "         -0.6082, -0.4950, -1.1704, -0.4950, -0.4950, -0.8001],\n",
      "        [-1.9502, -1.7957, -1.6403, -1.5021, -1.3769, -1.5716, -1.5716, -1.0541,\n",
      "         -0.9471, -0.8563, -0.8001, -0.5831, -0.4950, -0.3148, -3.5933, -1.9697,\n",
      "         -1.4107, -1.1036, -2.3367, -0.7882, -0.4950, -0.4950, -0.4950, -0.6082,\n",
      "         -0.4950, -1.1704, -0.4950, -0.4950, -0.8001, -0.7051],\n",
      "        [-1.7957, -1.6403, -1.5021, -1.3769, -1.5716, -1.5716, -1.0541, -0.9471,\n",
      "         -0.8563, -0.8001, -0.5831, -0.4950, -0.3148, -3.5933, -1.9697, -1.4107,\n",
      "         -1.1036, -2.3367, -0.7882, -0.4950, -0.4950, -0.4950, -0.6082, -0.4950,\n",
      "         -1.1704, -0.4950, -0.4950, -0.8001, -0.7051, -1.0545],\n",
      "        [-1.6403, -1.5021, -1.3769, -1.5716, -1.5716, -1.0541, -0.9471, -0.8563,\n",
      "         -0.8001, -0.5831, -0.4950, -0.3148, -3.5933, -1.9697, -1.4107, -1.1036,\n",
      "         -2.3367, -0.7882, -0.4950, -0.4950, -0.4950, -0.6082, -0.4950, -1.1704,\n",
      "         -0.4950, -0.4950, -0.8001, -0.7051, -1.0545, -1.7565],\n",
      "        [-1.5021, -1.3769, -1.5716, -1.5716, -1.0541, -0.9471, -0.8563, -0.8001,\n",
      "         -0.5831, -0.4950, -0.3148, -3.5933, -1.9697, -1.4107, -1.1036, -2.3367,\n",
      "         -0.7882, -0.4950, -0.4950, -0.4950, -0.6082, -0.4950, -1.1704, -0.4950,\n",
      "         -0.4950, -0.8001, -0.7051, -1.0545, -1.7565, -1.5716],\n",
      "        [-1.3769, -1.5716, -1.5716, -1.0541, -0.9471, -0.8563, -0.8001, -0.5831,\n",
      "         -0.4950, -0.3148, -3.5933, -1.9697, -1.4107, -1.1036, -2.3367, -0.7882,\n",
      "         -0.4950, -0.4950, -0.4950, -0.6082, -0.4950, -1.1704, -0.4950, -0.4950,\n",
      "         -0.8001, -0.7051, -1.0545, -1.7565, -1.5716, -1.5716],\n",
      "        [-1.5716, -1.5716, -1.0541, -0.9471, -0.8563, -0.8001, -0.5831, -0.4950,\n",
      "         -0.3148, -3.5933, -1.9697, -1.4107, -1.1036, -2.3367, -0.7882, -0.4950,\n",
      "         -0.4950, -0.4950, -0.6082, -0.4950, -1.1704, -0.4950, -0.4950, -0.8001,\n",
      "         -0.7051, -1.0545, -1.7565, -1.5716, -1.5716, -2.3431],\n",
      "        [-1.5716, -1.0541, -0.9471, -0.8563, -0.8001, -0.5831, -0.4950, -0.3148,\n",
      "         -3.5933, -1.9697, -1.4107, -1.1036, -2.3367, -0.7882, -0.4950, -0.4950,\n",
      "         -0.4950, -0.6082, -0.4950, -1.1704, -0.4950, -0.4950, -0.8001, -0.7051,\n",
      "         -1.0545, -1.7565, -1.5716, -1.5716, -2.3431, -2.3431],\n",
      "        [-1.0541, -0.9471, -0.8563, -0.8001, -0.5831, -0.4950, -0.3148, -3.5933,\n",
      "         -1.9697, -1.4107, -1.1036, -2.3367, -0.7882, -0.4950, -0.4950, -0.4950,\n",
      "         -0.6082, -0.4950, -1.1704, -0.4950, -0.4950, -0.8001, -0.7051, -1.0545,\n",
      "         -1.7565, -1.5716, -1.5716, -2.3431, -2.3431, -2.3431],\n",
      "        [-0.9471, -0.8563, -0.8001, -0.5831, -0.4950, -0.3148, -3.5933, -1.9697,\n",
      "         -1.4107, -1.1036, -2.3367, -0.7882, -0.4950, -0.4950, -0.4950, -0.6082,\n",
      "         -0.4950, -1.1704, -0.4950, -0.4950, -0.8001, -0.7051, -1.0545, -1.7565,\n",
      "         -1.5716, -1.5716, -2.3431, -2.3431, -2.3431, -2.3431],\n",
      "        [-0.8563, -0.8001, -0.5831, -0.4950, -0.3148, -3.5933, -1.9697, -1.4107,\n",
      "         -1.1036, -2.3367, -0.7882, -0.4950, -0.4950, -0.4950, -0.6082, -0.4950,\n",
      "         -1.1704, -0.4950, -0.4950, -0.8001, -0.7051, -1.0545, -1.7565, -1.5716,\n",
      "         -1.5716, -2.3431, -2.3431, -2.3431, -2.3431, -1.5716],\n",
      "        [-0.8001, -0.5831, -0.4950, -0.3148, -3.5933, -1.9697, -1.4107, -1.1036,\n",
      "         -2.3367, -0.7882, -0.4950, -0.4950, -0.4950, -0.6082, -0.4950, -1.1704,\n",
      "         -0.4950, -0.4950, -0.8001, -0.7051, -1.0545, -1.7565, -1.5716, -1.5716,\n",
      "         -2.3431, -2.3431, -2.3431, -2.3431, -1.5716, -1.5716]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0,\n",
      "         0, 4, 4, 4, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0,\n",
      "         4, 4, 4, 7, 4, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4,\n",
      "         7, 4, 7, 4, 4, 8],\n",
      "        [5, 5, 5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7,\n",
      "         4, 7, 4, 4, 8, 2],\n",
      "        [5, 5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4,\n",
      "         7, 4, 4, 8, 2, 7],\n",
      "        [5, 5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7,\n",
      "         4, 4, 8, 2, 7, 3],\n",
      "        [5, 5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4,\n",
      "         4, 8, 2, 7, 3, 8],\n",
      "        [5, 8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4, 4,\n",
      "         8, 2, 7, 3, 8, 8],\n",
      "        [8, 8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4, 4, 8,\n",
      "         2, 7, 3, 8, 8, 8],\n",
      "        [8, 6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4, 4, 8, 2,\n",
      "         7, 3, 8, 8, 8, 8],\n",
      "        [6, 6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4, 4, 8, 2, 7,\n",
      "         3, 8, 8, 8, 8, 8],\n",
      "        [6, 1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4, 4, 8, 2, 7, 3,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [1, 8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4, 4, 8, 2, 7, 3, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [8, 6, 4, 6, 7, 0, 0, 3, 0, 0, 4, 4, 4, 7, 4, 7, 4, 4, 8, 2, 7, 3, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.2928, -2.1420, -2.0035, -3.9121, -1.7771, -1.6825, -1.5953, -1.6574,\n",
      "         -1.4099, -1.3074, -1.2043, -1.0928, -0.9865, -0.8905, -1.4124, -0.7704,\n",
      "         -0.7446, -0.6429, -1.0349, -1.2928, -1.3767, -1.2127, -1.0767, -1.4849,\n",
      "         -1.4849, -1.4849, -1.4849, -0.8427, -0.8427, -0.8427],\n",
      "        [-2.1420, -2.0035, -3.9121, -1.7771, -1.6825, -1.5953, -1.6574, -1.4099,\n",
      "         -1.3074, -1.2043, -1.0928, -0.9865, -0.8905, -1.4124, -0.7704, -0.7446,\n",
      "         -0.6429, -1.0349, -1.2928, -1.3767, -1.2127, -1.0767, -1.4849, -1.4849,\n",
      "         -1.4849, -1.4849, -0.8427, -0.8427, -0.8427, -0.8427],\n",
      "        [-2.0035, -3.9121, -1.7771, -1.6825, -1.5953, -1.6574, -1.4099, -1.3074,\n",
      "         -1.2043, -1.0928, -0.9865, -0.8905, -1.4124, -0.7704, -0.7446, -0.6429,\n",
      "         -1.0349, -1.2928, -1.3767, -1.2127, -1.0767, -1.4849, -1.4849, -1.4849,\n",
      "         -1.4849, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427],\n",
      "        [-3.9121, -1.7771, -1.6825, -1.5953, -1.6574, -1.4099, -1.3074, -1.2043,\n",
      "         -1.0928, -0.9865, -0.8905, -1.4124, -0.7704, -0.7446, -0.6429, -1.0349,\n",
      "         -1.2928, -1.3767, -1.2127, -1.0767, -1.4849, -1.4849, -1.4849, -1.4849,\n",
      "         -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427],\n",
      "        [-1.7771, -1.6825, -1.5953, -1.6574, -1.4099, -1.3074, -1.2043, -1.0928,\n",
      "         -0.9865, -0.8905, -1.4124, -0.7704, -0.7446, -0.6429, -1.0349, -1.2928,\n",
      "         -1.3767, -1.2127, -1.0767, -1.4849, -1.4849, -1.4849, -1.4849, -0.8427,\n",
      "         -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -1.0281],\n",
      "        [-1.6825, -1.5953, -1.6574, -1.4099, -1.3074, -1.2043, -1.0928, -0.9865,\n",
      "         -0.8905, -1.4124, -0.7704, -0.7446, -0.6429, -1.0349, -1.2928, -1.3767,\n",
      "         -1.2127, -1.0767, -1.4849, -1.4849, -1.4849, -1.4849, -0.8427, -0.8427,\n",
      "         -0.8427, -0.8427, -0.8427, -0.8427, -1.0281, -0.4947],\n",
      "        [-1.5953, -1.6574, -1.4099, -1.3074, -1.2043, -1.0928, -0.9865, -0.8905,\n",
      "         -1.4124, -0.7704, -0.7446, -0.6429, -1.0349, -1.2928, -1.3767, -1.2127,\n",
      "         -1.0767, -1.4849, -1.4849, -1.4849, -1.4849, -0.8427, -0.8427, -0.8427,\n",
      "         -0.8427, -0.8427, -0.8427, -1.0281, -0.4947, -0.4947],\n",
      "        [-1.6574, -1.4099, -1.3074, -1.2043, -1.0928, -0.9865, -0.8905, -1.4124,\n",
      "         -0.7704, -0.7446, -0.6429, -1.0349, -1.2928, -1.3767, -1.2127, -1.0767,\n",
      "         -1.4849, -1.4849, -1.4849, -1.4849, -0.8427, -0.8427, -0.8427, -0.8427,\n",
      "         -0.8427, -0.8427, -1.0281, -0.4947, -0.4947, -0.1881],\n",
      "        [-1.4099, -1.3074, -1.2043, -1.0928, -0.9865, -0.8905, -1.4124, -0.7704,\n",
      "         -0.7446, -0.6429, -1.0349, -1.2928, -1.3767, -1.2127, -1.0767, -1.4849,\n",
      "         -1.4849, -1.4849, -1.4849, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427,\n",
      "         -0.8427, -1.0281, -0.4947, -0.4947, -0.1881, -0.4947],\n",
      "        [-1.3074, -1.2043, -1.0928, -0.9865, -0.8905, -1.4124, -0.7704, -0.7446,\n",
      "         -0.6429, -1.0349, -1.2928, -1.3767, -1.2127, -1.0767, -1.4849, -1.4849,\n",
      "         -1.4849, -1.4849, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427,\n",
      "         -1.0281, -0.4947, -0.4947, -0.1881, -0.4947, -0.4947],\n",
      "        [-1.2043, -1.0928, -0.9865, -0.8905, -1.4124, -0.7704, -0.7446, -0.6429,\n",
      "         -1.0349, -1.2928, -1.3767, -1.2127, -1.0767, -1.4849, -1.4849, -1.4849,\n",
      "         -1.4849, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -1.0281,\n",
      "         -0.4947, -0.4947, -0.1881, -0.4947, -0.4947, -0.7005],\n",
      "        [-1.0928, -0.9865, -0.8905, -1.4124, -0.7704, -0.7446, -0.6429, -1.0349,\n",
      "         -1.2928, -1.3767, -1.2127, -1.0767, -1.4849, -1.4849, -1.4849, -1.4849,\n",
      "         -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -1.0281, -0.4947,\n",
      "         -0.4947, -0.1881, -0.4947, -0.4947, -0.7005, -0.4947],\n",
      "        [-0.9865, -0.8905, -1.4124, -0.7704, -0.7446, -0.6429, -1.0349, -1.2928,\n",
      "         -1.3767, -1.2127, -1.0767, -1.4849, -1.4849, -1.4849, -1.4849, -0.8427,\n",
      "         -0.8427, -0.8427, -0.8427, -0.8427, -0.8427, -1.0281, -0.4947, -0.4947,\n",
      "         -0.1881, -0.4947, -0.4947, -0.7005, -0.4947,  0.7136],\n",
      "        [-0.8905, -1.4124, -0.7704, -0.7446, -0.6429, -1.0349, -1.2928, -1.3767,\n",
      "         -1.2127, -1.0767, -1.4849, -1.4849, -1.4849, -1.4849, -0.8427, -0.8427,\n",
      "         -0.8427, -0.8427, -0.8427, -0.8427, -1.0281, -0.4947, -0.4947, -0.1881,\n",
      "         -0.4947, -0.4947, -0.7005, -0.4947,  0.7136, -0.4947],\n",
      "        [-1.4124, -0.7704, -0.7446, -0.6429, -1.0349, -1.2928, -1.3767, -1.2127,\n",
      "         -1.0767, -1.4849, -1.4849, -1.4849, -1.4849, -0.8427, -0.8427, -0.8427,\n",
      "         -0.8427, -0.8427, -0.8427, -1.0281, -0.4947, -0.4947, -0.1881, -0.4947,\n",
      "         -0.4947, -0.7005, -0.4947,  0.7136, -0.4947, -5.6426],\n",
      "        [-0.7704, -0.7446, -0.6429, -1.0349, -1.2928, -1.3767, -1.2127, -1.0767,\n",
      "         -1.4849, -1.4849, -1.4849, -1.4849, -0.8427, -0.8427, -0.8427, -0.8427,\n",
      "         -0.8427, -0.8427, -1.0281, -0.4947, -0.4947, -0.1881, -0.4947, -0.4947,\n",
      "         -0.7005, -0.4947,  0.7136, -0.4947, -5.6426, -0.4947]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 7, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 7, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 7, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [7, 6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 7],\n",
      "        [6, 6, 0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 7, 4],\n",
      "        [6, 0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 7, 4, 4],\n",
      "        [0, 6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 7, 4, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 7, 4, 4, 7, 4],\n",
      "        [6, 6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         7, 4, 4, 7, 4, 4],\n",
      "        [6, 6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7,\n",
      "         4, 4, 7, 4, 4, 7],\n",
      "        [6, 6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 4,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [6, 6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 4, 4,\n",
      "         7, 4, 4, 7, 4, 7],\n",
      "        [6, 7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 4, 4, 7,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [7, 1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 4, 4, 7, 4,\n",
      "         4, 7, 4, 7, 4, 7],\n",
      "        [1, 1, 3, 2, 7, 3, 0, 1, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7, 4, 4, 7, 4, 4,\n",
      "         7, 4, 7, 4, 7, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.1532, -2.0661, -2.4264, -2.4150, -2.7087, -2.5666, -2.4017, -2.1605,\n",
      "         -1.9248, -1.8103, -1.7185, -1.1835, -1.1733, -1.1733, -1.1733, -1.1733,\n",
      "         -1.1733, -0.8299, -0.6281, -0.4949, -0.2059, -0.4949, -0.4949, -0.5865,\n",
      "         -0.4949,  0.3489, -0.4949, -4.2579, -0.8545, -0.4949],\n",
      "        [-2.0661, -2.4264, -2.4150, -2.7087, -2.5666, -2.4017, -2.1605, -1.9248,\n",
      "         -1.8103, -1.7185, -1.1835, -1.1733, -1.1733, -1.1733, -1.1733, -1.1733,\n",
      "         -0.8299, -0.6281, -0.4949, -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,\n",
      "          0.3489, -0.4949, -4.2579, -0.8545, -0.4949,  0.1112],\n",
      "        [-2.4264, -2.4150, -2.7087, -2.5666, -2.4017, -2.1605, -1.9248, -1.8103,\n",
      "         -1.7185, -1.1835, -1.1733, -1.1733, -1.1733, -1.1733, -1.1733, -0.8299,\n",
      "         -0.6281, -0.4949, -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,  0.3489,\n",
      "         -0.4949, -4.2579, -0.8545, -0.4949,  0.1112, -0.4949],\n",
      "        [-2.4150, -2.7087, -2.5666, -2.4017, -2.1605, -1.9248, -1.8103, -1.7185,\n",
      "         -1.1835, -1.1733, -1.1733, -1.1733, -1.1733, -1.1733, -0.8299, -0.6281,\n",
      "         -0.4949, -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,  0.3489, -0.4949,\n",
      "         -4.2579, -0.8545, -0.4949,  0.1112, -0.4949, -0.4949],\n",
      "        [-2.7087, -2.5666, -2.4017, -2.1605, -1.9248, -1.8103, -1.7185, -1.1835,\n",
      "         -1.1733, -1.1733, -1.1733, -1.1733, -1.1733, -0.8299, -0.6281, -0.4949,\n",
      "         -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,  0.3489, -0.4949, -4.2579,\n",
      "         -0.8545, -0.4949,  0.1112, -0.4949, -0.4949, -0.4949],\n",
      "        [-2.5666, -2.4017, -2.1605, -1.9248, -1.8103, -1.7185, -1.1835, -1.1733,\n",
      "         -1.1733, -1.1733, -1.1733, -1.1733, -0.8299, -0.6281, -0.4949, -0.2059,\n",
      "         -0.4949, -0.4949, -0.5865, -0.4949,  0.3489, -0.4949, -4.2579, -0.8545,\n",
      "         -0.4949,  0.1112, -0.4949, -0.4949, -0.4949, -0.4949],\n",
      "        [-2.4017, -2.1605, -1.9248, -1.8103, -1.7185, -1.1835, -1.1733, -1.1733,\n",
      "         -1.1733, -1.1733, -1.1733, -0.8299, -0.6281, -0.4949, -0.2059, -0.4949,\n",
      "         -0.4949, -0.5865, -0.4949,  0.3489, -0.4949, -4.2579, -0.8545, -0.4949,\n",
      "          0.1112, -0.4949, -0.4949, -0.4949, -0.4949, -0.4305],\n",
      "        [-2.1605, -1.9248, -1.8103, -1.7185, -1.1835, -1.1733, -1.1733, -1.1733,\n",
      "         -1.1733, -1.1733, -0.8299, -0.6281, -0.4949, -0.2059, -0.4949, -0.4949,\n",
      "         -0.5865, -0.4949,  0.3489, -0.4949, -4.2579, -0.8545, -0.4949,  0.1112,\n",
      "         -0.4949, -0.4949, -0.4949, -0.4949, -0.4305, -0.4949],\n",
      "        [-1.9248, -1.8103, -1.7185, -1.1835, -1.1733, -1.1733, -1.1733, -1.1733,\n",
      "         -1.1733, -0.8299, -0.6281, -0.4949, -0.2059, -0.4949, -0.4949, -0.5865,\n",
      "         -0.4949,  0.3489, -0.4949, -4.2579, -0.8545, -0.4949,  0.1112, -0.4949,\n",
      "         -0.4949, -0.4949, -0.4949, -0.4305, -0.4949, -0.4949],\n",
      "        [-1.8103, -1.7185, -1.1835, -1.1733, -1.1733, -1.1733, -1.1733, -1.1733,\n",
      "         -0.8299, -0.6281, -0.4949, -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,\n",
      "          0.3489, -0.4949, -4.2579, -0.8545, -0.4949,  0.1112, -0.4949, -0.4949,\n",
      "         -0.4949, -0.4949, -0.4305, -0.4949, -0.4949, -0.4949],\n",
      "        [-1.7185, -1.1835, -1.1733, -1.1733, -1.1733, -1.1733, -1.1733, -0.8299,\n",
      "         -0.6281, -0.4949, -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,  0.3489,\n",
      "         -0.4949, -4.2579, -0.8545, -0.4949,  0.1112, -0.4949, -0.4949, -0.4949,\n",
      "         -0.4949, -0.4305, -0.4949, -0.4949, -0.4949, -0.5093],\n",
      "        [-1.1835, -1.1733, -1.1733, -1.1733, -1.1733, -1.1733, -0.8299, -0.6281,\n",
      "         -0.4949, -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,  0.3489, -0.4949,\n",
      "         -4.2579, -0.8545, -0.4949,  0.1112, -0.4949, -0.4949, -0.4949, -0.4949,\n",
      "         -0.4305, -0.4949, -0.4949, -0.4949, -0.5093, -0.7743],\n",
      "        [-1.1733, -1.1733, -1.1733, -1.1733, -1.1733, -0.8299, -0.6281, -0.4949,\n",
      "         -0.2059, -0.4949, -0.4949, -0.5865, -0.4949,  0.3489, -0.4949, -4.2579,\n",
      "         -0.8545, -0.4949,  0.1112, -0.4949, -0.4949, -0.4949, -0.4949, -0.4305,\n",
      "         -0.4949, -0.4949, -0.4949, -0.5093, -0.7743, -0.4949],\n",
      "        [-1.1733, -1.1733, -1.1733, -1.1733, -0.8299, -0.6281, -0.4949, -0.2059,\n",
      "         -0.4949, -0.4949, -0.5865, -0.4949,  0.3489, -0.4949, -4.2579, -0.8545,\n",
      "         -0.4949,  0.1112, -0.4949, -0.4949, -0.4949, -0.4949, -0.4305, -0.4949,\n",
      "         -0.4949, -0.4949, -0.5093, -0.7743, -0.4949, -0.4949],\n",
      "        [-1.1733, -1.1733, -1.1733, -0.8299, -0.6281, -0.4949, -0.2059, -0.4949,\n",
      "         -0.4949, -0.5865, -0.4949,  0.3489, -0.4949, -4.2579, -0.8545, -0.4949,\n",
      "          0.1112, -0.4949, -0.4949, -0.4949, -0.4949, -0.4305, -0.4949, -0.4949,\n",
      "         -0.4949, -0.5093, -0.7743, -0.4949, -0.4949, -3.1274],\n",
      "        [-1.1733, -1.1733, -0.8299, -0.6281, -0.4949, -0.2059, -0.4949, -0.4949,\n",
      "         -0.5865, -0.4949,  0.3489, -0.4949, -4.2579, -0.8545, -0.4949,  0.1112,\n",
      "         -0.4949, -0.4949, -0.4949, -0.4949, -0.4305, -0.4949, -0.4949, -0.4949,\n",
      "         -0.5093, -0.7743, -0.4949, -0.4949, -3.1274, -1.0732]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 2, 3, 3, 0, 0, 3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7,\n",
      "         4, 6, 4, 7, 0, 4],\n",
      "        [6, 2, 3, 3, 0, 0, 3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4,\n",
      "         6, 4, 7, 0, 4, 0],\n",
      "        [2, 3, 3, 0, 0, 3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6,\n",
      "         4, 7, 0, 4, 0, 4],\n",
      "        [3, 3, 0, 0, 3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4,\n",
      "         7, 0, 4, 0, 4, 4],\n",
      "        [3, 0, 0, 3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7,\n",
      "         0, 4, 0, 4, 4, 4],\n",
      "        [0, 0, 3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0,\n",
      "         4, 0, 4, 4, 4, 4],\n",
      "        [0, 3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4,\n",
      "         0, 4, 4, 4, 4, 7],\n",
      "        [3, 0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [0, 1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [1, 8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4, 4,\n",
      "         4, 4, 7, 4, 4, 4],\n",
      "        [8, 6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4, 4, 4,\n",
      "         4, 7, 4, 4, 4, 7],\n",
      "        [6, 8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4, 4, 4, 4,\n",
      "         7, 4, 4, 4, 7, 7],\n",
      "        [8, 8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4, 4, 4, 4, 7,\n",
      "         4, 4, 4, 7, 7, 4],\n",
      "        [8, 8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4, 4, 4, 4, 7, 4,\n",
      "         4, 4, 7, 7, 4, 4],\n",
      "        [8, 8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4, 4, 4, 4, 7, 4, 4,\n",
      "         4, 7, 7, 4, 4, 7],\n",
      "        [8, 8, 7, 8, 4, 7, 4, 4, 7, 4, 6, 4, 7, 0, 4, 0, 4, 4, 4, 4, 7, 4, 4, 4,\n",
      "         7, 7, 4, 4, 7, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.4479, -2.3111, -2.1795, -2.0594, -1.9468, -1.8334, -1.7170, -1.5864,\n",
      "         -1.4595, -1.3383, -1.2082, -3.3765, -2.5646, -1.6091, -1.2361, -0.8473,\n",
      "         -0.6728, -0.5513, -0.4974, -0.3181, -0.4974, -0.4974, -0.4974, -0.2762,\n",
      "         -0.4974, -0.4974, -0.4974, -2.4414, -0.7426, -0.6863],\n",
      "        [-2.3111, -2.1795, -2.0594, -1.9468, -1.8334, -1.7170, -1.5864, -1.4595,\n",
      "         -1.3383, -1.2082, -3.3765, -2.5646, -1.6091, -1.2361, -0.8473, -0.6728,\n",
      "         -0.5513, -0.4974, -0.3181, -0.4974, -0.4974, -0.4974, -0.2762, -0.4974,\n",
      "         -0.4974, -0.4974, -2.4414, -0.7426, -0.6863, -0.6863],\n",
      "        [-2.1795, -2.0594, -1.9468, -1.8334, -1.7170, -1.5864, -1.4595, -1.3383,\n",
      "         -1.2082, -3.3765, -2.5646, -1.6091, -1.2361, -0.8473, -0.6728, -0.5513,\n",
      "         -0.4974, -0.3181, -0.4974, -0.4974, -0.4974, -0.2762, -0.4974, -0.4974,\n",
      "         -0.4974, -2.4414, -0.7426, -0.6863, -0.6863, -1.1821],\n",
      "        [-2.0594, -1.9468, -1.8334, -1.7170, -1.5864, -1.4595, -1.3383, -1.2082,\n",
      "         -3.3765, -2.5646, -1.6091, -1.2361, -0.8473, -0.6728, -0.5513, -0.4974,\n",
      "         -0.3181, -0.4974, -0.4974, -0.4974, -0.2762, -0.4974, -0.4974, -0.4974,\n",
      "         -2.4414, -0.7426, -0.6863, -0.6863, -1.1821, -1.6779],\n",
      "        [-1.9468, -1.8334, -1.7170, -1.5864, -1.4595, -1.3383, -1.2082, -3.3765,\n",
      "         -2.5646, -1.6091, -1.2361, -0.8473, -0.6728, -0.5513, -0.4974, -0.3181,\n",
      "         -0.4974, -0.4974, -0.4974, -0.2762, -0.4974, -0.4974, -0.4974, -2.4414,\n",
      "         -0.7426, -0.6863, -0.6863, -1.1821, -1.6779, -2.1737],\n",
      "        [-1.8334, -1.7170, -1.5864, -1.4595, -1.3383, -1.2082, -3.3765, -2.5646,\n",
      "         -1.6091, -1.2361, -0.8473, -0.6728, -0.5513, -0.4974, -0.3181, -0.4974,\n",
      "         -0.4974, -0.4974, -0.2762, -0.4974, -0.4974, -0.4974, -2.4414, -0.7426,\n",
      "         -0.6863, -0.6863, -1.1821, -1.6779, -2.1737, -1.6779],\n",
      "        [-1.7170, -1.5864, -1.4595, -1.3383, -1.2082, -3.3765, -2.5646, -1.6091,\n",
      "         -1.2361, -0.8473, -0.6728, -0.5513, -0.4974, -0.3181, -0.4974, -0.4974,\n",
      "         -0.4974, -0.2762, -0.4974, -0.4974, -0.4974, -2.4414, -0.7426, -0.6863,\n",
      "         -0.6863, -1.1821, -1.6779, -2.1737, -1.6779, -1.6779],\n",
      "        [-1.5864, -1.4595, -1.3383, -1.2082, -3.3765, -2.5646, -1.6091, -1.2361,\n",
      "         -0.8473, -0.6728, -0.5513, -0.4974, -0.3181, -0.4974, -0.4974, -0.4974,\n",
      "         -0.2762, -0.4974, -0.4974, -0.4974, -2.4414, -0.7426, -0.6863, -0.6863,\n",
      "         -1.1821, -1.6779, -2.1737, -1.6779, -1.6779, -1.6779],\n",
      "        [-1.4595, -1.3383, -1.2082, -3.3765, -2.5646, -1.6091, -1.2361, -0.8473,\n",
      "         -0.6728, -0.5513, -0.4974, -0.3181, -0.4974, -0.4974, -0.4974, -0.2762,\n",
      "         -0.4974, -0.4974, -0.4974, -2.4414, -0.7426, -0.6863, -0.6863, -1.1821,\n",
      "         -1.6779, -2.1737, -1.6779, -1.6779, -1.6779, -1.6779],\n",
      "        [-1.3383, -1.2082, -3.3765, -2.5646, -1.6091, -1.2361, -0.8473, -0.6728,\n",
      "         -0.5513, -0.4974, -0.3181, -0.4974, -0.4974, -0.4974, -0.2762, -0.4974,\n",
      "         -0.4974, -0.4974, -2.4414, -0.7426, -0.6863, -0.6863, -1.1821, -1.6779,\n",
      "         -2.1737, -1.6779, -1.6779, -1.6779, -1.6779, -1.1821],\n",
      "        [-1.2082, -3.3765, -2.5646, -1.6091, -1.2361, -0.8473, -0.6728, -0.5513,\n",
      "         -0.4974, -0.3181, -0.4974, -0.4974, -0.4974, -0.2762, -0.4974, -0.4974,\n",
      "         -0.4974, -2.4414, -0.7426, -0.6863, -0.6863, -1.1821, -1.6779, -2.1737,\n",
      "         -1.6779, -1.6779, -1.6779, -1.6779, -1.1821, -2.1636],\n",
      "        [-3.3765, -2.5646, -1.6091, -1.2361, -0.8473, -0.6728, -0.5513, -0.4974,\n",
      "         -0.3181, -0.4974, -0.4974, -0.4974, -0.2762, -0.4974, -0.4974, -0.4974,\n",
      "         -2.4414, -0.7426, -0.6863, -0.6863, -1.1821, -1.6779, -2.1737, -1.6779,\n",
      "         -1.6779, -1.6779, -1.6779, -1.1821, -2.1636, -1.6779],\n",
      "        [-2.5646, -1.6091, -1.2361, -0.8473, -0.6728, -0.5513, -0.4974, -0.3181,\n",
      "         -0.4974, -0.4974, -0.4974, -0.2762, -0.4974, -0.4974, -0.4974, -2.4414,\n",
      "         -0.7426, -0.6863, -0.6863, -1.1821, -1.6779, -2.1737, -1.6779, -1.6779,\n",
      "         -1.6779, -1.6779, -1.1821, -2.1636, -1.6779, -1.9450],\n",
      "        [-1.6091, -1.2361, -0.8473, -0.6728, -0.5513, -0.4974, -0.3181, -0.4974,\n",
      "         -0.4974, -0.4974, -0.2762, -0.4974, -0.4974, -0.4974, -2.4414, -0.7426,\n",
      "         -0.6863, -0.6863, -1.1821, -1.6779, -2.1737, -1.6779, -1.6779, -1.6779,\n",
      "         -1.6779, -1.1821, -2.1636, -1.6779, -1.9450, -1.6779],\n",
      "        [-1.2361, -0.8473, -0.6728, -0.5513, -0.4974, -0.3181, -0.4974, -0.4974,\n",
      "         -0.4974, -0.2762, -0.4974, -0.4974, -0.4974, -2.4414, -0.7426, -0.6863,\n",
      "         -0.6863, -1.1821, -1.6779, -2.1737, -1.6779, -1.6779, -1.6779, -1.6779,\n",
      "         -1.1821, -2.1636, -1.6779, -1.9450, -1.6779, -1.6779],\n",
      "        [-0.8473, -0.6728, -0.5513, -0.4974, -0.3181, -0.4974, -0.4974, -0.4974,\n",
      "         -0.2762, -0.4974, -0.4974, -0.4974, -2.4414, -0.7426, -0.6863, -0.6863,\n",
      "         -1.1821, -1.6779, -2.1737, -1.6779, -1.6779, -1.6779, -1.6779, -1.1821,\n",
      "         -2.1636, -1.6779, -1.9450, -1.6779, -1.6779, -2.1737]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7,\n",
      "         4, 4, 4, 7, 7, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4,\n",
      "         4, 4, 7, 7, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4,\n",
      "         4, 7, 7, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4,\n",
      "         7, 7, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [6, 7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 7],\n",
      "        [7, 0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 7, 8],\n",
      "        [0, 0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 7, 8, 7],\n",
      "        [0, 0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 7, 8, 7, 8],\n",
      "        [0, 1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 7, 8, 7, 8, 8],\n",
      "        [1, 5, 5, 4, 5, 4, 4, 4, 7, 4, 4, 4, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         7, 8, 7, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.0359, -2.8509, -2.6680, -2.4954, -2.3312, -2.1386, -1.9109, -1.6971,\n",
      "         -1.5039, -1.3240, -1.1977, -2.3690, -1.0131, -0.8746, -0.7732, -1.3201,\n",
      "         -1.2180, -1.3358, -1.0915, -0.8006, -0.8006, -0.8006, -0.4233, -2.0985,\n",
      "         -0.8006, -1.8857, -1.0859, -1.4822, -1.3890, -1.7570],\n",
      "        [-2.8509, -2.6680, -2.4954, -2.3312, -2.1386, -1.9109, -1.6971, -1.5039,\n",
      "         -1.3240, -1.1977, -2.3690, -1.0131, -0.8746, -0.7732, -1.3201, -1.2180,\n",
      "         -1.3358, -1.0915, -0.8006, -0.8006, -0.8006, -0.4233, -2.0985, -0.8006,\n",
      "         -1.8857, -1.0859, -1.4822, -1.3890, -1.7570, -1.5388],\n",
      "        [-2.6680, -2.4954, -2.3312, -2.1386, -1.9109, -1.6971, -1.5039, -1.3240,\n",
      "         -1.1977, -2.3690, -1.0131, -0.8746, -0.7732, -1.3201, -1.2180, -1.3358,\n",
      "         -1.0915, -0.8006, -0.8006, -0.8006, -0.4233, -2.0985, -0.8006, -1.8857,\n",
      "         -1.0859, -1.4822, -1.3890, -1.7570, -1.5388, -0.9200],\n",
      "        [-2.4954, -2.3312, -2.1386, -1.9109, -1.6971, -1.5039, -1.3240, -1.1977,\n",
      "         -2.3690, -1.0131, -0.8746, -0.7732, -1.3201, -1.2180, -1.3358, -1.0915,\n",
      "         -0.8006, -0.8006, -0.8006, -0.4233, -2.0985, -0.8006, -1.8857, -1.0859,\n",
      "         -1.4822, -1.3890, -1.7570, -1.5388, -0.9200, -0.7099],\n",
      "        [-2.3312, -2.1386, -1.9109, -1.6971, -1.5039, -1.3240, -1.1977, -2.3690,\n",
      "         -1.0131, -0.8746, -0.7732, -1.3201, -1.2180, -1.3358, -1.0915, -0.8006,\n",
      "         -0.8006, -0.8006, -0.4233, -2.0985, -0.8006, -1.8857, -1.0859, -1.4822,\n",
      "         -1.3890, -1.7570, -1.5388, -0.9200, -0.7099, -0.5431],\n",
      "        [-2.1386, -1.9109, -1.6971, -1.5039, -1.3240, -1.1977, -2.3690, -1.0131,\n",
      "         -0.8746, -0.7732, -1.3201, -1.2180, -1.3358, -1.0915, -0.8006, -0.8006,\n",
      "         -0.8006, -0.4233, -2.0985, -0.8006, -1.8857, -1.0859, -1.4822, -1.3890,\n",
      "         -1.7570, -1.5388, -0.9200, -0.7099, -0.5431, -0.5431],\n",
      "        [-1.9109, -1.6971, -1.5039, -1.3240, -1.1977, -2.3690, -1.0131, -0.8746,\n",
      "         -0.7732, -1.3201, -1.2180, -1.3358, -1.0915, -0.8006, -0.8006, -0.8006,\n",
      "         -0.4233, -2.0985, -0.8006, -1.8857, -1.0859, -1.4822, -1.3890, -1.7570,\n",
      "         -1.5388, -0.9200, -0.7099, -0.5431, -0.5431, -0.5431],\n",
      "        [-1.6971, -1.5039, -1.3240, -1.1977, -2.3690, -1.0131, -0.8746, -0.7732,\n",
      "         -1.3201, -1.2180, -1.3358, -1.0915, -0.8006, -0.8006, -0.8006, -0.4233,\n",
      "         -2.0985, -0.8006, -1.8857, -1.0859, -1.4822, -1.3890, -1.7570, -1.5388,\n",
      "         -0.9200, -0.7099, -0.5431, -0.5431, -0.5431, -0.0157],\n",
      "        [-1.5039, -1.3240, -1.1977, -2.3690, -1.0131, -0.8746, -0.7732, -1.3201,\n",
      "         -1.2180, -1.3358, -1.0915, -0.8006, -0.8006, -0.8006, -0.4233, -2.0985,\n",
      "         -0.8006, -1.8857, -1.0859, -1.4822, -1.3890, -1.7570, -1.5388, -0.9200,\n",
      "         -0.7099, -0.5431, -0.5431, -0.5431, -0.0157, -0.5431],\n",
      "        [-1.3240, -1.1977, -2.3690, -1.0131, -0.8746, -0.7732, -1.3201, -1.2180,\n",
      "         -1.3358, -1.0915, -0.8006, -0.8006, -0.8006, -0.4233, -2.0985, -0.8006,\n",
      "         -1.8857, -1.0859, -1.4822, -1.3890, -1.7570, -1.5388, -0.9200, -0.7099,\n",
      "         -0.5431, -0.5431, -0.5431, -0.0157, -0.5431, -0.5431],\n",
      "        [-1.1977, -2.3690, -1.0131, -0.8746, -0.7732, -1.3201, -1.2180, -1.3358,\n",
      "         -1.0915, -0.8006, -0.8006, -0.8006, -0.4233, -2.0985, -0.8006, -1.8857,\n",
      "         -1.0859, -1.4822, -1.3890, -1.7570, -1.5388, -0.9200, -0.7099, -0.5431,\n",
      "         -0.5431, -0.5431, -0.0157, -0.5431, -0.5431, -0.5431],\n",
      "        [-2.3690, -1.0131, -0.8746, -0.7732, -1.3201, -1.2180, -1.3358, -1.0915,\n",
      "         -0.8006, -0.8006, -0.8006, -0.4233, -2.0985, -0.8006, -1.8857, -1.0859,\n",
      "         -1.4822, -1.3890, -1.7570, -1.5388, -0.9200, -0.7099, -0.5431, -0.5431,\n",
      "         -0.5431, -0.0157, -0.5431, -0.5431, -0.5431, -0.5431],\n",
      "        [-1.0131, -0.8746, -0.7732, -1.3201, -1.2180, -1.3358, -1.0915, -0.8006,\n",
      "         -0.8006, -0.8006, -0.4233, -2.0985, -0.8006, -1.8857, -1.0859, -1.4822,\n",
      "         -1.3890, -1.7570, -1.5388, -0.9200, -0.7099, -0.5431, -0.5431, -0.5431,\n",
      "         -0.0157, -0.5431, -0.5431, -0.5431, -0.5431,  0.4132],\n",
      "        [-0.8746, -0.7732, -1.3201, -1.2180, -1.3358, -1.0915, -0.8006, -0.8006,\n",
      "         -0.8006, -0.4233, -2.0985, -0.8006, -1.8857, -1.0859, -1.4822, -1.3890,\n",
      "         -1.7570, -1.5388, -0.9200, -0.7099, -0.5431, -0.5431, -0.5431, -0.0157,\n",
      "         -0.5431, -0.5431, -0.5431, -0.5431,  0.4132, -0.5431],\n",
      "        [-0.7732, -1.3201, -1.2180, -1.3358, -1.0915, -0.8006, -0.8006, -0.8006,\n",
      "         -0.4233, -2.0985, -0.8006, -1.8857, -1.0859, -1.4822, -1.3890, -1.7570,\n",
      "         -1.5388, -0.9200, -0.7099, -0.5431, -0.5431, -0.5431, -0.0157, -0.5431,\n",
      "         -0.5431, -0.5431, -0.5431,  0.4132, -0.5431, -0.5431],\n",
      "        [-1.3201, -1.2180, -1.3358, -1.0915, -0.8006, -0.8006, -0.8006, -0.4233,\n",
      "         -2.0985, -0.8006, -1.8857, -1.0859, -1.4822, -1.3890, -1.7570, -1.5388,\n",
      "         -0.9200, -0.7099, -0.5431, -0.5431, -0.5431, -0.0157, -0.5431, -0.5431,\n",
      "         -0.5431, -0.5431,  0.4132, -0.5431, -0.5431, -0.8798]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7,\n",
      "         8, 7, 1, 3, 0, 3],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8,\n",
      "         7, 1, 3, 0, 3, 0],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7,\n",
      "         1, 3, 0, 3, 0, 0],\n",
      "        [5, 5, 5, 5, 5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1,\n",
      "         3, 0, 3, 0, 0, 0],\n",
      "        [5, 5, 5, 5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3,\n",
      "         0, 3, 0, 0, 0, 4],\n",
      "        [5, 5, 5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0,\n",
      "         3, 0, 0, 0, 4, 4],\n",
      "        [5, 5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3,\n",
      "         0, 0, 0, 4, 4, 4],\n",
      "        [5, 5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0,\n",
      "         0, 0, 4, 4, 4, 7],\n",
      "        [5, 6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0,\n",
      "         0, 4, 4, 4, 7, 4],\n",
      "        [6, 6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0, 0,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [6, 7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0, 0, 4,\n",
      "         4, 4, 7, 4, 4, 4],\n",
      "        [7, 2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0, 0, 4, 4,\n",
      "         4, 7, 4, 4, 4, 4],\n",
      "        [2, 6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0, 0, 4, 4, 4,\n",
      "         7, 4, 4, 4, 4, 7],\n",
      "        [6, 6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0, 0, 4, 4, 4, 7,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [6, 0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0, 0, 4, 4, 4, 7, 4,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [0, 1, 8, 7, 8, 8, 8, 7, 7, 8, 7, 1, 3, 0, 3, 0, 0, 0, 4, 4, 4, 7, 4, 4,\n",
      "         4, 4, 7, 4, 4, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.9851, -1.9076, -1.8089, -1.7284, -1.6400, -1.5463, -1.4562, -2.5424,\n",
      "         -1.3102, -2.2899, -1.5640, -1.8714, -1.7569, -2.0800, -1.8663, -1.4145,\n",
      "         -1.2610, -0.7615, -0.6600, -0.5388, -0.4202, -0.5365, -0.5365, -0.5365,\n",
      "         -0.5365,  0.2432, -0.5365, -0.5365, -1.0960, -0.5365],\n",
      "        [-1.9076, -1.8089, -1.7284, -1.6400, -1.5463, -1.4562, -2.5424, -1.3102,\n",
      "         -2.2899, -1.5640, -1.8714, -1.7569, -2.0800, -1.8663, -1.4145, -1.2610,\n",
      "         -0.7615, -0.6600, -0.5388, -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,\n",
      "          0.2432, -0.5365, -0.5365, -1.0960, -0.5365, -0.7583],\n",
      "        [-1.8089, -1.7284, -1.6400, -1.5463, -1.4562, -2.5424, -1.3102, -2.2899,\n",
      "         -1.5640, -1.8714, -1.7569, -2.0800, -1.8663, -1.4145, -1.2610, -0.7615,\n",
      "         -0.6600, -0.5388, -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,  0.2432,\n",
      "         -0.5365, -0.5365, -1.0960, -0.5365, -0.7583, -0.5365],\n",
      "        [-1.7284, -1.6400, -1.5463, -1.4562, -2.5424, -1.3102, -2.2899, -1.5640,\n",
      "         -1.8714, -1.7569, -2.0800, -1.8663, -1.4145, -1.2610, -0.7615, -0.6600,\n",
      "         -0.5388, -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,  0.2432, -0.5365,\n",
      "         -0.5365, -1.0960, -0.5365, -0.7583, -0.5365, -0.5365],\n",
      "        [-1.6400, -1.5463, -1.4562, -2.5424, -1.3102, -2.2899, -1.5640, -1.8714,\n",
      "         -1.7569, -2.0800, -1.8663, -1.4145, -1.2610, -0.7615, -0.6600, -0.5388,\n",
      "         -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,  0.2432, -0.5365, -0.5365,\n",
      "         -1.0960, -0.5365, -0.7583, -0.5365, -0.5365, -0.6558],\n",
      "        [-1.5463, -1.4562, -2.5424, -1.3102, -2.2899, -1.5640, -1.8714, -1.7569,\n",
      "         -2.0800, -1.8663, -1.4145, -1.2610, -0.7615, -0.6600, -0.5388, -0.4202,\n",
      "         -0.5365, -0.5365, -0.5365, -0.5365,  0.2432, -0.5365, -0.5365, -1.0960,\n",
      "         -0.5365, -0.7583, -0.5365, -0.5365, -0.6558, -0.5365],\n",
      "        [-1.4562, -2.5424, -1.3102, -2.2899, -1.5640, -1.8714, -1.7569, -2.0800,\n",
      "         -1.8663, -1.4145, -1.2610, -0.7615, -0.6600, -0.5388, -0.4202, -0.5365,\n",
      "         -0.5365, -0.5365, -0.5365,  0.2432, -0.5365, -0.5365, -1.0960, -0.5365,\n",
      "         -0.7583, -0.5365, -0.5365, -0.6558, -0.5365, -0.1992],\n",
      "        [-2.5424, -1.3102, -2.2899, -1.5640, -1.8714, -1.7569, -2.0800, -1.8663,\n",
      "         -1.4145, -1.2610, -0.7615, -0.6600, -0.5388, -0.4202, -0.5365, -0.5365,\n",
      "         -0.5365, -0.5365,  0.2432, -0.5365, -0.5365, -1.0960, -0.5365, -0.7583,\n",
      "         -0.5365, -0.5365, -0.6558, -0.5365, -0.1992, -0.5365],\n",
      "        [-1.3102, -2.2899, -1.5640, -1.8714, -1.7569, -2.0800, -1.8663, -1.4145,\n",
      "         -1.2610, -0.7615, -0.6600, -0.5388, -0.4202, -0.5365, -0.5365, -0.5365,\n",
      "         -0.5365,  0.2432, -0.5365, -0.5365, -1.0960, -0.5365, -0.7583, -0.5365,\n",
      "         -0.5365, -0.6558, -0.5365, -0.1992, -0.5365, -0.6479],\n",
      "        [-2.2899, -1.5640, -1.8714, -1.7569, -2.0800, -1.8663, -1.4145, -1.2610,\n",
      "         -0.7615, -0.6600, -0.5388, -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,\n",
      "          0.2432, -0.5365, -0.5365, -1.0960, -0.5365, -0.7583, -0.5365, -0.5365,\n",
      "         -0.6558, -0.5365, -0.1992, -0.5365, -0.6479, -3.3850],\n",
      "        [-1.5640, -1.8714, -1.7569, -2.0800, -1.8663, -1.4145, -1.2610, -0.7615,\n",
      "         -0.6600, -0.5388, -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,  0.2432,\n",
      "         -0.5365, -0.5365, -1.0960, -0.5365, -0.7583, -0.5365, -0.5365, -0.6558,\n",
      "         -0.5365, -0.1992, -0.5365, -0.6479, -3.3850, -1.0966],\n",
      "        [-1.8714, -1.7569, -2.0800, -1.8663, -1.4145, -1.2610, -0.7615, -0.6600,\n",
      "         -0.5388, -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,  0.2432, -0.5365,\n",
      "         -0.5365, -1.0960, -0.5365, -0.7583, -0.5365, -0.5365, -0.6558, -0.5365,\n",
      "         -0.1992, -0.5365, -0.6479, -3.3850, -1.0966, -1.0966],\n",
      "        [-1.7569, -2.0800, -1.8663, -1.4145, -1.2610, -0.7615, -0.6600, -0.5388,\n",
      "         -0.4202, -0.5365, -0.5365, -0.5365, -0.5365,  0.2432, -0.5365, -0.5365,\n",
      "         -1.0960, -0.5365, -0.7583, -0.5365, -0.5365, -0.6558, -0.5365, -0.1992,\n",
      "         -0.5365, -0.6479, -3.3850, -1.0966, -1.0966, -1.0966],\n",
      "        [-2.0800, -1.8663, -1.4145, -1.2610, -0.7615, -0.6600, -0.5388, -0.4202,\n",
      "         -0.5365, -0.5365, -0.5365, -0.5365,  0.2432, -0.5365, -0.5365, -1.0960,\n",
      "         -0.5365, -0.7583, -0.5365, -0.5365, -0.6558, -0.5365, -0.1992, -0.5365,\n",
      "         -0.6479, -3.3850, -1.0966, -1.0966, -1.0966, -1.5452],\n",
      "        [-1.8663, -1.4145, -1.2610, -0.7615, -0.6600, -0.5388, -0.4202, -0.5365,\n",
      "         -0.5365, -0.5365, -0.5365,  0.2432, -0.5365, -0.5365, -1.0960, -0.5365,\n",
      "         -0.7583, -0.5365, -0.5365, -0.6558, -0.5365, -0.1992, -0.5365, -0.6479,\n",
      "         -3.3850, -1.0966, -1.0966, -1.0966, -1.5452, -3.0893],\n",
      "        [-1.4145, -1.2610, -0.7615, -0.6600, -0.5388, -0.4202, -0.5365, -0.5365,\n",
      "         -0.5365, -0.5365,  0.2432, -0.5365, -0.5365, -1.0960, -0.5365, -0.7583,\n",
      "         -0.5365, -0.5365, -0.6558, -0.5365, -0.1992, -0.5365, -0.6479, -3.3850,\n",
      "         -1.0966, -1.0966, -1.0966, -1.5452, -3.0893, -1.0966]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4,\n",
      "         4, 6, 4, 4, 7, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4,\n",
      "         6, 4, 4, 7, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [6, 6, 6, 6, 7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [6, 6, 6, 7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4,\n",
      "         7, 4, 7, 4, 4, 7],\n",
      "        [6, 6, 7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [6, 7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4,\n",
      "         7, 4, 4, 7, 4, 8],\n",
      "        [7, 6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7,\n",
      "         4, 4, 7, 4, 8, 4],\n",
      "        [6, 7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4,\n",
      "         4, 7, 4, 8, 4, 8],\n",
      "        [7, 3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4, 4,\n",
      "         7, 4, 8, 4, 8, 7],\n",
      "        [3, 3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4, 4, 7,\n",
      "         4, 8, 4, 8, 7, 8],\n",
      "        [3, 0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4, 4, 7, 4,\n",
      "         8, 4, 8, 7, 8, 8],\n",
      "        [0, 3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4, 4, 7, 4, 8,\n",
      "         4, 8, 7, 8, 8, 8],\n",
      "        [3, 0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4, 4, 7, 4, 8, 4,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [0, 0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4, 4, 7, 4, 8, 4, 8,\n",
      "         7, 8, 8, 8, 8, 7],\n",
      "        [0, 0, 5, 5, 5, 5, 4, 4, 4, 4, 6, 4, 4, 7, 4, 7, 4, 4, 7, 4, 8, 4, 8, 7,\n",
      "         8, 8, 8, 8, 7, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.1428, -3.0067, -2.8635, -2.6925, -2.5249, -2.3372, -2.1208, -1.9067,\n",
      "         -1.7208, -1.5502, -1.3619, -1.1631, -0.9777, -0.8032, -0.6356, -0.4943,\n",
      "         -0.4942, -0.4996, -0.4942, -0.0120, -0.4942, -0.4942, -2.9783, -1.7680,\n",
      "         -0.7444, -0.7444, -1.1703, -2.7098, -1.8187, -2.2548],\n",
      "        [-3.0067, -2.8635, -2.6925, -2.5249, -2.3372, -2.1208, -1.9067, -1.7208,\n",
      "         -1.5502, -1.3619, -1.1631, -0.9777, -0.8032, -0.6356, -0.4943, -0.4942,\n",
      "         -0.4996, -0.4942, -0.0120, -0.4942, -0.4942, -2.9783, -1.7680, -0.7444,\n",
      "         -0.7444, -1.1703, -2.7098, -1.8187, -2.2548, -1.4685],\n",
      "        [-2.8635, -2.6925, -2.5249, -2.3372, -2.1208, -1.9067, -1.7208, -1.5502,\n",
      "         -1.3619, -1.1631, -0.9777, -0.8032, -0.6356, -0.4943, -0.4942, -0.4996,\n",
      "         -0.4942, -0.0120, -0.4942, -0.4942, -2.9783, -1.7680, -0.7444, -0.7444,\n",
      "         -1.1703, -2.7098, -1.8187, -2.2548, -1.4685, -1.1327],\n",
      "        [-2.6925, -2.5249, -2.3372, -2.1208, -1.9067, -1.7208, -1.5502, -1.3619,\n",
      "         -1.1631, -0.9777, -0.8032, -0.6356, -0.4943, -0.4942, -0.4996, -0.4942,\n",
      "         -0.0120, -0.4942, -0.4942, -2.9783, -1.7680, -0.7444, -0.7444, -1.1703,\n",
      "         -2.7098, -1.8187, -2.2548, -1.4685, -1.1327, -0.9593],\n",
      "        [-2.5249, -2.3372, -2.1208, -1.9067, -1.7208, -1.5502, -1.3619, -1.1631,\n",
      "         -0.9777, -0.8032, -0.6356, -0.4943, -0.4942, -0.4996, -0.4942, -0.0120,\n",
      "         -0.4942, -0.4942, -2.9783, -1.7680, -0.7444, -0.7444, -1.1703, -2.7098,\n",
      "         -1.8187, -2.2548, -1.4685, -1.1327, -0.9593, -1.1703],\n",
      "        [-2.3372, -2.1208, -1.9067, -1.7208, -1.5502, -1.3619, -1.1631, -0.9777,\n",
      "         -0.8032, -0.6356, -0.4943, -0.4942, -0.4996, -0.4942, -0.0120, -0.4942,\n",
      "         -0.4942, -2.9783, -1.7680, -0.7444, -0.7444, -1.1703, -2.7098, -1.8187,\n",
      "         -2.2548, -1.4685, -1.1327, -0.9593, -1.1703, -1.5961],\n",
      "        [-2.1208, -1.9067, -1.7208, -1.5502, -1.3619, -1.1631, -0.9777, -0.8032,\n",
      "         -0.6356, -0.4943, -0.4942, -0.4996, -0.4942, -0.0120, -0.4942, -0.4942,\n",
      "         -2.9783, -1.7680, -0.7444, -0.7444, -1.1703, -2.7098, -1.8187, -2.2548,\n",
      "         -1.4685, -1.1327, -0.9593, -1.1703, -1.5961, -1.6623],\n",
      "        [-1.9067, -1.7208, -1.5502, -1.3619, -1.1631, -0.9777, -0.8032, -0.6356,\n",
      "         -0.4943, -0.4942, -0.4996, -0.4942, -0.0120, -0.4942, -0.4942, -2.9783,\n",
      "         -1.7680, -0.7444, -0.7444, -1.1703, -2.7098, -1.8187, -2.2548, -1.4685,\n",
      "         -1.1327, -0.9593, -1.1703, -1.5961, -1.6623, -0.7444],\n",
      "        [-1.7208, -1.5502, -1.3619, -1.1631, -0.9777, -0.8032, -0.6356, -0.4943,\n",
      "         -0.4942, -0.4996, -0.4942, -0.0120, -0.4942, -0.4942, -2.9783, -1.7680,\n",
      "         -0.7444, -0.7444, -1.1703, -2.7098, -1.8187, -2.2548, -1.4685, -1.1327,\n",
      "         -0.9593, -1.1703, -1.5961, -1.6623, -0.7444, -0.4942],\n",
      "        [-1.5502, -1.3619, -1.1631, -0.9777, -0.8032, -0.6356, -0.4943, -0.4942,\n",
      "         -0.4996, -0.4942, -0.0120, -0.4942, -0.4942, -2.9783, -1.7680, -0.7444,\n",
      "         -0.7444, -1.1703, -2.7098, -1.8187, -2.2548, -1.4685, -1.1327, -0.9593,\n",
      "         -1.1703, -1.5961, -1.6623, -0.7444, -0.4942, -0.4942],\n",
      "        [-1.3619, -1.1631, -0.9777, -0.8032, -0.6356, -0.4943, -0.4942, -0.4996,\n",
      "         -0.4942, -0.0120, -0.4942, -0.4942, -2.9783, -1.7680, -0.7444, -0.7444,\n",
      "         -1.1703, -2.7098, -1.8187, -2.2548, -1.4685, -1.1327, -0.9593, -1.1703,\n",
      "         -1.5961, -1.6623, -0.7444, -0.4942, -0.4942, -1.3200],\n",
      "        [-1.1631, -0.9777, -0.8032, -0.6356, -0.4943, -0.4942, -0.4996, -0.4942,\n",
      "         -0.0120, -0.4942, -0.4942, -2.9783, -1.7680, -0.7444, -0.7444, -1.1703,\n",
      "         -2.7098, -1.8187, -2.2548, -1.4685, -1.1327, -0.9593, -1.1703, -1.5961,\n",
      "         -1.6623, -0.7444, -0.4942, -0.4942, -1.3200, -0.4942],\n",
      "        [-0.9777, -0.8032, -0.6356, -0.4943, -0.4942, -0.4996, -0.4942, -0.0120,\n",
      "         -0.4942, -0.4942, -2.9783, -1.7680, -0.7444, -0.7444, -1.1703, -2.7098,\n",
      "         -1.8187, -2.2548, -1.4685, -1.1327, -0.9593, -1.1703, -1.5961, -1.6623,\n",
      "         -0.7444, -0.4942, -0.4942, -1.3200, -0.4942, -0.4942],\n",
      "        [-0.8032, -0.6356, -0.4943, -0.4942, -0.4996, -0.4942, -0.0120, -0.4942,\n",
      "         -0.4942, -2.9783, -1.7680, -0.7444, -0.7444, -1.1703, -2.7098, -1.8187,\n",
      "         -2.2548, -1.4685, -1.1327, -0.9593, -1.1703, -1.5961, -1.6623, -0.7444,\n",
      "         -0.4942, -0.4942, -1.3200, -0.4942, -0.4942, -0.8363],\n",
      "        [-0.6356, -0.4943, -0.4942, -0.4996, -0.4942, -0.0120, -0.4942, -0.4942,\n",
      "         -2.9783, -1.7680, -0.7444, -0.7444, -1.1703, -2.7098, -1.8187, -2.2548,\n",
      "         -1.4685, -1.1327, -0.9593, -1.1703, -1.5961, -1.6623, -0.7444, -0.4942,\n",
      "         -0.4942, -1.3200, -0.4942, -0.4942, -0.8363,  0.1073],\n",
      "        [-0.4943, -0.4942, -0.4996, -0.4942, -0.0120, -0.4942, -0.4942, -2.9783,\n",
      "         -1.7680, -0.7444, -0.7444, -1.1703, -2.7098, -1.8187, -2.2548, -1.4685,\n",
      "         -1.1327, -0.9593, -1.1703, -1.5961, -1.6623, -0.7444, -0.4942, -0.4942,\n",
      "         -1.3200, -0.4942, -0.4942, -0.8363,  0.1073, -0.4942]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0,\n",
      "         8, 8, 8, 7, 3, 1],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8,\n",
      "         8, 8, 7, 3, 1, 0],\n",
      "        [5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8,\n",
      "         8, 7, 3, 1, 0, 1],\n",
      "        [5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8,\n",
      "         7, 3, 1, 0, 1, 2],\n",
      "        [5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7,\n",
      "         3, 1, 0, 1, 2, 8],\n",
      "        [5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3,\n",
      "         1, 0, 1, 2, 8, 8],\n",
      "        [5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1,\n",
      "         0, 1, 2, 8, 8, 0],\n",
      "        [5, 6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0,\n",
      "         1, 2, 8, 8, 0, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1,\n",
      "         2, 8, 8, 0, 8, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1, 2,\n",
      "         8, 8, 0, 8, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1, 2, 8,\n",
      "         8, 0, 8, 4, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1, 2, 8, 8,\n",
      "         0, 8, 4, 4, 7, 4],\n",
      "        [6, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1, 2, 8, 8, 0,\n",
      "         8, 4, 4, 7, 4, 4],\n",
      "        [6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1, 2, 8, 8, 0, 8,\n",
      "         4, 4, 7, 4, 4, 7],\n",
      "        [6, 6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1, 2, 8, 8, 0, 8, 4,\n",
      "         4, 7, 4, 4, 7, 8],\n",
      "        [6, 4, 7, 4, 6, 4, 4, 7, 0, 8, 8, 8, 7, 3, 1, 0, 1, 2, 8, 8, 0, 8, 4, 4,\n",
      "         7, 4, 4, 7, 8, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.5436, -2.3459, -2.1816, -2.0113, -1.8366, -1.6681, -3.2395, -1.7850,\n",
      "         -1.3726, -1.2344, -1.2561, -2.9567, -1.8418, -2.1790, -1.5440, -1.3006,\n",
      "         -1.1669, -1.2561, -1.7823, -1.6999, -0.7298, -0.4961, -0.4961, -1.4936,\n",
      "         -0.4961, -0.4961, -0.9844,  0.3228, -0.4961, -0.4961],\n",
      "        [-2.3459, -2.1816, -2.0113, -1.8366, -1.6681, -3.2395, -1.7850, -1.3726,\n",
      "         -1.2344, -1.2561, -2.9567, -1.8418, -2.1790, -1.5440, -1.3006, -1.1669,\n",
      "         -1.2561, -1.7823, -1.6999, -0.7298, -0.4961, -0.4961, -1.4936, -0.4961,\n",
      "         -0.4961, -0.9844,  0.3228, -0.4961, -0.4961, -0.8329],\n",
      "        [-2.1816, -2.0113, -1.8366, -1.6681, -3.2395, -1.7850, -1.3726, -1.2344,\n",
      "         -1.2561, -2.9567, -1.8418, -2.1790, -1.5440, -1.3006, -1.1669, -1.2561,\n",
      "         -1.7823, -1.6999, -0.7298, -0.4961, -0.4961, -1.4936, -0.4961, -0.4961,\n",
      "         -0.9844,  0.3228, -0.4961, -0.4961, -0.8329, -0.4961],\n",
      "        [-2.0113, -1.8366, -1.6681, -3.2395, -1.7850, -1.3726, -1.2344, -1.2561,\n",
      "         -2.9567, -1.8418, -2.1790, -1.5440, -1.3006, -1.1669, -1.2561, -1.7823,\n",
      "         -1.6999, -0.7298, -0.4961, -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,\n",
      "          0.3228, -0.4961, -0.4961, -0.8329, -0.4961,  0.0269],\n",
      "        [-1.8366, -1.6681, -3.2395, -1.7850, -1.3726, -1.2344, -1.2561, -2.9567,\n",
      "         -1.8418, -2.1790, -1.5440, -1.3006, -1.1669, -1.2561, -1.7823, -1.6999,\n",
      "         -0.7298, -0.4961, -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,  0.3228,\n",
      "         -0.4961, -0.4961, -0.8329, -0.4961,  0.0269, -0.4961],\n",
      "        [-1.6681, -3.2395, -1.7850, -1.3726, -1.2344, -1.2561, -2.9567, -1.8418,\n",
      "         -2.1790, -1.5440, -1.3006, -1.1669, -1.2561, -1.7823, -1.6999, -0.7298,\n",
      "         -0.4961, -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,  0.3228, -0.4961,\n",
      "         -0.4961, -0.8329, -0.4961,  0.0269, -0.4961, -0.4961],\n",
      "        [-3.2395, -1.7850, -1.3726, -1.2344, -1.2561, -2.9567, -1.8418, -2.1790,\n",
      "         -1.5440, -1.3006, -1.1669, -1.2561, -1.7823, -1.6999, -0.7298, -0.4961,\n",
      "         -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,  0.3228, -0.4961, -0.4961,\n",
      "         -0.8329, -0.4961,  0.0269, -0.4961, -0.4961, -0.8846],\n",
      "        [-1.7850, -1.3726, -1.2344, -1.2561, -2.9567, -1.8418, -2.1790, -1.5440,\n",
      "         -1.3006, -1.1669, -1.2561, -1.7823, -1.6999, -0.7298, -0.4961, -0.4961,\n",
      "         -1.4936, -0.4961, -0.4961, -0.9844,  0.3228, -0.4961, -0.4961, -0.8329,\n",
      "         -0.4961,  0.0269, -0.4961, -0.4961, -0.8846, -0.4961],\n",
      "        [-1.3726, -1.2344, -1.2561, -2.9567, -1.8418, -2.1790, -1.5440, -1.3006,\n",
      "         -1.1669, -1.2561, -1.7823, -1.6999, -0.7298, -0.4961, -0.4961, -1.4936,\n",
      "         -0.4961, -0.4961, -0.9844,  0.3228, -0.4961, -0.4961, -0.8329, -0.4961,\n",
      "          0.0269, -0.4961, -0.4961, -0.8846, -0.4961, -1.4145],\n",
      "        [-1.2344, -1.2561, -2.9567, -1.8418, -2.1790, -1.5440, -1.3006, -1.1669,\n",
      "         -1.2561, -1.7823, -1.6999, -0.7298, -0.4961, -0.4961, -1.4936, -0.4961,\n",
      "         -0.4961, -0.9844,  0.3228, -0.4961, -0.4961, -0.8329, -0.4961,  0.0269,\n",
      "         -0.4961, -0.4961, -0.8846, -0.4961, -1.4145, -0.4961],\n",
      "        [-1.2561, -2.9567, -1.8418, -2.1790, -1.5440, -1.3006, -1.1669, -1.2561,\n",
      "         -1.7823, -1.6999, -0.7298, -0.4961, -0.4961, -1.4936, -0.4961, -0.4961,\n",
      "         -0.9844,  0.3228, -0.4961, -0.4961, -0.8329, -0.4961,  0.0269, -0.4961,\n",
      "         -0.4961, -0.8846, -0.4961, -1.4145, -0.4961, -0.4961],\n",
      "        [-2.9567, -1.8418, -2.1790, -1.5440, -1.3006, -1.1669, -1.2561, -1.7823,\n",
      "         -1.6999, -0.7298, -0.4961, -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,\n",
      "          0.3228, -0.4961, -0.4961, -0.8329, -0.4961,  0.0269, -0.4961, -0.4961,\n",
      "         -0.8846, -0.4961, -1.4145, -0.4961, -0.4961, -0.4961],\n",
      "        [-1.8418, -2.1790, -1.5440, -1.3006, -1.1669, -1.2561, -1.7823, -1.6999,\n",
      "         -0.7298, -0.4961, -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,  0.3228,\n",
      "         -0.4961, -0.4961, -0.8329, -0.4961,  0.0269, -0.4961, -0.4961, -0.8846,\n",
      "         -0.4961, -1.4145, -0.4961, -0.4961, -0.4961, -0.4961],\n",
      "        [-2.1790, -1.5440, -1.3006, -1.1669, -1.2561, -1.7823, -1.6999, -0.7298,\n",
      "         -0.4961, -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,  0.3228, -0.4961,\n",
      "         -0.4961, -0.8329, -0.4961,  0.0269, -0.4961, -0.4961, -0.8846, -0.4961,\n",
      "         -1.4145, -0.4961, -0.4961, -0.4961, -0.4961,  0.3634],\n",
      "        [-1.5440, -1.3006, -1.1669, -1.2561, -1.7823, -1.6999, -0.7298, -0.4961,\n",
      "         -0.4961, -1.4936, -0.4961, -0.4961, -0.9844,  0.3228, -0.4961, -0.4961,\n",
      "         -0.8329, -0.4961,  0.0269, -0.4961, -0.4961, -0.8846, -0.4961, -1.4145,\n",
      "         -0.4961, -0.4961, -0.4961, -0.4961,  0.3634, -0.4961],\n",
      "        [-1.3006, -1.1669, -1.2561, -1.7823, -1.6999, -0.7298, -0.4961, -0.4961,\n",
      "         -1.4936, -0.4961, -0.4961, -0.9844,  0.3228, -0.4961, -0.4961, -0.8329,\n",
      "         -0.4961,  0.0269, -0.4961, -0.4961, -0.8846, -0.4961, -1.4145, -0.4961,\n",
      "         -0.4961, -0.4961, -0.4961,  0.3634, -0.4961, -0.4961]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 7, 0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7,\n",
      "         4, 4, 7, 8, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 7, 0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4,\n",
      "         4, 7, 8, 4, 4, 7],\n",
      "        [6, 6, 6, 6, 7, 0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4,\n",
      "         7, 8, 4, 4, 7, 4],\n",
      "        [6, 6, 6, 7, 0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7,\n",
      "         8, 4, 4, 7, 4, 7],\n",
      "        [6, 6, 7, 0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [6, 7, 0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [7, 0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4,\n",
      "         7, 4, 7, 4, 4, 7],\n",
      "        [0, 6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [6, 6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4,\n",
      "         7, 4, 4, 7, 4, 7],\n",
      "        [6, 8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4, 7,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [8, 7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4, 7, 4,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [7, 3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4, 7, 4, 4,\n",
      "         7, 4, 7, 4, 4, 4],\n",
      "        [3, 1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4, 7, 4, 4, 7,\n",
      "         4, 7, 4, 4, 4, 4],\n",
      "        [1, 0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4, 7, 4, 4, 7, 4,\n",
      "         7, 4, 4, 4, 4, 7],\n",
      "        [0, 1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4, 7, 4, 4, 7, 4, 7,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [1, 3, 8, 8, 0, 8, 4, 4, 7, 4, 4, 7, 8, 4, 4, 7, 4, 7, 4, 4, 7, 4, 7, 4,\n",
      "         4, 4, 4, 7, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.5075, -3.0917, -3.7578, -3.0917, -2.4256, -1.7595, -1.7595, -2.2905,\n",
      "         -1.7595, -1.7595, -1.5402, -1.0934, -0.9589, -0.8474, -1.3170, -0.7229,\n",
      "         -0.6668, -0.6174, -0.5316, -1.3931, -0.9270, -2.1740, -1.2330, -0.7751,\n",
      "         -0.5216, -0.4967,  0.1793, -0.4967, -0.4967, -0.4967],\n",
      "        [-3.0917, -3.7578, -3.0917, -2.4256, -1.7595, -1.7595, -2.2905, -1.7595,\n",
      "         -1.7595, -1.5402, -1.0934, -0.9589, -0.8474, -1.3170, -0.7229, -0.6668,\n",
      "         -0.6174, -0.5316, -1.3931, -0.9270, -2.1740, -1.2330, -0.7751, -0.5216,\n",
      "         -0.4967,  0.1793, -0.4967, -0.4967, -0.4967, -0.4967],\n",
      "        [-3.7578, -3.0917, -2.4256, -1.7595, -1.7595, -2.2905, -1.7595, -1.7595,\n",
      "         -1.5402, -1.0934, -0.9589, -0.8474, -1.3170, -0.7229, -0.6668, -0.6174,\n",
      "         -0.5316, -1.3931, -0.9270, -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,\n",
      "          0.1793, -0.4967, -0.4967, -0.4967, -0.4967, -0.6149],\n",
      "        [-3.0917, -2.4256, -1.7595, -1.7595, -2.2905, -1.7595, -1.7595, -1.5402,\n",
      "         -1.0934, -0.9589, -0.8474, -1.3170, -0.7229, -0.6668, -0.6174, -0.5316,\n",
      "         -1.3931, -0.9270, -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,  0.1793,\n",
      "         -0.4967, -0.4967, -0.4967, -0.4967, -0.6149, -0.4967],\n",
      "        [-2.4256, -1.7595, -1.7595, -2.2905, -1.7595, -1.7595, -1.5402, -1.0934,\n",
      "         -0.9589, -0.8474, -1.3170, -0.7229, -0.6668, -0.6174, -0.5316, -1.3931,\n",
      "         -0.9270, -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,  0.1793, -0.4967,\n",
      "         -0.4967, -0.4967, -0.4967, -0.6149, -0.4967, -0.4967],\n",
      "        [-1.7595, -1.7595, -2.2905, -1.7595, -1.7595, -1.5402, -1.0934, -0.9589,\n",
      "         -0.8474, -1.3170, -0.7229, -0.6668, -0.6174, -0.5316, -1.3931, -0.9270,\n",
      "         -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,  0.1793, -0.4967, -0.4967,\n",
      "         -0.4967, -0.4967, -0.6149, -0.4967, -0.4967, -0.6690],\n",
      "        [-1.7595, -2.2905, -1.7595, -1.7595, -1.5402, -1.0934, -0.9589, -0.8474,\n",
      "         -1.3170, -0.7229, -0.6668, -0.6174, -0.5316, -1.3931, -0.9270, -2.1740,\n",
      "         -1.2330, -0.7751, -0.5216, -0.4967,  0.1793, -0.4967, -0.4967, -0.4967,\n",
      "         -0.4967, -0.6149, -0.4967, -0.4967, -0.6690, -0.4967],\n",
      "        [-2.2905, -1.7595, -1.7595, -1.5402, -1.0934, -0.9589, -0.8474, -1.3170,\n",
      "         -0.7229, -0.6668, -0.6174, -0.5316, -1.3931, -0.9270, -2.1740, -1.2330,\n",
      "         -0.7751, -0.5216, -0.4967,  0.1793, -0.4967, -0.4967, -0.4967, -0.4967,\n",
      "         -0.6149, -0.4967, -0.4967, -0.6690, -0.4967,  0.3586],\n",
      "        [-1.7595, -1.7595, -1.5402, -1.0934, -0.9589, -0.8474, -1.3170, -0.7229,\n",
      "         -0.6668, -0.6174, -0.5316, -1.3931, -0.9270, -2.1740, -1.2330, -0.7751,\n",
      "         -0.5216, -0.4967,  0.1793, -0.4967, -0.4967, -0.4967, -0.4967, -0.6149,\n",
      "         -0.4967, -0.4967, -0.6690, -0.4967,  0.3586, -0.4967],\n",
      "        [-1.7595, -1.5402, -1.0934, -0.9589, -0.8474, -1.3170, -0.7229, -0.6668,\n",
      "         -0.6174, -0.5316, -1.3931, -0.9270, -2.1740, -1.2330, -0.7751, -0.5216,\n",
      "         -0.4967,  0.1793, -0.4967, -0.4967, -0.4967, -0.4967, -0.6149, -0.4967,\n",
      "         -0.4967, -0.6690, -0.4967,  0.3586, -0.4967, -0.4967],\n",
      "        [-1.5402, -1.0934, -0.9589, -0.8474, -1.3170, -0.7229, -0.6668, -0.6174,\n",
      "         -0.5316, -1.3931, -0.9270, -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,\n",
      "          0.1793, -0.4967, -0.4967, -0.4967, -0.4967, -0.6149, -0.4967, -0.4967,\n",
      "         -0.6690, -0.4967,  0.3586, -0.4967, -0.4967, -0.9106],\n",
      "        [-1.0934, -0.9589, -0.8474, -1.3170, -0.7229, -0.6668, -0.6174, -0.5316,\n",
      "         -1.3931, -0.9270, -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,  0.1793,\n",
      "         -0.4967, -0.4967, -0.4967, -0.4967, -0.6149, -0.4967, -0.4967, -0.6690,\n",
      "         -0.4967,  0.3586, -0.4967, -0.4967, -0.9106, -0.4967],\n",
      "        [-0.9589, -0.8474, -1.3170, -0.7229, -0.6668, -0.6174, -0.5316, -1.3931,\n",
      "         -0.9270, -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,  0.1793, -0.4967,\n",
      "         -0.4967, -0.4967, -0.4967, -0.6149, -0.4967, -0.4967, -0.6690, -0.4967,\n",
      "          0.3586, -0.4967, -0.4967, -0.9106, -0.4967, -1.6945],\n",
      "        [-0.8474, -1.3170, -0.7229, -0.6668, -0.6174, -0.5316, -1.3931, -0.9270,\n",
      "         -2.1740, -1.2330, -0.7751, -0.5216, -0.4967,  0.1793, -0.4967, -0.4967,\n",
      "         -0.4967, -0.4967, -0.6149, -0.4967, -0.4967, -0.6690, -0.4967,  0.3586,\n",
      "         -0.4967, -0.4967, -0.9106, -0.4967, -1.6945, -0.4967],\n",
      "        [-1.3170, -0.7229, -0.6668, -0.6174, -0.5316, -1.3931, -0.9270, -2.1740,\n",
      "         -1.2330, -0.7751, -0.5216, -0.4967,  0.1793, -0.4967, -0.4967, -0.4967,\n",
      "         -0.4967, -0.6149, -0.4967, -0.4967, -0.6690, -0.4967,  0.3586, -0.4967,\n",
      "         -0.4967, -0.9106, -0.4967, -1.6945, -0.4967, -1.4335],\n",
      "        [-0.7229, -0.6668, -0.6174, -0.5316, -1.3931, -0.9270, -2.1740, -1.2330,\n",
      "         -0.7751, -0.5216, -0.4967,  0.1793, -0.4967, -0.4967, -0.4967, -0.4967,\n",
      "         -0.6149, -0.4967, -0.4967, -0.6690, -0.4967,  0.3586, -0.4967, -0.4967,\n",
      "         -0.9106, -0.4967, -1.6945, -0.4967, -1.4335, -1.0934]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[3, 8, 8, 8, 8, 8, 8, 7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0,\n",
      "         1, 4, 6, 4, 4, 4],\n",
      "        [8, 8, 8, 8, 8, 8, 7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1,\n",
      "         4, 6, 4, 4, 4, 4],\n",
      "        [8, 8, 8, 8, 8, 7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4,\n",
      "         6, 4, 4, 4, 4, 7],\n",
      "        [8, 8, 8, 8, 7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6,\n",
      "         4, 4, 4, 4, 7, 4],\n",
      "        [8, 8, 8, 7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [8, 8, 7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4,\n",
      "         4, 4, 7, 4, 4, 7],\n",
      "        [8, 7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [7, 8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4,\n",
      "         7, 4, 4, 7, 4, 7],\n",
      "        [8, 8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [8, 7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7, 4,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [7, 8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7, 4, 4,\n",
      "         7, 4, 7, 4, 4, 7],\n",
      "        [8, 5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7, 4, 4, 7,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [5, 5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7, 4, 4, 7, 4,\n",
      "         7, 4, 4, 7, 4, 7],\n",
      "        [5, 7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7, 4, 4, 7, 4, 7,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [7, 6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7, 4, 4, 7, 4, 7, 4,\n",
      "         4, 7, 4, 7, 4, 7],\n",
      "        [6, 6, 6, 2, 7, 0, 7, 3, 0, 1, 4, 6, 4, 4, 4, 4, 7, 4, 4, 7, 4, 7, 4, 4,\n",
      "         7, 4, 7, 4, 7, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.9281, -1.8905, -1.8609, -1.9935, -2.2116, -2.6063, -2.4355, -2.0744,\n",
      "         -1.8239, -1.5764, -1.2833, -1.2040, -1.1285, -1.0471, -0.9228, -0.8221,\n",
      "         -0.6988, -0.5722, -0.6112, -0.4958, -0.1913, -0.4958, -0.4958, -0.8157,\n",
      "         -0.4958, -1.4789, -0.4958, -1.2581, -0.7313, -1.2804],\n",
      "        [-1.8905, -1.8609, -1.9935, -2.2116, -2.6063, -2.4355, -2.0744, -1.8239,\n",
      "         -1.5764, -1.2833, -1.2040, -1.1285, -1.0471, -0.9228, -0.8221, -0.6988,\n",
      "         -0.5722, -0.6112, -0.4958, -0.1913, -0.4958, -0.4958, -0.8157, -0.4958,\n",
      "         -1.4789, -0.4958, -1.2581, -0.7313, -1.2804, -0.7313],\n",
      "        [-1.8609, -1.9935, -2.2116, -2.6063, -2.4355, -2.0744, -1.8239, -1.5764,\n",
      "         -1.2833, -1.2040, -1.1285, -1.0471, -0.9228, -0.8221, -0.6988, -0.5722,\n",
      "         -0.6112, -0.4958, -0.1913, -0.4958, -0.4958, -0.8157, -0.4958, -1.4789,\n",
      "         -0.4958, -1.2581, -0.7313, -1.2804, -0.7313, -1.2804],\n",
      "        [-1.9935, -2.2116, -2.6063, -2.4355, -2.0744, -1.8239, -1.5764, -1.2833,\n",
      "         -1.2040, -1.1285, -1.0471, -0.9228, -0.8221, -0.6988, -0.5722, -0.6112,\n",
      "         -0.4958, -0.1913, -0.4958, -0.4958, -0.8157, -0.4958, -1.4789, -0.4958,\n",
      "         -1.2581, -0.7313, -1.2804, -0.7313, -1.2804, -1.2804],\n",
      "        [-2.2116, -2.6063, -2.4355, -2.0744, -1.8239, -1.5764, -1.2833, -1.2040,\n",
      "         -1.1285, -1.0471, -0.9228, -0.8221, -0.6988, -0.5722, -0.6112, -0.4958,\n",
      "         -0.1913, -0.4958, -0.4958, -0.8157, -0.4958, -1.4789, -0.4958, -1.2581,\n",
      "         -0.7313, -1.2804, -0.7313, -1.2804, -1.2804, -1.2804],\n",
      "        [-2.6063, -2.4355, -2.0744, -1.8239, -1.5764, -1.2833, -1.2040, -1.1285,\n",
      "         -1.0471, -0.9228, -0.8221, -0.6988, -0.5722, -0.6112, -0.4958, -0.1913,\n",
      "         -0.4958, -0.4958, -0.8157, -0.4958, -1.4789, -0.4958, -1.2581, -0.7313,\n",
      "         -1.2804, -0.7313, -1.2804, -1.2804, -1.2804, -1.8294],\n",
      "        [-2.4355, -2.0744, -1.8239, -1.5764, -1.2833, -1.2040, -1.1285, -1.0471,\n",
      "         -0.9228, -0.8221, -0.6988, -0.5722, -0.6112, -0.4958, -0.1913, -0.4958,\n",
      "         -0.4958, -0.8157, -0.4958, -1.4789, -0.4958, -1.2581, -0.7313, -1.2804,\n",
      "         -0.7313, -1.2804, -1.2804, -1.2804, -1.8294, -1.8294],\n",
      "        [-2.0744, -1.8239, -1.5764, -1.2833, -1.2040, -1.1285, -1.0471, -0.9228,\n",
      "         -0.8221, -0.6988, -0.5722, -0.6112, -0.4958, -0.1913, -0.4958, -0.4958,\n",
      "         -0.8157, -0.4958, -1.4789, -0.4958, -1.2581, -0.7313, -1.2804, -0.7313,\n",
      "         -1.2804, -1.2804, -1.2804, -1.8294, -1.8294, -1.2804],\n",
      "        [-1.8239, -1.5764, -1.2833, -1.2040, -1.1285, -1.0471, -0.9228, -0.8221,\n",
      "         -0.6988, -0.5722, -0.6112, -0.4958, -0.1913, -0.4958, -0.4958, -0.8157,\n",
      "         -0.4958, -1.4789, -0.4958, -1.2581, -0.7313, -1.2804, -0.7313, -1.2804,\n",
      "         -1.2804, -1.2804, -1.8294, -1.8294, -1.2804, -1.8294],\n",
      "        [-1.5764, -1.2833, -1.2040, -1.1285, -1.0471, -0.9228, -0.8221, -0.6988,\n",
      "         -0.5722, -0.6112, -0.4958, -0.1913, -0.4958, -0.4958, -0.8157, -0.4958,\n",
      "         -1.4789, -0.4958, -1.2581, -0.7313, -1.2804, -0.7313, -1.2804, -1.2804,\n",
      "         -1.2804, -1.8294, -1.8294, -1.2804, -1.8294, -1.3884],\n",
      "        [-1.2833, -1.2040, -1.1285, -1.0471, -0.9228, -0.8221, -0.6988, -0.5722,\n",
      "         -0.6112, -0.4958, -0.1913, -0.4958, -0.4958, -0.8157, -0.4958, -1.4789,\n",
      "         -0.4958, -1.2581, -0.7313, -1.2804, -0.7313, -1.2804, -1.2804, -1.2804,\n",
      "         -1.8294, -1.8294, -1.2804, -1.8294, -1.3884, -1.8294],\n",
      "        [-1.2040, -1.1285, -1.0471, -0.9228, -0.8221, -0.6988, -0.5722, -0.6112,\n",
      "         -0.4958, -0.1913, -0.4958, -0.4958, -0.8157, -0.4958, -1.4789, -0.4958,\n",
      "         -1.2581, -0.7313, -1.2804, -0.7313, -1.2804, -1.2804, -1.2804, -1.8294,\n",
      "         -1.8294, -1.2804, -1.8294, -1.3884, -1.8294, -1.2804],\n",
      "        [-1.1285, -1.0471, -0.9228, -0.8221, -0.6988, -0.5722, -0.6112, -0.4958,\n",
      "         -0.1913, -0.4958, -0.4958, -0.8157, -0.4958, -1.4789, -0.4958, -1.2581,\n",
      "         -0.7313, -1.2804, -0.7313, -1.2804, -1.2804, -1.2804, -1.8294, -1.8294,\n",
      "         -1.2804, -1.8294, -1.3884, -1.8294, -1.2804, -1.2804],\n",
      "        [-1.0471, -0.9228, -0.8221, -0.6988, -0.5722, -0.6112, -0.4958, -0.1913,\n",
      "         -0.4958, -0.4958, -0.8157, -0.4958, -1.4789, -0.4958, -1.2581, -0.7313,\n",
      "         -1.2804, -0.7313, -1.2804, -1.2804, -1.2804, -1.8294, -1.8294, -1.2804,\n",
      "         -1.8294, -1.3884, -1.8294, -1.2804, -1.2804, -1.2804],\n",
      "        [-0.9228, -0.8221, -0.6988, -0.5722, -0.6112, -0.4958, -0.1913, -0.4958,\n",
      "         -0.4958, -0.8157, -0.4958, -1.4789, -0.4958, -1.2581, -0.7313, -1.2804,\n",
      "         -0.7313, -1.2804, -1.2804, -1.2804, -1.8294, -1.8294, -1.2804, -1.8294,\n",
      "         -1.3884, -1.8294, -1.2804, -1.2804, -1.2804, -1.2804],\n",
      "        [-0.8221, -0.6988, -0.5722, -0.6112, -0.4958, -0.1913, -0.4958, -0.4958,\n",
      "         -0.8157, -0.4958, -1.4789, -0.4958, -1.2581, -0.7313, -1.2804, -0.7313,\n",
      "         -1.2804, -1.2804, -1.2804, -1.8294, -1.8294, -1.2804, -1.8294, -1.3884,\n",
      "         -1.8294, -1.2804, -1.2804, -1.2804, -1.2804, -1.2804]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 2, 3, 0, 2, 3, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7,\n",
      "         4, 7, 4, 7, 8, 8],\n",
      "        [6, 2, 3, 0, 2, 3, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4,\n",
      "         7, 4, 7, 8, 8, 8],\n",
      "        [2, 3, 0, 2, 3, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7,\n",
      "         4, 7, 8, 8, 8, 8],\n",
      "        [3, 0, 2, 3, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [0, 2, 3, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [2, 3, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [3, 0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [0, 0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [0, 0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [0, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 7, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 7, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 7, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 7, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [6, 6, 6, 7, 4, 5, 4, 4, 7, 4, 7, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 7,\n",
      "         8, 8, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.0900, -1.9809, -1.8836, -1.7910, -1.6934, -1.5989, -1.5069, -1.7668,\n",
      "         -1.3674, -1.7567, -1.6770, -2.2161, -2.0859, -1.1891, -0.8791, -0.7644,\n",
      "         -0.6660, -0.5917, -1.2215, -1.2215, -0.6498, -1.2215, -1.1509, -1.2215,\n",
      "         -0.5239, -0.6760, -0.9690, -0.5375, -0.5375, -0.5239],\n",
      "        [-1.9809, -1.8836, -1.7910, -1.6934, -1.5989, -1.5069, -1.7668, -1.3674,\n",
      "         -1.7567, -1.6770, -2.2161, -2.0859, -1.1891, -0.8791, -0.7644, -0.6660,\n",
      "         -0.5917, -1.2215, -1.2215, -0.6498, -1.2215, -1.1509, -1.2215, -0.5239,\n",
      "         -0.6760, -0.9690, -0.5375, -0.5375, -0.5239, -0.5375],\n",
      "        [-1.8836, -1.7910, -1.6934, -1.5989, -1.5069, -1.7668, -1.3674, -1.7567,\n",
      "         -1.6770, -2.2161, -2.0859, -1.1891, -0.8791, -0.7644, -0.6660, -0.5917,\n",
      "         -1.2215, -1.2215, -0.6498, -1.2215, -1.1509, -1.2215, -0.5239, -0.6760,\n",
      "         -0.9690, -0.5375, -0.5375, -0.5239, -0.5375, -0.5375],\n",
      "        [-1.7910, -1.6934, -1.5989, -1.5069, -1.7668, -1.3674, -1.7567, -1.6770,\n",
      "         -2.2161, -2.0859, -1.1891, -0.8791, -0.7644, -0.6660, -0.5917, -1.2215,\n",
      "         -1.2215, -0.6498, -1.2215, -1.1509, -1.2215, -0.5239, -0.6760, -0.9690,\n",
      "         -0.5375, -0.5375, -0.5239, -0.5375, -0.5375,  0.3438],\n",
      "        [-1.6934, -1.5989, -1.5069, -1.7668, -1.3674, -1.7567, -1.6770, -2.2161,\n",
      "         -2.0859, -1.1891, -0.8791, -0.7644, -0.6660, -0.5917, -1.2215, -1.2215,\n",
      "         -0.6498, -1.2215, -1.1509, -1.2215, -0.5239, -0.6760, -0.9690, -0.5375,\n",
      "         -0.5375, -0.5239, -0.5375, -0.5375,  0.3438, -0.4528],\n",
      "        [-1.5989, -1.5069, -1.7668, -1.3674, -1.7567, -1.6770, -2.2161, -2.0859,\n",
      "         -1.1891, -0.8791, -0.7644, -0.6660, -0.5917, -1.2215, -1.2215, -0.6498,\n",
      "         -1.2215, -1.1509, -1.2215, -0.5239, -0.6760, -0.9690, -0.5375, -0.5375,\n",
      "         -0.5239, -0.5375, -0.5375,  0.3438, -0.4528, -0.5375],\n",
      "        [-1.5069, -1.7668, -1.3674, -1.7567, -1.6770, -2.2161, -2.0859, -1.1891,\n",
      "         -0.8791, -0.7644, -0.6660, -0.5917, -1.2215, -1.2215, -0.6498, -1.2215,\n",
      "         -1.1509, -1.2215, -0.5239, -0.6760, -0.9690, -0.5375, -0.5375, -0.5239,\n",
      "         -0.5375, -0.5375,  0.3438, -0.4528, -0.5375, -2.3517],\n",
      "        [-1.7668, -1.3674, -1.7567, -1.6770, -2.2161, -2.0859, -1.1891, -0.8791,\n",
      "         -0.7644, -0.6660, -0.5917, -1.2215, -1.2215, -0.6498, -1.2215, -1.1509,\n",
      "         -1.2215, -0.5239, -0.6760, -0.9690, -0.5375, -0.5375, -0.5239, -0.5375,\n",
      "         -0.5375,  0.3438, -0.4528, -0.5375, -2.3517, -0.5375],\n",
      "        [-1.3674, -1.7567, -1.6770, -2.2161, -2.0859, -1.1891, -0.8791, -0.7644,\n",
      "         -0.6660, -0.5917, -1.2215, -1.2215, -0.6498, -1.2215, -1.1509, -1.2215,\n",
      "         -0.5239, -0.6760, -0.9690, -0.5375, -0.5375, -0.5239, -0.5375, -0.5375,\n",
      "          0.3438, -0.4528, -0.5375, -2.3517, -0.5375, -0.8393],\n",
      "        [-1.7567, -1.6770, -2.2161, -2.0859, -1.1891, -0.8791, -0.7644, -0.6660,\n",
      "         -0.5917, -1.2215, -1.2215, -0.6498, -1.2215, -1.1509, -1.2215, -0.5239,\n",
      "         -0.6760, -0.9690, -0.5375, -0.5375, -0.5239, -0.5375, -0.5375,  0.3438,\n",
      "         -0.4528, -0.5375, -2.3517, -0.5375, -0.8393, -1.9649],\n",
      "        [-1.6770, -2.2161, -2.0859, -1.1891, -0.8791, -0.7644, -0.6660, -0.5917,\n",
      "         -1.2215, -1.2215, -0.6498, -1.2215, -1.1509, -1.2215, -0.5239, -0.6760,\n",
      "         -0.9690, -0.5375, -0.5375, -0.5239, -0.5375, -0.5375,  0.3438, -0.4528,\n",
      "         -0.5375, -2.3517, -0.5375, -0.8393, -1.9649, -0.5375],\n",
      "        [-2.2161, -2.0859, -1.1891, -0.8791, -0.7644, -0.6660, -0.5917, -1.2215,\n",
      "         -1.2215, -0.6498, -1.2215, -1.1509, -1.2215, -0.5239, -0.6760, -0.9690,\n",
      "         -0.5375, -0.5375, -0.5239, -0.5375, -0.5375,  0.3438, -0.4528, -0.5375,\n",
      "         -2.3517, -0.5375, -0.8393, -1.9649, -0.5375, -0.5375],\n",
      "        [-2.0859, -1.1891, -0.8791, -0.7644, -0.6660, -0.5917, -1.2215, -1.2215,\n",
      "         -0.6498, -1.2215, -1.1509, -1.2215, -0.5239, -0.6760, -0.9690, -0.5375,\n",
      "         -0.5375, -0.5239, -0.5375, -0.5375,  0.3438, -0.4528, -0.5375, -2.3517,\n",
      "         -0.5375, -0.8393, -1.9649, -0.5375, -0.5375, -0.5375],\n",
      "        [-1.1891, -0.8791, -0.7644, -0.6660, -0.5917, -1.2215, -1.2215, -0.6498,\n",
      "         -1.2215, -1.1509, -1.2215, -0.5239, -0.6760, -0.9690, -0.5375, -0.5375,\n",
      "         -0.5239, -0.5375, -0.5375,  0.3438, -0.4528, -0.5375, -2.3517, -0.5375,\n",
      "         -0.8393, -1.9649, -0.5375, -0.5375, -0.5375, -0.5375],\n",
      "        [-0.8791, -0.7644, -0.6660, -0.5917, -1.2215, -1.2215, -0.6498, -1.2215,\n",
      "         -1.1509, -1.2215, -0.5239, -0.6760, -0.9690, -0.5375, -0.5375, -0.5239,\n",
      "         -0.5375, -0.5375,  0.3438, -0.4528, -0.5375, -2.3517, -0.5375, -0.8393,\n",
      "         -1.9649, -0.5375, -0.5375, -0.5375, -0.5375,  0.6679],\n",
      "        [-0.7644, -0.6660, -0.5917, -1.2215, -1.2215, -0.6498, -1.2215, -1.1509,\n",
      "         -1.2215, -0.5239, -0.6760, -0.9690, -0.5375, -0.5375, -0.5239, -0.5375,\n",
      "         -0.5375,  0.3438, -0.4528, -0.5375, -2.3517, -0.5375, -0.8393, -1.9649,\n",
      "         -0.5375, -0.5375, -0.5375, -0.5375,  0.6679, -0.5375]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 5, 5, 5, 5, 5, 2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8,\n",
      "         8, 7, 7, 4, 4, 8],\n",
      "        [6, 5, 5, 5, 5, 5, 2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8,\n",
      "         7, 7, 4, 4, 8, 4],\n",
      "        [5, 5, 5, 5, 5, 2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7,\n",
      "         7, 4, 4, 8, 4, 4],\n",
      "        [5, 5, 5, 5, 2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7,\n",
      "         4, 4, 8, 4, 4, 7],\n",
      "        [5, 5, 5, 2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4,\n",
      "         4, 8, 4, 4, 7, 7],\n",
      "        [5, 5, 2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4,\n",
      "         8, 4, 4, 7, 7, 4],\n",
      "        [5, 2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8,\n",
      "         4, 4, 7, 7, 4, 7],\n",
      "        [2, 1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4,\n",
      "         4, 7, 7, 4, 7, 4],\n",
      "        [1, 3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4,\n",
      "         7, 7, 4, 7, 4, 7],\n",
      "        [3, 1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4, 7,\n",
      "         7, 4, 7, 4, 7, 7],\n",
      "        [1, 2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4, 7, 7,\n",
      "         4, 7, 4, 7, 7, 4],\n",
      "        [2, 3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4, 7, 7, 4,\n",
      "         7, 4, 7, 7, 4, 4],\n",
      "        [3, 0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4, 7, 7, 4, 7,\n",
      "         4, 7, 7, 4, 4, 4],\n",
      "        [0, 5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4, 7, 7, 4, 7, 4,\n",
      "         7, 7, 4, 4, 4, 4],\n",
      "        [5, 5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4, 7, 7, 4, 7, 4, 7,\n",
      "         7, 4, 4, 4, 4, 7],\n",
      "        [5, 6, 6, 8, 8, 7, 8, 7, 8, 8, 7, 7, 4, 4, 8, 4, 4, 7, 7, 4, 7, 4, 7, 7,\n",
      "         4, 4, 4, 4, 7, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.3560, -2.2480, -2.1987, -2.1987, -1.8670, -2.1987, -1.7303, -2.1987,\n",
      "         -1.5580, -1.7679, -2.0101, -1.3734, -1.0974, -1.0776, -0.9573, -0.7801,\n",
      "         -0.6756, -0.5692, -0.5388, -2.4042, -0.5388, -1.1199, -2.0059, -1.1992,\n",
      "         -1.3767, -0.8374, -0.5388, -0.0731, -0.5388, -0.5388],\n",
      "        [-2.2480, -2.1987, -2.1987, -1.8670, -2.1987, -1.7303, -2.1987, -1.5580,\n",
      "         -1.7679, -2.0101, -1.3734, -1.0974, -1.0776, -0.9573, -0.7801, -0.6756,\n",
      "         -0.5692, -0.5388, -2.4042, -0.5388, -1.1199, -2.0059, -1.1992, -1.3767,\n",
      "         -0.8374, -0.5388, -0.0731, -0.5388, -0.5388, -0.6666],\n",
      "        [-2.1987, -2.1987, -1.8670, -2.1987, -1.7303, -2.1987, -1.5580, -1.7679,\n",
      "         -2.0101, -1.3734, -1.0974, -1.0776, -0.9573, -0.7801, -0.6756, -0.5692,\n",
      "         -0.5388, -2.4042, -0.5388, -1.1199, -2.0059, -1.1992, -1.3767, -0.8374,\n",
      "         -0.5388, -0.0731, -0.5388, -0.5388, -0.6666, -0.9573],\n",
      "        [-2.1987, -1.8670, -2.1987, -1.7303, -2.1987, -1.5580, -1.7679, -2.0101,\n",
      "         -1.3734, -1.0974, -1.0776, -0.9573, -0.7801, -0.6756, -0.5692, -0.5388,\n",
      "         -2.4042, -0.5388, -1.1199, -2.0059, -1.1992, -1.3767, -0.8374, -0.5388,\n",
      "         -0.0731, -0.5388, -0.5388, -0.6666, -0.9573,  0.2842],\n",
      "        [-1.8670, -2.1987, -1.7303, -2.1987, -1.5580, -1.7679, -2.0101, -1.3734,\n",
      "         -1.0974, -1.0776, -0.9573, -0.7801, -0.6756, -0.5692, -0.5388, -2.4042,\n",
      "         -0.5388, -1.1199, -2.0059, -1.1992, -1.3767, -0.8374, -0.5388, -0.0731,\n",
      "         -0.5388, -0.5388, -0.6666, -0.9573,  0.2842, -0.9610],\n",
      "        [-2.1987, -1.7303, -2.1987, -1.5580, -1.7679, -2.0101, -1.3734, -1.0974,\n",
      "         -1.0776, -0.9573, -0.7801, -0.6756, -0.5692, -0.5388, -2.4042, -0.5388,\n",
      "         -1.1199, -2.0059, -1.1992, -1.3767, -0.8374, -0.5388, -0.0731, -0.5388,\n",
      "         -0.5388, -0.6666, -0.9573,  0.2842, -0.9610, -0.5388],\n",
      "        [-1.7303, -2.1987, -1.5580, -1.7679, -2.0101, -1.3734, -1.0974, -1.0776,\n",
      "         -0.9573, -0.7801, -0.6756, -0.5692, -0.5388, -2.4042, -0.5388, -1.1199,\n",
      "         -2.0059, -1.1992, -1.3767, -0.8374, -0.5388, -0.0731, -0.5388, -0.5388,\n",
      "         -0.6666, -0.9573,  0.2842, -0.9610, -0.5388, -0.9573],\n",
      "        [-2.1987, -1.5580, -1.7679, -2.0101, -1.3734, -1.0974, -1.0776, -0.9573,\n",
      "         -0.7801, -0.6756, -0.5692, -0.5388, -2.4042, -0.5388, -1.1199, -2.0059,\n",
      "         -1.1992, -1.3767, -0.8374, -0.5388, -0.0731, -0.5388, -0.5388, -0.6666,\n",
      "         -0.9573,  0.2842, -0.9610, -0.5388, -0.9573, -0.5388],\n",
      "        [-1.5580, -1.7679, -2.0101, -1.3734, -1.0974, -1.0776, -0.9573, -0.7801,\n",
      "         -0.6756, -0.5692, -0.5388, -2.4042, -0.5388, -1.1199, -2.0059, -1.1992,\n",
      "         -1.3767, -0.8374, -0.5388, -0.0731, -0.5388, -0.5388, -0.6666, -0.9573,\n",
      "          0.2842, -0.9610, -0.5388, -0.9573, -0.5388, -0.7789],\n",
      "        [-1.7679, -2.0101, -1.3734, -1.0974, -1.0776, -0.9573, -0.7801, -0.6756,\n",
      "         -0.5692, -0.5388, -2.4042, -0.5388, -1.1199, -2.0059, -1.1992, -1.3767,\n",
      "         -0.8374, -0.5388, -0.0731, -0.5388, -0.5388, -0.6666, -0.9573,  0.2842,\n",
      "         -0.9610, -0.5388, -0.9573, -0.5388, -0.7789, -0.5388],\n",
      "        [-2.0101, -1.3734, -1.0974, -1.0776, -0.9573, -0.7801, -0.6756, -0.5692,\n",
      "         -0.5388, -2.4042, -0.5388, -1.1199, -2.0059, -1.1992, -1.3767, -0.8374,\n",
      "         -0.5388, -0.0731, -0.5388, -0.5388, -0.6666, -0.9573,  0.2842, -0.9610,\n",
      "         -0.5388, -0.9573, -0.5388, -0.7789, -0.5388, -0.5388],\n",
      "        [-1.3734, -1.0974, -1.0776, -0.9573, -0.7801, -0.6756, -0.5692, -0.5388,\n",
      "         -2.4042, -0.5388, -1.1199, -2.0059, -1.1992, -1.3767, -0.8374, -0.5388,\n",
      "         -0.0731, -0.5388, -0.5388, -0.6666, -0.9573,  0.2842, -0.9610, -0.5388,\n",
      "         -0.9573, -0.5388, -0.7789, -0.5388, -0.5388, -1.3622],\n",
      "        [-1.0974, -1.0776, -0.9573, -0.7801, -0.6756, -0.5692, -0.5388, -2.4042,\n",
      "         -0.5388, -1.1199, -2.0059, -1.1992, -1.3767, -0.8374, -0.5388, -0.0731,\n",
      "         -0.5388, -0.5388, -0.6666, -0.9573,  0.2842, -0.9610, -0.5388, -0.9573,\n",
      "         -0.5388, -0.7789, -0.5388, -0.5388, -1.3622, -0.9573],\n",
      "        [-1.0776, -0.9573, -0.7801, -0.6756, -0.5692, -0.5388, -2.4042, -0.5388,\n",
      "         -1.1199, -2.0059, -1.1992, -1.3767, -0.8374, -0.5388, -0.0731, -0.5388,\n",
      "         -0.5388, -0.6666, -0.9573,  0.2842, -0.9610, -0.5388, -0.9573, -0.5388,\n",
      "         -0.7789, -0.5388, -0.5388, -1.3622, -0.9573, -0.9573],\n",
      "        [-0.9573, -0.7801, -0.6756, -0.5692, -0.5388, -2.4042, -0.5388, -1.1199,\n",
      "         -2.0059, -1.1992, -1.3767, -0.8374, -0.5388, -0.0731, -0.5388, -0.5388,\n",
      "         -0.6666, -0.9573,  0.2842, -0.9610, -0.5388, -0.9573, -0.5388, -0.7789,\n",
      "         -0.5388, -0.5388, -1.3622, -0.9573, -0.9573, -0.5388],\n",
      "        [-0.7801, -0.6756, -0.5692, -0.5388, -2.4042, -0.5388, -1.1199, -2.0059,\n",
      "         -1.1992, -1.3767, -0.8374, -0.5388, -0.0731, -0.5388, -0.5388, -0.6666,\n",
      "         -0.9573,  0.2842, -0.9610, -0.5388, -0.9573, -0.5388, -0.7789, -0.5388,\n",
      "         -0.5388, -1.3622, -0.9573, -0.9573, -0.5388, -0.5388]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 8, 8, 5, 8, 2, 8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3,\n",
      "         0, 0, 4, 0, 4, 4],\n",
      "        [5, 8, 8, 5, 8, 2, 8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0,\n",
      "         0, 4, 0, 4, 4, 7],\n",
      "        [8, 8, 5, 8, 2, 8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0,\n",
      "         4, 0, 4, 4, 7, 8],\n",
      "        [8, 5, 8, 2, 8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4,\n",
      "         0, 4, 4, 7, 8, 8],\n",
      "        [5, 8, 2, 8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0,\n",
      "         4, 4, 7, 8, 8, 7],\n",
      "        [8, 2, 8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4,\n",
      "         4, 7, 8, 8, 7, 4],\n",
      "        [2, 8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4,\n",
      "         7, 8, 8, 7, 4, 8],\n",
      "        [8, 0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7,\n",
      "         8, 8, 7, 4, 8, 4],\n",
      "        [0, 1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8,\n",
      "         8, 7, 4, 8, 4, 7],\n",
      "        [1, 1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8, 8,\n",
      "         7, 4, 8, 4, 7, 4],\n",
      "        [1, 0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8, 8, 7,\n",
      "         4, 8, 4, 7, 4, 4],\n",
      "        [0, 6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8, 8, 7, 4,\n",
      "         8, 4, 7, 4, 4, 7],\n",
      "        [6, 1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8, 8, 7, 4, 8,\n",
      "         4, 7, 4, 4, 7, 8],\n",
      "        [1, 8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8, 8, 7, 4, 8, 4,\n",
      "         7, 4, 4, 7, 8, 8],\n",
      "        [8, 6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8, 8, 7, 4, 8, 4, 7,\n",
      "         4, 4, 7, 8, 8, 4],\n",
      "        [6, 6, 6, 4, 7, 4, 2, 7, 3, 0, 0, 4, 0, 4, 4, 7, 8, 8, 7, 4, 8, 4, 7, 4,\n",
      "         4, 7, 8, 8, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.1254, -2.0304, -1.9157, -2.5983, -1.6875, -1.5868, -2.2049, -1.5602,\n",
      "         -1.6610, -1.4030, -1.1372, -1.0548, -0.9769, -0.9023, -0.9878, -1.3650,\n",
      "         -0.6400, -1.1732, -0.5137, -1.3650, -0.5361, -0.9934, -0.5503, -0.5536,\n",
      "         -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,  0.1190],\n",
      "        [-2.0304, -1.9157, -2.5983, -1.6875, -1.5868, -2.2049, -1.5602, -1.6610,\n",
      "         -1.4030, -1.1372, -1.0548, -0.9769, -0.9023, -0.9878, -1.3650, -0.6400,\n",
      "         -1.1732, -0.5137, -1.3650, -0.5361, -0.9934, -0.5503, -0.5536, -1.5693,\n",
      "         -1.3650, -1.3650, -0.5137, -0.5137,  0.1190, -0.5137],\n",
      "        [-1.9157, -2.5983, -1.6875, -1.5868, -2.2049, -1.5602, -1.6610, -1.4030,\n",
      "         -1.1372, -1.0548, -0.9769, -0.9023, -0.9878, -1.3650, -0.6400, -1.1732,\n",
      "         -0.5137, -1.3650, -0.5361, -0.9934, -0.5503, -0.5536, -1.5693, -1.3650,\n",
      "         -1.3650, -0.5137, -0.5137,  0.1190, -0.5137, -0.6512],\n",
      "        [-2.5983, -1.6875, -1.5868, -2.2049, -1.5602, -1.6610, -1.4030, -1.1372,\n",
      "         -1.0548, -0.9769, -0.9023, -0.9878, -1.3650, -0.6400, -1.1732, -0.5137,\n",
      "         -1.3650, -0.5361, -0.9934, -0.5503, -0.5536, -1.5693, -1.3650, -1.3650,\n",
      "         -0.5137, -0.5137,  0.1190, -0.5137, -0.6512, -0.5137],\n",
      "        [-1.6875, -1.5868, -2.2049, -1.5602, -1.6610, -1.4030, -1.1372, -1.0548,\n",
      "         -0.9769, -0.9023, -0.9878, -1.3650, -0.6400, -1.1732, -0.5137, -1.3650,\n",
      "         -0.5361, -0.9934, -0.5503, -0.5536, -1.5693, -1.3650, -1.3650, -0.5137,\n",
      "         -0.5137,  0.1190, -0.5137, -0.6512, -0.5137, -0.5137],\n",
      "        [-1.5868, -2.2049, -1.5602, -1.6610, -1.4030, -1.1372, -1.0548, -0.9769,\n",
      "         -0.9023, -0.9878, -1.3650, -0.6400, -1.1732, -0.5137, -1.3650, -0.5361,\n",
      "         -0.9934, -0.5503, -0.5536, -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,\n",
      "          0.1190, -0.5137, -0.6512, -0.5137, -0.5137, -1.3346],\n",
      "        [-2.2049, -1.5602, -1.6610, -1.4030, -1.1372, -1.0548, -0.9769, -0.9023,\n",
      "         -0.9878, -1.3650, -0.6400, -1.1732, -0.5137, -1.3650, -0.5361, -0.9934,\n",
      "         -0.5503, -0.5536, -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,  0.1190,\n",
      "         -0.5137, -0.6512, -0.5137, -0.5137, -1.3346, -0.5137],\n",
      "        [-1.5602, -1.6610, -1.4030, -1.1372, -1.0548, -0.9769, -0.9023, -0.9878,\n",
      "         -1.3650, -0.6400, -1.1732, -0.5137, -1.3650, -0.5361, -0.9934, -0.5503,\n",
      "         -0.5536, -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,  0.1190, -0.5137,\n",
      "         -0.6512, -0.5137, -0.5137, -1.3346, -0.5137, -0.5137],\n",
      "        [-1.6610, -1.4030, -1.1372, -1.0548, -0.9769, -0.9023, -0.9878, -1.3650,\n",
      "         -0.6400, -1.1732, -0.5137, -1.3650, -0.5361, -0.9934, -0.5503, -0.5536,\n",
      "         -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,  0.1190, -0.5137, -0.6512,\n",
      "         -0.5137, -0.5137, -1.3346, -0.5137, -0.5137, -0.5137],\n",
      "        [-1.4030, -1.1372, -1.0548, -0.9769, -0.9023, -0.9878, -1.3650, -0.6400,\n",
      "         -1.1732, -0.5137, -1.3650, -0.5361, -0.9934, -0.5503, -0.5536, -1.5693,\n",
      "         -1.3650, -1.3650, -0.5137, -0.5137,  0.1190, -0.5137, -0.6512, -0.5137,\n",
      "         -0.5137, -1.3346, -0.5137, -0.5137, -0.5137,  1.3883],\n",
      "        [-1.1372, -1.0548, -0.9769, -0.9023, -0.9878, -1.3650, -0.6400, -1.1732,\n",
      "         -0.5137, -1.3650, -0.5361, -0.9934, -0.5503, -0.5536, -1.5693, -1.3650,\n",
      "         -1.3650, -0.5137, -0.5137,  0.1190, -0.5137, -0.6512, -0.5137, -0.5137,\n",
      "         -1.3346, -0.5137, -0.5137, -0.5137,  1.3883, -0.5137],\n",
      "        [-1.0548, -0.9769, -0.9023, -0.9878, -1.3650, -0.6400, -1.1732, -0.5137,\n",
      "         -1.3650, -0.5361, -0.9934, -0.5503, -0.5536, -1.5693, -1.3650, -1.3650,\n",
      "         -0.5137, -0.5137,  0.1190, -0.5137, -0.6512, -0.5137, -0.5137, -1.3346,\n",
      "         -0.5137, -0.5137, -0.5137,  1.3883, -0.5137, -1.5309],\n",
      "        [-0.9769, -0.9023, -0.9878, -1.3650, -0.6400, -1.1732, -0.5137, -1.3650,\n",
      "         -0.5361, -0.9934, -0.5503, -0.5536, -1.5693, -1.3650, -1.3650, -0.5137,\n",
      "         -0.5137,  0.1190, -0.5137, -0.6512, -0.5137, -0.5137, -1.3346, -0.5137,\n",
      "         -0.5137, -0.5137,  1.3883, -0.5137, -1.5309, -0.5137],\n",
      "        [-0.9023, -0.9878, -1.3650, -0.6400, -1.1732, -0.5137, -1.3650, -0.5361,\n",
      "         -0.9934, -0.5503, -0.5536, -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,\n",
      "          0.1190, -0.5137, -0.6512, -0.5137, -0.5137, -1.3346, -0.5137, -0.5137,\n",
      "         -0.5137,  1.3883, -0.5137, -1.5309, -0.5137, -0.5137],\n",
      "        [-0.9878, -1.3650, -0.6400, -1.1732, -0.5137, -1.3650, -0.5361, -0.9934,\n",
      "         -0.5503, -0.5536, -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,  0.1190,\n",
      "         -0.5137, -0.6512, -0.5137, -0.5137, -1.3346, -0.5137, -0.5137, -0.5137,\n",
      "          1.3883, -0.5137, -1.5309, -0.5137, -0.5137, -1.3818],\n",
      "        [-1.3650, -0.6400, -1.1732, -0.5137, -1.3650, -0.5361, -0.9934, -0.5503,\n",
      "         -0.5536, -1.5693, -1.3650, -1.3650, -0.5137, -0.5137,  0.1190, -0.5137,\n",
      "         -0.6512, -0.5137, -0.5137, -1.3346, -0.5137, -0.5137, -0.5137,  1.3883,\n",
      "         -0.5137, -1.5309, -0.5137, -0.5137, -1.3818, -2.0004]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 7, 6, 6, 7, 0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1,\n",
      "         7, 8, 8, 4, 4, 7],\n",
      "        [6, 6, 7, 6, 6, 7, 0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7,\n",
      "         8, 8, 4, 4, 7, 4],\n",
      "        [6, 7, 6, 6, 7, 0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8,\n",
      "         8, 4, 4, 7, 4, 7],\n",
      "        [7, 6, 6, 7, 0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [6, 6, 7, 0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [6, 7, 0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4,\n",
      "         7, 4, 7, 4, 4, 7],\n",
      "        [7, 0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [0, 0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4,\n",
      "         7, 4, 4, 7, 4, 4],\n",
      "        [0, 0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7,\n",
      "         4, 4, 7, 4, 4, 4],\n",
      "        [0, 6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7, 4,\n",
      "         4, 7, 4, 4, 4, 7],\n",
      "        [6, 6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7, 4, 4,\n",
      "         7, 4, 4, 4, 7, 4],\n",
      "        [6, 6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7, 4, 4, 7,\n",
      "         4, 4, 4, 7, 4, 7],\n",
      "        [6, 6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7, 4, 4, 7, 4,\n",
      "         4, 4, 7, 4, 7, 4],\n",
      "        [6, 3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7, 4, 4, 7, 4, 4,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [3, 8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7, 4, 4, 7, 4, 4, 4,\n",
      "         7, 4, 7, 4, 4, 7],\n",
      "        [8, 6, 7, 4, 8, 7, 7, 1, 1, 7, 8, 8, 4, 4, 7, 4, 7, 4, 4, 7, 4, 4, 4, 7,\n",
      "         4, 7, 4, 4, 7, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.0465, -1.9530, -1.8747, -1.8000, -1.7256, -1.7670, -1.6921, -1.6954,\n",
      "         -1.6944, -1.4497, -1.3212, -1.2316, -1.1277, -1.0209, -0.9154, -0.8161,\n",
      "         -0.7029, -0.5788, -0.4913, -0.5054, -0.5054, -0.5054, -0.0329, -0.5054,\n",
      "         -0.5836, -0.5054, -0.5054, -0.5135, -0.8043, -0.8303],\n",
      "        [-1.9530, -1.8747, -1.8000, -1.7256, -1.7670, -1.6921, -1.6954, -1.6944,\n",
      "         -1.4497, -1.3212, -1.2316, -1.1277, -1.0209, -0.9154, -0.8161, -0.7029,\n",
      "         -0.5788, -0.4913, -0.5054, -0.5054, -0.5054, -0.0329, -0.5054, -0.5836,\n",
      "         -0.5054, -0.5054, -0.5135, -0.8043, -0.8303, -0.5054],\n",
      "        [-1.8747, -1.8000, -1.7256, -1.7670, -1.6921, -1.6954, -1.6944, -1.4497,\n",
      "         -1.3212, -1.2316, -1.1277, -1.0209, -0.9154, -0.8161, -0.7029, -0.5788,\n",
      "         -0.4913, -0.5054, -0.5054, -0.5054, -0.0329, -0.5054, -0.5836, -0.5054,\n",
      "         -0.5054, -0.5135, -0.8043, -0.8303, -0.5054, -1.7541],\n",
      "        [-1.8000, -1.7256, -1.7670, -1.6921, -1.6954, -1.6944, -1.4497, -1.3212,\n",
      "         -1.2316, -1.1277, -1.0209, -0.9154, -0.8161, -0.7029, -0.5788, -0.4913,\n",
      "         -0.5054, -0.5054, -0.5054, -0.0329, -0.5054, -0.5836, -0.5054, -0.5054,\n",
      "         -0.5135, -0.8043, -0.8303, -0.5054, -1.7541, -3.2631],\n",
      "        [-1.7256, -1.7670, -1.6921, -1.6954, -1.6944, -1.4497, -1.3212, -1.2316,\n",
      "         -1.1277, -1.0209, -0.9154, -0.8161, -0.7029, -0.5788, -0.4913, -0.5054,\n",
      "         -0.5054, -0.5054, -0.0329, -0.5054, -0.5836, -0.5054, -0.5054, -0.5135,\n",
      "         -0.8043, -0.8303, -0.5054, -1.7541, -3.2631, -1.9850],\n",
      "        [-1.7670, -1.6921, -1.6954, -1.6944, -1.4497, -1.3212, -1.2316, -1.1277,\n",
      "         -1.0209, -0.9154, -0.8161, -0.7029, -0.5788, -0.4913, -0.5054, -0.5054,\n",
      "         -0.5054, -0.0329, -0.5054, -0.5836, -0.5054, -0.5054, -0.5135, -0.8043,\n",
      "         -0.8303, -0.5054, -1.7541, -3.2631, -1.9850, -1.4355],\n",
      "        [-1.6921, -1.6954, -1.6944, -1.4497, -1.3212, -1.2316, -1.1277, -1.0209,\n",
      "         -0.9154, -0.8161, -0.7029, -0.5788, -0.4913, -0.5054, -0.5054, -0.5054,\n",
      "         -0.0329, -0.5054, -0.5836, -0.5054, -0.5054, -0.5135, -0.8043, -0.8303,\n",
      "         -0.5054, -1.7541, -3.2631, -1.9850, -1.4355, -3.2796],\n",
      "        [-1.6954, -1.6944, -1.4497, -1.3212, -1.2316, -1.1277, -1.0209, -0.9154,\n",
      "         -0.8161, -0.7029, -0.5788, -0.4913, -0.5054, -0.5054, -0.5054, -0.0329,\n",
      "         -0.5054, -0.5836, -0.5054, -0.5054, -0.5135, -0.8043, -0.8303, -0.5054,\n",
      "         -1.7541, -3.2631, -1.9850, -1.4355, -3.2796, -2.6922],\n",
      "        [-1.6944, -1.4497, -1.3212, -1.2316, -1.1277, -1.0209, -0.9154, -0.8161,\n",
      "         -0.7029, -0.5788, -0.4913, -0.5054, -0.5054, -0.5054, -0.0329, -0.5054,\n",
      "         -0.5836, -0.5054, -0.5054, -0.5135, -0.8043, -0.8303, -0.5054, -1.7541,\n",
      "         -3.2631, -1.9850, -1.4355, -3.2796, -2.6922, -2.0406],\n",
      "        [-1.4497, -1.3212, -1.2316, -1.1277, -1.0209, -0.9154, -0.8161, -0.7029,\n",
      "         -0.5788, -0.4913, -0.5054, -0.5054, -0.5054, -0.0329, -0.5054, -0.5836,\n",
      "         -0.5054, -0.5054, -0.5135, -0.8043, -0.8303, -0.5054, -1.7541, -3.2631,\n",
      "         -1.9850, -1.4355, -3.2796, -2.6922, -2.0406, -2.0406],\n",
      "        [-1.3212, -1.2316, -1.1277, -1.0209, -0.9154, -0.8161, -0.7029, -0.5788,\n",
      "         -0.4913, -0.5054, -0.5054, -0.5054, -0.0329, -0.5054, -0.5836, -0.5054,\n",
      "         -0.5054, -0.5135, -0.8043, -0.8303, -0.5054, -1.7541, -3.2631, -1.9850,\n",
      "         -1.4355, -3.2796, -2.6922, -2.0406, -2.0406, -1.4355],\n",
      "        [-1.2316, -1.1277, -1.0209, -0.9154, -0.8161, -0.7029, -0.5788, -0.4913,\n",
      "         -0.5054, -0.5054, -0.5054, -0.0329, -0.5054, -0.5836, -0.5054, -0.5054,\n",
      "         -0.5135, -0.8043, -0.8303, -0.5054, -1.7541, -3.2631, -1.9850, -1.4355,\n",
      "         -3.2796, -2.6922, -2.0406, -2.0406, -1.4355, -0.8303],\n",
      "        [-1.1277, -1.0209, -0.9154, -0.8161, -0.7029, -0.5788, -0.4913, -0.5054,\n",
      "         -0.5054, -0.5054, -0.0329, -0.5054, -0.5836, -0.5054, -0.5054, -0.5135,\n",
      "         -0.8043, -0.8303, -0.5054, -1.7541, -3.2631, -1.9850, -1.4355, -3.2796,\n",
      "         -2.6922, -2.0406, -2.0406, -1.4355, -0.8303, -0.8303],\n",
      "        [-1.0209, -0.9154, -0.8161, -0.7029, -0.5788, -0.4913, -0.5054, -0.5054,\n",
      "         -0.5054, -0.0329, -0.5054, -0.5836, -0.5054, -0.5054, -0.5135, -0.8043,\n",
      "         -0.8303, -0.5054, -1.7541, -3.2631, -1.9850, -1.4355, -3.2796, -2.6922,\n",
      "         -2.0406, -2.0406, -1.4355, -0.8303, -0.8303, -0.8303],\n",
      "        [-0.9154, -0.8161, -0.7029, -0.5788, -0.4913, -0.5054, -0.5054, -0.5054,\n",
      "         -0.0329, -0.5054, -0.5836, -0.5054, -0.5054, -0.5135, -0.8043, -0.8303,\n",
      "         -0.5054, -1.7541, -3.2631, -1.9850, -1.4355, -3.2796, -2.6922, -2.0406,\n",
      "         -2.0406, -1.4355, -0.8303, -0.8303, -0.8303, -0.8303],\n",
      "        [-0.8161, -0.7029, -0.5788, -0.4913, -0.5054, -0.5054, -0.5054, -0.0329,\n",
      "         -0.5054, -0.5836, -0.5054, -0.5054, -0.5135, -0.8043, -0.8303, -0.5054,\n",
      "         -1.7541, -3.2631, -1.9850, -1.4355, -3.2796, -2.6922, -2.0406, -2.0406,\n",
      "         -1.4355, -0.8303, -0.8303, -0.8303, -0.8303, -1.4355]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 1, 1, 1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4,\n",
      "         7, 4, 4, 7, 7, 8],\n",
      "        [6, 6, 6, 6, 1, 1, 1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7,\n",
      "         4, 4, 7, 7, 8, 4],\n",
      "        [6, 6, 6, 1, 1, 1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4,\n",
      "         4, 7, 7, 8, 4, 7],\n",
      "        [6, 6, 1, 1, 1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4,\n",
      "         7, 7, 8, 4, 7, 7],\n",
      "        [6, 1, 1, 1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7,\n",
      "         7, 8, 4, 7, 7, 0],\n",
      "        [1, 1, 1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7,\n",
      "         8, 4, 7, 7, 0, 8],\n",
      "        [1, 1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8,\n",
      "         4, 7, 7, 0, 8, 7],\n",
      "        [1, 1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4,\n",
      "         7, 7, 0, 8, 7, 2],\n",
      "        [1, 0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7,\n",
      "         7, 0, 8, 7, 2, 8],\n",
      "        [0, 5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7, 7,\n",
      "         0, 8, 7, 2, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7, 7, 0,\n",
      "         8, 7, 2, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7, 7, 0, 8,\n",
      "         7, 2, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7, 7, 0, 8, 7,\n",
      "         2, 8, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7, 7, 0, 8, 7, 2,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7, 7, 0, 8, 7, 2, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [5, 5, 5, 7, 4, 4, 4, 6, 4, 7, 4, 4, 7, 7, 8, 4, 7, 7, 0, 8, 7, 2, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.3525, -3.1367, -2.9462, -2.7239, -2.5093, -2.2809, -2.0233, -1.7472,\n",
      "         -1.5703, -1.4125, -1.2581, -1.0891, -0.9276, -0.7784, -0.6238, -1.4222,\n",
      "         -2.6667, -2.1546, -1.0566, -2.6803, -2.5865, -1.8115, -1.7985, -1.4050,\n",
      "         -0.4987, -0.4987, -0.1893, -0.4987, -0.7855, -0.7855],\n",
      "        [-3.1367, -2.9462, -2.7239, -2.5093, -2.2809, -2.0233, -1.7472, -1.5703,\n",
      "         -1.4125, -1.2581, -1.0891, -0.9276, -0.7784, -0.6238, -1.4222, -2.6667,\n",
      "         -2.1546, -1.0566, -2.6803, -2.5865, -1.8115, -1.7985, -1.4050, -0.4987,\n",
      "         -0.4987, -0.1893, -0.4987, -0.7855, -0.7855, -0.1204],\n",
      "        [-2.9462, -2.7239, -2.5093, -2.2809, -2.0233, -1.7472, -1.5703, -1.4125,\n",
      "         -1.2581, -1.0891, -0.9276, -0.7784, -0.6238, -1.4222, -2.6667, -2.1546,\n",
      "         -1.0566, -2.6803, -2.5865, -1.8115, -1.7985, -1.4050, -0.4987, -0.4987,\n",
      "         -0.1893, -0.4987, -0.7855, -0.7855, -0.1204, -0.9013],\n",
      "        [-2.7239, -2.5093, -2.2809, -2.0233, -1.7472, -1.5703, -1.4125, -1.2581,\n",
      "         -1.0891, -0.9276, -0.7784, -0.6238, -1.4222, -2.6667, -2.1546, -1.0566,\n",
      "         -2.6803, -2.5865, -1.8115, -1.7985, -1.4050, -0.4987, -0.4987, -0.1893,\n",
      "         -0.4987, -0.7855, -0.7855, -0.1204, -0.9013, -0.5742],\n",
      "        [-2.5093, -2.2809, -2.0233, -1.7472, -1.5703, -1.4125, -1.2581, -1.0891,\n",
      "         -0.9276, -0.7784, -0.6238, -1.4222, -2.6667, -2.1546, -1.0566, -2.6803,\n",
      "         -2.5865, -1.8115, -1.7985, -1.4050, -0.4987, -0.4987, -0.1893, -0.4987,\n",
      "         -0.7855, -0.7855, -0.1204, -0.9013, -0.5742, -0.9142],\n",
      "        [-2.2809, -2.0233, -1.7472, -1.5703, -1.4125, -1.2581, -1.0891, -0.9276,\n",
      "         -0.7784, -0.6238, -1.4222, -2.6667, -2.1546, -1.0566, -2.6803, -2.5865,\n",
      "         -1.8115, -1.7985, -1.4050, -0.4987, -0.4987, -0.1893, -0.4987, -0.7855,\n",
      "         -0.7855, -0.1204, -0.9013, -0.5742, -0.9142, -0.7686],\n",
      "        [-2.0233, -1.7472, -1.5703, -1.4125, -1.2581, -1.0891, -0.9276, -0.7784,\n",
      "         -0.6238, -1.4222, -2.6667, -2.1546, -1.0566, -2.6803, -2.5865, -1.8115,\n",
      "         -1.7985, -1.4050, -0.4987, -0.4987, -0.1893, -0.4987, -0.7855, -0.7855,\n",
      "         -0.1204, -0.9013, -0.5742, -0.9142, -0.7686, -0.1204],\n",
      "        [-1.7472, -1.5703, -1.4125, -1.2581, -1.0891, -0.9276, -0.7784, -0.6238,\n",
      "         -1.4222, -2.6667, -2.1546, -1.0566, -2.6803, -2.5865, -1.8115, -1.7985,\n",
      "         -1.4050, -0.4987, -0.4987, -0.1893, -0.4987, -0.7855, -0.7855, -0.1204,\n",
      "         -0.9013, -0.5742, -0.9142, -0.7686, -0.1204, -0.4987],\n",
      "        [-1.5703, -1.4125, -1.2581, -1.0891, -0.9276, -0.7784, -0.6238, -1.4222,\n",
      "         -2.6667, -2.1546, -1.0566, -2.6803, -2.5865, -1.8115, -1.7985, -1.4050,\n",
      "         -0.4987, -0.4987, -0.1893, -0.4987, -0.7855, -0.7855, -0.1204, -0.9013,\n",
      "         -0.5742, -0.9142, -0.7686, -0.1204, -0.4987, -0.4987],\n",
      "        [-1.4125, -1.2581, -1.0891, -0.9276, -0.7784, -0.6238, -1.4222, -2.6667,\n",
      "         -2.1546, -1.0566, -2.6803, -2.5865, -1.8115, -1.7985, -1.4050, -0.4987,\n",
      "         -0.4987, -0.1893, -0.4987, -0.7855, -0.7855, -0.1204, -0.9013, -0.5742,\n",
      "         -0.9142, -0.7686, -0.1204, -0.4987, -0.4987, -0.4987],\n",
      "        [-1.2581, -1.0891, -0.9276, -0.7784, -0.6238, -1.4222, -2.6667, -2.1546,\n",
      "         -1.0566, -2.6803, -2.5865, -1.8115, -1.7985, -1.4050, -0.4987, -0.4987,\n",
      "         -0.1893, -0.4987, -0.7855, -0.7855, -0.1204, -0.9013, -0.5742, -0.9142,\n",
      "         -0.7686, -0.1204, -0.4987, -0.4987, -0.4987, -0.4987],\n",
      "        [-1.0891, -0.9276, -0.7784, -0.6238, -1.4222, -2.6667, -2.1546, -1.0566,\n",
      "         -2.6803, -2.5865, -1.8115, -1.7985, -1.4050, -0.4987, -0.4987, -0.1893,\n",
      "         -0.4987, -0.7855, -0.7855, -0.1204, -0.9013, -0.5742, -0.9142, -0.7686,\n",
      "         -0.1204, -0.4987, -0.4987, -0.4987, -0.4987,  0.2474],\n",
      "        [-0.9276, -0.7784, -0.6238, -1.4222, -2.6667, -2.1546, -1.0566, -2.6803,\n",
      "         -2.5865, -1.8115, -1.7985, -1.4050, -0.4987, -0.4987, -0.1893, -0.4987,\n",
      "         -0.7855, -0.7855, -0.1204, -0.9013, -0.5742, -0.9142, -0.7686, -0.1204,\n",
      "         -0.4987, -0.4987, -0.4987, -0.4987,  0.2474, -0.7676],\n",
      "        [-0.7784, -0.6238, -1.4222, -2.6667, -2.1546, -1.0566, -2.6803, -2.5865,\n",
      "         -1.8115, -1.7985, -1.4050, -0.4987, -0.4987, -0.1893, -0.4987, -0.7855,\n",
      "         -0.7855, -0.1204, -0.9013, -0.5742, -0.9142, -0.7686, -0.1204, -0.4987,\n",
      "         -0.4987, -0.4987, -0.4987,  0.2474, -0.7676, -0.4987],\n",
      "        [-0.6238, -1.4222, -2.6667, -2.1546, -1.0566, -2.6803, -2.5865, -1.8115,\n",
      "         -1.7985, -1.4050, -0.4987, -0.4987, -0.1893, -0.4987, -0.7855, -0.7855,\n",
      "         -0.1204, -0.9013, -0.5742, -0.9142, -0.7686, -0.1204, -0.4987, -0.4987,\n",
      "         -0.4987, -0.4987,  0.2474, -0.7676, -0.4987, -0.4987],\n",
      "        [-1.4222, -2.6667, -2.1546, -1.0566, -2.6803, -2.5865, -1.8115, -1.7985,\n",
      "         -1.4050, -0.4987, -0.4987, -0.1893, -0.4987, -0.7855, -0.7855, -0.1204,\n",
      "         -0.9013, -0.5742, -0.9142, -0.7686, -0.1204, -0.4987, -0.4987, -0.4987,\n",
      "         -0.4987,  0.2474, -0.7676, -0.4987, -0.4987, -0.4987]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0,\n",
      "         4, 4, 0, 4, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4,\n",
      "         4, 0, 4, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4,\n",
      "         0, 4, 8, 8, 8, 7],\n",
      "        [5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0,\n",
      "         4, 8, 8, 8, 7, 7],\n",
      "        [5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4,\n",
      "         8, 8, 8, 7, 7, 7],\n",
      "        [5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8,\n",
      "         8, 8, 7, 7, 7, 0],\n",
      "        [5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8,\n",
      "         8, 7, 7, 7, 0, 8],\n",
      "        [5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8,\n",
      "         7, 7, 7, 0, 8, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7,\n",
      "         7, 7, 0, 8, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7, 7,\n",
      "         7, 0, 8, 4, 4, 4],\n",
      "        [6, 6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7, 7, 7,\n",
      "         0, 8, 4, 4, 4, 4],\n",
      "        [6, 6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7, 7, 7, 0,\n",
      "         8, 4, 4, 4, 4, 7],\n",
      "        [6, 6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7, 7, 7, 0, 8,\n",
      "         4, 4, 4, 4, 7, 7],\n",
      "        [6, 6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7, 7, 7, 0, 8, 4,\n",
      "         4, 4, 4, 7, 7, 4],\n",
      "        [6, 7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7, 7, 7, 0, 8, 4, 4,\n",
      "         4, 4, 7, 7, 4, 4],\n",
      "        [7, 7, 0, 3, 7, 2, 1, 1, 0, 4, 4, 0, 4, 8, 8, 8, 7, 7, 7, 0, 8, 4, 4, 4,\n",
      "         4, 7, 7, 4, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.7447, -2.3542, -1.8124, -2.7588, -2.8343, -1.9215, -1.9091, -1.6567,\n",
      "         -1.5422, -1.4394, -1.3422, -1.2558, -1.1760, -1.0363, -0.8924, -0.9057,\n",
      "         -0.6419, -0.9193, -0.9796, -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,\n",
      "          0.2014, -0.7666, -0.5022, -0.5022, -0.5022, -1.3762],\n",
      "        [-2.3542, -1.8124, -2.7588, -2.8343, -1.9215, -1.9091, -1.6567, -1.5422,\n",
      "         -1.4394, -1.3422, -1.2558, -1.1760, -1.0363, -0.8924, -0.9057, -0.6419,\n",
      "         -0.9193, -0.9796, -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,  0.2014,\n",
      "         -0.7666, -0.5022, -0.5022, -0.5022, -1.3762, -0.5022],\n",
      "        [-1.8124, -2.7588, -2.8343, -1.9215, -1.9091, -1.6567, -1.5422, -1.4394,\n",
      "         -1.3422, -1.2558, -1.1760, -1.0363, -0.8924, -0.9057, -0.6419, -0.9193,\n",
      "         -0.9796, -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,  0.2014, -0.7666,\n",
      "         -0.5022, -0.5022, -0.5022, -1.3762, -0.5022, -0.5022],\n",
      "        [-2.7588, -2.8343, -1.9215, -1.9091, -1.6567, -1.5422, -1.4394, -1.3422,\n",
      "         -1.2558, -1.1760, -1.0363, -0.8924, -0.9057, -0.6419, -0.9193, -0.9796,\n",
      "         -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,  0.2014, -0.7666, -0.5022,\n",
      "         -0.5022, -0.5022, -1.3762, -0.5022, -0.5022, -1.7884],\n",
      "        [-2.8343, -1.9215, -1.9091, -1.6567, -1.5422, -1.4394, -1.3422, -1.2558,\n",
      "         -1.1760, -1.0363, -0.8924, -0.9057, -0.6419, -0.9193, -0.9796, -0.3917,\n",
      "         -0.5022, -0.5022, -0.5022, -0.5022,  0.2014, -0.7666, -0.5022, -0.5022,\n",
      "         -0.5022, -1.3762, -0.5022, -0.5022, -1.7884, -1.7420],\n",
      "        [-1.9215, -1.9091, -1.6567, -1.5422, -1.4394, -1.3422, -1.2558, -1.1760,\n",
      "         -1.0363, -0.8924, -0.9057, -0.6419, -0.9193, -0.9796, -0.3917, -0.5022,\n",
      "         -0.5022, -0.5022, -0.5022,  0.2014, -0.7666, -0.5022, -0.5022, -0.5022,\n",
      "         -1.3762, -0.5022, -0.5022, -1.7884, -1.7420, -0.9620],\n",
      "        [-1.9091, -1.6567, -1.5422, -1.4394, -1.3422, -1.2558, -1.1760, -1.0363,\n",
      "         -0.8924, -0.9057, -0.6419, -0.9193, -0.9796, -0.3917, -0.5022, -0.5022,\n",
      "         -0.5022, -0.5022,  0.2014, -0.7666, -0.5022, -0.5022, -0.5022, -1.3762,\n",
      "         -0.5022, -0.5022, -1.7884, -1.7420, -0.9620, -2.1224],\n",
      "        [-1.6567, -1.5422, -1.4394, -1.3422, -1.2558, -1.1760, -1.0363, -0.8924,\n",
      "         -0.9057, -0.6419, -0.9193, -0.9796, -0.3917, -0.5022, -0.5022, -0.5022,\n",
      "         -0.5022,  0.2014, -0.7666, -0.5022, -0.5022, -0.5022, -1.3762, -0.5022,\n",
      "         -0.5022, -1.7884, -1.7420, -0.9620, -2.1224, -1.8463],\n",
      "        [-1.5422, -1.4394, -1.3422, -1.2558, -1.1760, -1.0363, -0.8924, -0.9057,\n",
      "         -0.6419, -0.9193, -0.9796, -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,\n",
      "          0.2014, -0.7666, -0.5022, -0.5022, -0.5022, -1.3762, -0.5022, -0.5022,\n",
      "         -1.7884, -1.7420, -0.9620, -2.1224, -1.8463, -1.9019],\n",
      "        [-1.4394, -1.3422, -1.2558, -1.1760, -1.0363, -0.8924, -0.9057, -0.6419,\n",
      "         -0.9193, -0.9796, -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,  0.2014,\n",
      "         -0.7666, -0.5022, -0.5022, -0.5022, -1.3762, -0.5022, -0.5022, -1.7884,\n",
      "         -1.7420, -0.9620, -2.1224, -1.8463, -1.9019, -2.1871],\n",
      "        [-1.3422, -1.2558, -1.1760, -1.0363, -0.8924, -0.9057, -0.6419, -0.9193,\n",
      "         -0.9796, -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,  0.2014, -0.7666,\n",
      "         -0.5022, -0.5022, -0.5022, -1.3762, -0.5022, -0.5022, -1.7884, -1.7420,\n",
      "         -0.9620, -2.1224, -1.8463, -1.9019, -2.1871, -2.7756],\n",
      "        [-1.2558, -1.1760, -1.0363, -0.8924, -0.9057, -0.6419, -0.9193, -0.9796,\n",
      "         -0.3917, -0.5022, -0.5022, -0.5022, -0.5022,  0.2014, -0.7666, -0.5022,\n",
      "         -0.5022, -0.5022, -1.3762, -0.5022, -0.5022, -1.7884, -1.7420, -0.9620,\n",
      "         -2.1224, -1.8463, -1.9019, -2.1871, -2.7756, -2.4896],\n",
      "        [-1.1760, -1.0363, -0.8924, -0.9057, -0.6419, -0.9193, -0.9796, -0.3917,\n",
      "         -0.5022, -0.5022, -0.5022, -0.5022,  0.2014, -0.7666, -0.5022, -0.5022,\n",
      "         -0.5022, -1.3762, -0.5022, -0.5022, -1.7884, -1.7420, -0.9620, -2.1224,\n",
      "         -1.8463, -1.9019, -2.1871, -2.7756, -2.4896, -1.3864],\n",
      "        [-1.0363, -0.8924, -0.9057, -0.6419, -0.9193, -0.9796, -0.3917, -0.5022,\n",
      "         -0.5022, -0.5022, -0.5022,  0.2014, -0.7666, -0.5022, -0.5022, -0.5022,\n",
      "         -1.3762, -0.5022, -0.5022, -1.7884, -1.7420, -0.9620, -2.1224, -1.8463,\n",
      "         -1.9019, -2.1871, -2.7756, -2.4896, -1.3864, -1.9480],\n",
      "        [-0.8924, -0.9057, -0.6419, -0.9193, -0.9796, -0.3917, -0.5022, -0.5022,\n",
      "         -0.5022, -0.5022,  0.2014, -0.7666, -0.5022, -0.5022, -0.5022, -1.3762,\n",
      "         -0.5022, -0.5022, -1.7884, -1.7420, -0.9620, -2.1224, -1.8463, -1.9019,\n",
      "         -2.1871, -2.7756, -2.4896, -1.3864, -1.9480, -1.7608],\n",
      "        [-0.9057, -0.6419, -0.9193, -0.9796, -0.3917, -0.5022, -0.5022, -0.5022,\n",
      "         -0.5022,  0.2014, -0.7666, -0.5022, -0.5022, -0.5022, -1.3762, -0.5022,\n",
      "         -0.5022, -1.7884, -1.7420, -0.9620, -2.1224, -1.8463, -1.9019, -2.1871,\n",
      "         -2.7756, -2.4896, -1.3864, -1.9480, -1.7608, -1.3526]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[7, 0, 6, 7, 2, 1, 1, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4,\n",
      "         6, 7, 4, 4, 4, 7],\n",
      "        [0, 6, 7, 2, 1, 1, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6,\n",
      "         7, 4, 4, 4, 7, 4],\n",
      "        [6, 7, 2, 1, 1, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7,\n",
      "         4, 4, 4, 7, 4, 4],\n",
      "        [7, 2, 1, 1, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4,\n",
      "         4, 4, 7, 4, 4, 7],\n",
      "        [2, 1, 1, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4,\n",
      "         4, 7, 4, 4, 7, 7],\n",
      "        [1, 1, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4,\n",
      "         7, 4, 4, 7, 7, 2],\n",
      "        [1, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7,\n",
      "         4, 4, 7, 7, 2, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4,\n",
      "         4, 7, 7, 2, 7, 1],\n",
      "        [5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4,\n",
      "         7, 7, 2, 7, 1, 8],\n",
      "        [5, 5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4, 7,\n",
      "         7, 2, 7, 1, 8, 3],\n",
      "        [5, 5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4, 7, 7,\n",
      "         2, 7, 1, 8, 3, 8],\n",
      "        [5, 5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4, 7, 7, 2,\n",
      "         7, 1, 8, 3, 8, 0],\n",
      "        [5, 5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4, 7, 7, 2, 7,\n",
      "         1, 8, 3, 8, 0, 1],\n",
      "        [5, 6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4, 7, 7, 2, 7, 1,\n",
      "         8, 3, 8, 0, 1, 3],\n",
      "        [6, 7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4, 7, 7, 2, 7, 1, 8,\n",
      "         3, 8, 0, 1, 3, 3],\n",
      "        [7, 6, 7, 0, 5, 4, 4, 4, 4, 6, 7, 4, 4, 4, 7, 4, 4, 7, 7, 2, 7, 1, 8, 3,\n",
      "         8, 0, 1, 3, 3, 1]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.4956, -3.2788, -3.1307, -2.9491, -2.7426, -2.5477, -2.3453, -2.1393,\n",
      "         -1.8784, -1.6199, -1.3574, -1.1192, -0.8767, -1.2060, -0.4962, -0.4962,\n",
      "         -1.5878, -1.5449, -0.4744, -1.8974, -1.2034, -1.6423, -1.7254, -2.3671,\n",
      "         -1.9574, -0.9174, -1.4274, -1.1660, -0.7436, -0.8297],\n",
      "        [-3.2788, -3.1307, -2.9491, -2.7426, -2.5477, -2.3453, -2.1393, -1.8784,\n",
      "         -1.6199, -1.3574, -1.1192, -0.8767, -1.2060, -0.4962, -0.4962, -1.5878,\n",
      "         -1.5449, -0.4744, -1.8974, -1.2034, -1.6423, -1.7254, -2.3671, -1.9574,\n",
      "         -0.9174, -1.4274, -1.1660, -0.7436, -0.8297, -0.8320],\n",
      "        [-3.1307, -2.9491, -2.7426, -2.5477, -2.3453, -2.1393, -1.8784, -1.6199,\n",
      "         -1.3574, -1.1192, -0.8767, -1.2060, -0.4962, -0.4962, -1.5878, -1.5449,\n",
      "         -0.4744, -1.8974, -1.2034, -1.6423, -1.7254, -2.3671, -1.9574, -0.9174,\n",
      "         -1.4274, -1.1660, -0.7436, -0.8297, -0.8320, -0.8725],\n",
      "        [-2.9491, -2.7426, -2.5477, -2.3453, -2.1393, -1.8784, -1.6199, -1.3574,\n",
      "         -1.1192, -0.8767, -1.2060, -0.4962, -0.4962, -1.5878, -1.5449, -0.4744,\n",
      "         -1.8974, -1.2034, -1.6423, -1.7254, -2.3671, -1.9574, -0.9174, -1.4274,\n",
      "         -1.1660, -0.7436, -0.8297, -0.8320, -0.8725, -0.8551],\n",
      "        [-2.7426, -2.5477, -2.3453, -2.1393, -1.8784, -1.6199, -1.3574, -1.1192,\n",
      "         -0.8767, -1.2060, -0.4962, -0.4962, -1.5878, -1.5449, -0.4744, -1.8974,\n",
      "         -1.2034, -1.6423, -1.7254, -2.3671, -1.9574, -0.9174, -1.4274, -1.1660,\n",
      "         -0.7436, -0.8297, -0.8320, -0.8725, -0.8551, -0.6957],\n",
      "        [-2.5477, -2.3453, -2.1393, -1.8784, -1.6199, -1.3574, -1.1192, -0.8767,\n",
      "         -1.2060, -0.4962, -0.4962, -1.5878, -1.5449, -0.4744, -1.8974, -1.2034,\n",
      "         -1.6423, -1.7254, -2.3671, -1.9574, -0.9174, -1.4274, -1.1660, -0.7436,\n",
      "         -0.8297, -0.8320, -0.8725, -0.8551, -0.6957, -0.5249],\n",
      "        [-2.3453, -2.1393, -1.8784, -1.6199, -1.3574, -1.1192, -0.8767, -1.2060,\n",
      "         -0.4962, -0.4962, -1.5878, -1.5449, -0.4744, -1.8974, -1.2034, -1.6423,\n",
      "         -1.7254, -2.3671, -1.9574, -0.9174, -1.4274, -1.1660, -0.7436, -0.8297,\n",
      "         -0.8320, -0.8725, -0.8551, -0.6957, -0.5249, -0.4962],\n",
      "        [-2.1393, -1.8784, -1.6199, -1.3574, -1.1192, -0.8767, -1.2060, -0.4962,\n",
      "         -0.4962, -1.5878, -1.5449, -0.4744, -1.8974, -1.2034, -1.6423, -1.7254,\n",
      "         -2.3671, -1.9574, -0.9174, -1.4274, -1.1660, -0.7436, -0.8297, -0.8320,\n",
      "         -0.8725, -0.8551, -0.6957, -0.5249, -0.4962, -0.7778],\n",
      "        [-1.8784, -1.6199, -1.3574, -1.1192, -0.8767, -1.2060, -0.4962, -0.4962,\n",
      "         -1.5878, -1.5449, -0.4744, -1.8974, -1.2034, -1.6423, -1.7254, -2.3671,\n",
      "         -1.9574, -0.9174, -1.4274, -1.1660, -0.7436, -0.8297, -0.8320, -0.8725,\n",
      "         -0.8551, -0.6957, -0.5249, -0.4962, -0.7778, -0.4597],\n",
      "        [-1.6199, -1.3574, -1.1192, -0.8767, -1.2060, -0.4962, -0.4962, -1.5878,\n",
      "         -1.5449, -0.4744, -1.8974, -1.2034, -1.6423, -1.7254, -2.3671, -1.9574,\n",
      "         -0.9174, -1.4274, -1.1660, -0.7436, -0.8297, -0.8320, -0.8725, -0.8551,\n",
      "         -0.6957, -0.5249, -0.4962, -0.7778, -0.4597, -1.0518],\n",
      "        [-1.3574, -1.1192, -0.8767, -1.2060, -0.4962, -0.4962, -1.5878, -1.5449,\n",
      "         -0.4744, -1.8974, -1.2034, -1.6423, -1.7254, -2.3671, -1.9574, -0.9174,\n",
      "         -1.4274, -1.1660, -0.7436, -0.8297, -0.8320, -0.8725, -0.8551, -0.6957,\n",
      "         -0.5249, -0.4962, -0.7778, -0.4597, -1.0518, -1.2346],\n",
      "        [-1.1192, -0.8767, -1.2060, -0.4962, -0.4962, -1.5878, -1.5449, -0.4744,\n",
      "         -1.8974, -1.2034, -1.6423, -1.7254, -2.3671, -1.9574, -0.9174, -1.4274,\n",
      "         -1.1660, -0.7436, -0.8297, -0.8320, -0.8725, -0.8551, -0.6957, -0.5249,\n",
      "         -0.4962, -0.7778, -0.4597, -1.0518, -1.2346, -0.9174],\n",
      "        [-0.8767, -1.2060, -0.4962, -0.4962, -1.5878, -1.5449, -0.4744, -1.8974,\n",
      "         -1.2034, -1.6423, -1.7254, -2.3671, -1.9574, -0.9174, -1.4274, -1.1660,\n",
      "         -0.7436, -0.8297, -0.8320, -0.8725, -0.8551, -0.6957, -0.5249, -0.4962,\n",
      "         -0.7778, -0.4597, -1.0518, -1.2346, -0.9174, -0.8431],\n",
      "        [-1.2060, -0.4962, -0.4962, -1.5878, -1.5449, -0.4744, -1.8974, -1.2034,\n",
      "         -1.6423, -1.7254, -2.3671, -1.9574, -0.9174, -1.4274, -1.1660, -0.7436,\n",
      "         -0.8297, -0.8320, -0.8725, -0.8551, -0.6957, -0.5249, -0.4962, -0.7778,\n",
      "         -0.4597, -1.0518, -1.2346, -0.9174, -0.8431, -0.9294],\n",
      "        [-0.4962, -0.4962, -1.5878, -1.5449, -0.4744, -1.8974, -1.2034, -1.6423,\n",
      "         -1.7254, -2.3671, -1.9574, -0.9174, -1.4274, -1.1660, -0.7436, -0.8297,\n",
      "         -0.8320, -0.8725, -0.8551, -0.6957, -0.5249, -0.4962, -0.7778, -0.4597,\n",
      "         -1.0518, -1.2346, -0.9174, -0.8431, -0.9294, -0.9395],\n",
      "        [-0.4962, -1.5878, -1.5449, -0.4744, -1.8974, -1.2034, -1.6423, -1.7254,\n",
      "         -2.3671, -1.9574, -0.9174, -1.4274, -1.1660, -0.7436, -0.8297, -0.8320,\n",
      "         -0.8725, -0.8551, -0.6957, -0.5249, -0.4962, -0.7778, -0.4597, -1.0518,\n",
      "         -1.2346, -0.9174, -0.8431, -0.9294, -0.9395, -0.9834]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8,\n",
      "         0, 8, 7, 3, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0,\n",
      "         8, 7, 3, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8,\n",
      "         7, 3, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7,\n",
      "         3, 5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3,\n",
      "         5, 5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5,\n",
      "         5, 5, 5, 5, 5, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5,\n",
      "         5, 5, 5, 5, 5, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5,\n",
      "         5, 5, 5, 5, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5,\n",
      "         5, 5, 5, 4, 7, 5],\n",
      "        [6, 6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5, 5,\n",
      "         5, 5, 4, 7, 5, 7],\n",
      "        [6, 6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5, 5, 5,\n",
      "         5, 4, 7, 5, 7, 1],\n",
      "        [6, 6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5, 5, 5, 5,\n",
      "         4, 7, 5, 7, 1, 8],\n",
      "        [6, 7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5, 5, 5, 5, 4,\n",
      "         7, 5, 7, 1, 8, 5],\n",
      "        [7, 4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5, 5, 5, 5, 4, 7,\n",
      "         5, 7, 1, 8, 5, 5],\n",
      "        [4, 4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5, 5, 5, 5, 4, 7, 5,\n",
      "         7, 1, 8, 5, 5, 5],\n",
      "        [4, 7, 7, 2, 7, 1, 8, 7, 8, 0, 8, 7, 3, 5, 5, 5, 5, 5, 5, 5, 4, 7, 5, 7,\n",
      "         1, 8, 5, 5, 5, 5]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.3830, -2.3249, -0.9404, -2.8018, -1.5263, -1.7111, -2.5691, -2.4934,\n",
      "         -2.6562, -0.9288, -2.1659, -1.5183, -0.7869, -0.8034, -0.6259, -0.6880,\n",
      "         -0.6614, -0.4937, -0.4937, -0.8477, -1.2871, -0.3464, -1.6578, -1.5397,\n",
      "         -0.9288, -0.6429, -0.8016, -0.9288, -0.8580, -0.9456],\n",
      "        [-2.3249, -0.9404, -2.8018, -1.5263, -1.7111, -2.5691, -2.4934, -2.6562,\n",
      "         -0.9288, -2.1659, -1.5183, -0.7869, -0.8034, -0.6259, -0.6880, -0.6614,\n",
      "         -0.4937, -0.4937, -0.8477, -1.2871, -0.3464, -1.6578, -1.5397, -0.9288,\n",
      "         -0.6429, -0.8016, -0.9288, -0.8580, -0.9456, -0.9816],\n",
      "        [-0.9404, -2.8018, -1.5263, -1.7111, -2.5691, -2.4934, -2.6562, -0.9288,\n",
      "         -2.1659, -1.5183, -0.7869, -0.8034, -0.6259, -0.6880, -0.6614, -0.4937,\n",
      "         -0.4937, -0.8477, -1.2871, -0.3464, -1.6578, -1.5397, -0.9288, -0.6429,\n",
      "         -0.8016, -0.9288, -0.8580, -0.9456, -0.9816, -1.2350],\n",
      "        [-2.8018, -1.5263, -1.7111, -2.5691, -2.4934, -2.6562, -0.9288, -2.1659,\n",
      "         -1.5183, -0.7869, -0.8034, -0.6259, -0.6880, -0.6614, -0.4937, -0.4937,\n",
      "         -0.8477, -1.2871, -0.3464, -1.6578, -1.5397, -0.9288, -0.6429, -0.8016,\n",
      "         -0.9288, -0.8580, -0.9456, -0.9816, -1.2350, -1.4149],\n",
      "        [-1.5263, -1.7111, -2.5691, -2.4934, -2.6562, -0.9288, -2.1659, -1.5183,\n",
      "         -0.7869, -0.8034, -0.6259, -0.6880, -0.6614, -0.4937, -0.4937, -0.8477,\n",
      "         -1.2871, -0.3464, -1.6578, -1.5397, -0.9288, -0.6429, -0.8016, -0.9288,\n",
      "         -0.8580, -0.9456, -0.9816, -1.2350, -1.4149, -1.7094],\n",
      "        [-1.7111, -2.5691, -2.4934, -2.6562, -0.9288, -2.1659, -1.5183, -0.7869,\n",
      "         -0.8034, -0.6259, -0.6880, -0.6614, -0.4937, -0.4937, -0.8477, -1.2871,\n",
      "         -0.3464, -1.6578, -1.5397, -0.9288, -0.6429, -0.8016, -0.9288, -0.8580,\n",
      "         -0.9456, -0.9816, -1.2350, -1.4149, -1.7094, -1.8655],\n",
      "        [-2.5691, -2.4934, -2.6562, -0.9288, -2.1659, -1.5183, -0.7869, -0.8034,\n",
      "         -0.6259, -0.6880, -0.6614, -0.4937, -0.4937, -0.8477, -1.2871, -0.3464,\n",
      "         -1.6578, -1.5397, -0.9288, -0.6429, -0.8016, -0.9288, -0.8580, -0.9456,\n",
      "         -0.9816, -1.2350, -1.4149, -1.7094, -1.8655, -1.8625],\n",
      "        [-2.4934, -2.6562, -0.9288, -2.1659, -1.5183, -0.7869, -0.8034, -0.6259,\n",
      "         -0.6880, -0.6614, -0.4937, -0.4937, -0.8477, -1.2871, -0.3464, -1.6578,\n",
      "         -1.5397, -0.9288, -0.6429, -0.8016, -0.9288, -0.8580, -0.9456, -0.9816,\n",
      "         -1.2350, -1.4149, -1.7094, -1.8655, -1.8625, -1.8731],\n",
      "        [-2.6562, -0.9288, -2.1659, -1.5183, -0.7869, -0.8034, -0.6259, -0.6880,\n",
      "         -0.6614, -0.4937, -0.4937, -0.8477, -1.2871, -0.3464, -1.6578, -1.5397,\n",
      "         -0.9288, -0.6429, -0.8016, -0.9288, -0.8580, -0.9456, -0.9816, -1.2350,\n",
      "         -1.4149, -1.7094, -1.8655, -1.8625, -1.8731, -1.8417],\n",
      "        [-0.9288, -2.1659, -1.5183, -0.7869, -0.8034, -0.6259, -0.6880, -0.6614,\n",
      "         -0.4937, -0.4937, -0.8477, -1.2871, -0.3464, -1.6578, -1.5397, -0.9288,\n",
      "         -0.6429, -0.8016, -0.9288, -0.8580, -0.9456, -0.9816, -1.2350, -1.4149,\n",
      "         -1.7094, -1.8655, -1.8625, -1.8731, -1.8417, -1.7052],\n",
      "        [-2.1659, -1.5183, -0.7869, -0.8034, -0.6259, -0.6880, -0.6614, -0.4937,\n",
      "         -0.4937, -0.8477, -1.2871, -0.3464, -1.6578, -1.5397, -0.9288, -0.6429,\n",
      "         -0.8016, -0.9288, -0.8580, -0.9456, -0.9816, -1.2350, -1.4149, -1.7094,\n",
      "         -1.8655, -1.8625, -1.8731, -1.8417, -1.7052, -1.1741],\n",
      "        [-1.5183, -0.7869, -0.8034, -0.6259, -0.6880, -0.6614, -0.4937, -0.4937,\n",
      "         -0.8477, -1.2871, -0.3464, -1.6578, -1.5397, -0.9288, -0.6429, -0.8016,\n",
      "         -0.9288, -0.8580, -0.9456, -0.9816, -1.2350, -1.4149, -1.7094, -1.8655,\n",
      "         -1.8625, -1.8731, -1.8417, -1.7052, -1.1741, -0.8454],\n",
      "        [-0.7869, -0.8034, -0.6259, -0.6880, -0.6614, -0.4937, -0.4937, -0.8477,\n",
      "         -1.2871, -0.3464, -1.6578, -1.5397, -0.9288, -0.6429, -0.8016, -0.9288,\n",
      "         -0.8580, -0.9456, -0.9816, -1.2350, -1.4149, -1.7094, -1.8655, -1.8625,\n",
      "         -1.8731, -1.8417, -1.7052, -1.1741, -0.8454, -0.4726],\n",
      "        [-0.8034, -0.6259, -0.6880, -0.6614, -0.4937, -0.4937, -0.8477, -1.2871,\n",
      "         -0.3464, -1.6578, -1.5397, -0.9288, -0.6429, -0.8016, -0.9288, -0.8580,\n",
      "         -0.9456, -0.9816, -1.2350, -1.4149, -1.7094, -1.8655, -1.8625, -1.8731,\n",
      "         -1.8417, -1.7052, -1.1741, -0.8454, -0.4726, -0.4937],\n",
      "        [-0.6259, -0.6880, -0.6614, -0.4937, -0.4937, -0.8477, -1.2871, -0.3464,\n",
      "         -1.6578, -1.5397, -0.9288, -0.6429, -0.8016, -0.9288, -0.8580, -0.9456,\n",
      "         -0.9816, -1.2350, -1.4149, -1.7094, -1.8655, -1.8625, -1.8731, -1.8417,\n",
      "         -1.7052, -1.1741, -0.8454, -0.4726, -0.4937, -0.4937],\n",
      "        [-0.6880, -0.6614, -0.4937, -0.4937, -0.8477, -1.2871, -0.3464, -1.6578,\n",
      "         -1.5397, -0.9288, -0.6429, -0.8016, -0.9288, -0.8580, -0.9456, -0.9816,\n",
      "         -1.2350, -1.4149, -1.7094, -1.8655, -1.8625, -1.8731, -1.8417, -1.7052,\n",
      "         -1.1741, -0.8454, -0.4726, -0.4937, -0.4937, -0.4937]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[7, 7, 6, 7, 3, 8, 7, 8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1,\n",
      "         8, 5, 7, 8, 5, 5],\n",
      "        [7, 6, 7, 3, 8, 7, 8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8,\n",
      "         5, 7, 8, 5, 5, 6],\n",
      "        [6, 7, 3, 8, 7, 8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5,\n",
      "         7, 8, 5, 5, 6, 6],\n",
      "        [7, 3, 8, 7, 8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7,\n",
      "         8, 5, 5, 6, 6, 6],\n",
      "        [3, 8, 7, 8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8,\n",
      "         5, 5, 6, 6, 6, 6],\n",
      "        [8, 7, 8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5,\n",
      "         5, 6, 6, 6, 6, 6],\n",
      "        [7, 8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [0, 8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [8, 7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [3, 1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [1, 0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [0, 5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 4],\n",
      "        [5, 5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 6, 4, 4],\n",
      "        [5, 5, 4, 4, 7, 7, 7, 7, 1, 8, 5, 7, 8, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "         6, 6, 6, 4, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.2821, -0.9136, -0.8330, -1.4535, -2.1439, -1.3246, -2.7263, -2.1754,\n",
      "         -1.5641, -1.3744, -1.6771, -1.7205, -1.4813, -1.7734, -1.6505, -1.4193,\n",
      "         -1.4193, -1.4193, -1.1233, -1.1220, -1.1267, -1.5034, -1.0527, -0.8185,\n",
      "         -0.8765, -0.5091, -0.6272, -0.4962, -0.4962, -0.4962],\n",
      "        [-0.9136, -0.8330, -1.4535, -2.1439, -1.3246, -2.7263, -2.1754, -1.5641,\n",
      "         -1.3744, -1.6771, -1.7205, -1.4813, -1.7734, -1.6505, -1.4193, -1.4193,\n",
      "         -1.4193, -1.1233, -1.1220, -1.1267, -1.5034, -1.0527, -0.8185, -0.8765,\n",
      "         -0.5091, -0.6272, -0.4962, -0.4962, -0.4962, -1.0578],\n",
      "        [-0.8330, -1.4535, -2.1439, -1.3246, -2.7263, -2.1754, -1.5641, -1.3744,\n",
      "         -1.6771, -1.7205, -1.4813, -1.7734, -1.6505, -1.4193, -1.4193, -1.4193,\n",
      "         -1.1233, -1.1220, -1.1267, -1.5034, -1.0527, -0.8185, -0.8765, -0.5091,\n",
      "         -0.6272, -0.4962, -0.4962, -0.4962, -1.0578, -0.5054],\n",
      "        [-1.4535, -2.1439, -1.3246, -2.7263, -2.1754, -1.5641, -1.3744, -1.6771,\n",
      "         -1.7205, -1.4813, -1.7734, -1.6505, -1.4193, -1.4193, -1.4193, -1.1233,\n",
      "         -1.1220, -1.1267, -1.5034, -1.0527, -0.8185, -0.8765, -0.5091, -0.6272,\n",
      "         -0.4962, -0.4962, -0.4962, -1.0578, -0.5054, -0.7215],\n",
      "        [-2.1439, -1.3246, -2.7263, -2.1754, -1.5641, -1.3744, -1.6771, -1.7205,\n",
      "         -1.4813, -1.7734, -1.6505, -1.4193, -1.4193, -1.4193, -1.1233, -1.1220,\n",
      "         -1.1267, -1.5034, -1.0527, -0.8185, -0.8765, -0.5091, -0.6272, -0.4962,\n",
      "         -0.4962, -0.4962, -1.0578, -0.5054, -0.7215, -1.4193],\n",
      "        [-1.3246, -2.7263, -2.1754, -1.5641, -1.3744, -1.6771, -1.7205, -1.4813,\n",
      "         -1.7734, -1.6505, -1.4193, -1.4193, -1.4193, -1.1233, -1.1220, -1.1267,\n",
      "         -1.5034, -1.0527, -0.8185, -0.8765, -0.5091, -0.6272, -0.4962, -0.4962,\n",
      "         -0.4962, -1.0578, -0.5054, -0.7215, -1.4193, -0.5054],\n",
      "        [-2.7263, -2.1754, -1.5641, -1.3744, -1.6771, -1.7205, -1.4813, -1.7734,\n",
      "         -1.6505, -1.4193, -1.4193, -1.4193, -1.1233, -1.1220, -1.1267, -1.5034,\n",
      "         -1.0527, -0.8185, -0.8765, -0.5091, -0.6272, -0.4962, -0.4962, -0.4962,\n",
      "         -1.0578, -0.5054, -0.7215, -1.4193, -0.5054, -0.5054],\n",
      "        [-2.1754, -1.5641, -1.3744, -1.6771, -1.7205, -1.4813, -1.7734, -1.6505,\n",
      "         -1.4193, -1.4193, -1.4193, -1.1233, -1.1220, -1.1267, -1.5034, -1.0527,\n",
      "         -0.8185, -0.8765, -0.5091, -0.6272, -0.4962, -0.4962, -0.4962, -1.0578,\n",
      "         -0.5054, -0.7215, -1.4193, -0.5054, -0.5054, -0.4962],\n",
      "        [-1.5641, -1.3744, -1.6771, -1.7205, -1.4813, -1.7734, -1.6505, -1.4193,\n",
      "         -1.4193, -1.4193, -1.1233, -1.1220, -1.1267, -1.5034, -1.0527, -0.8185,\n",
      "         -0.8765, -0.5091, -0.6272, -0.4962, -0.4962, -0.4962, -1.0578, -0.5054,\n",
      "         -0.7215, -1.4193, -0.5054, -0.5054, -0.4962, -1.3938],\n",
      "        [-1.3744, -1.6771, -1.7205, -1.4813, -1.7734, -1.6505, -1.4193, -1.4193,\n",
      "         -1.4193, -1.1233, -1.1220, -1.1267, -1.5034, -1.0527, -0.8185, -0.8765,\n",
      "         -0.5091, -0.6272, -0.4962, -0.4962, -0.4962, -1.0578, -0.5054, -0.7215,\n",
      "         -1.4193, -0.5054, -0.5054, -0.4962, -1.3938, -0.4962],\n",
      "        [-1.6771, -1.7205, -1.4813, -1.7734, -1.6505, -1.4193, -1.4193, -1.4193,\n",
      "         -1.1233, -1.1220, -1.1267, -1.5034, -1.0527, -0.8185, -0.8765, -0.5091,\n",
      "         -0.6272, -0.4962, -0.4962, -0.4962, -1.0578, -0.5054, -0.7215, -1.4193,\n",
      "         -0.5054, -0.5054, -0.4962, -1.3938, -0.4962, -0.0312],\n",
      "        [-1.7205, -1.4813, -1.7734, -1.6505, -1.4193, -1.4193, -1.4193, -1.1233,\n",
      "         -1.1220, -1.1267, -1.5034, -1.0527, -0.8185, -0.8765, -0.5091, -0.6272,\n",
      "         -0.4962, -0.4962, -0.4962, -1.0578, -0.5054, -0.7215, -1.4193, -0.5054,\n",
      "         -0.5054, -0.4962, -1.3938, -0.4962, -0.0312, -0.4962],\n",
      "        [-1.4813, -1.7734, -1.6505, -1.4193, -1.4193, -1.4193, -1.1233, -1.1220,\n",
      "         -1.1267, -1.5034, -1.0527, -0.8185, -0.8765, -0.5091, -0.6272, -0.4962,\n",
      "         -0.4962, -0.4962, -1.0578, -0.5054, -0.7215, -1.4193, -0.5054, -0.5054,\n",
      "         -0.4962, -1.3938, -0.4962, -0.0312, -0.4962, -0.4962],\n",
      "        [-1.7734, -1.6505, -1.4193, -1.4193, -1.4193, -1.1233, -1.1220, -1.1267,\n",
      "         -1.5034, -1.0527, -0.8185, -0.8765, -0.5091, -0.6272, -0.4962, -0.4962,\n",
      "         -0.4962, -1.0578, -0.5054, -0.7215, -1.4193, -0.5054, -0.5054, -0.4962,\n",
      "         -1.3938, -0.4962, -0.0312, -0.4962, -0.4962, -0.4962],\n",
      "        [-1.6505, -1.4193, -1.4193, -1.4193, -1.1233, -1.1220, -1.1267, -1.5034,\n",
      "         -1.0527, -0.8185, -0.8765, -0.5091, -0.6272, -0.4962, -0.4962, -0.4962,\n",
      "         -1.0578, -0.5054, -0.7215, -1.4193, -0.5054, -0.5054, -0.4962, -1.3938,\n",
      "         -0.4962, -0.0312, -0.4962, -0.4962, -0.4962, -0.6089],\n",
      "        [-1.4193, -1.4193, -1.4193, -1.1233, -1.1220, -1.1267, -1.5034, -1.0527,\n",
      "         -0.8185, -0.8765, -0.5091, -0.6272, -0.4962, -0.4962, -0.4962, -1.0578,\n",
      "         -0.5054, -0.7215, -1.4193, -0.5054, -0.5054, -0.4962, -1.3938, -0.4962,\n",
      "         -0.0312, -0.4962, -0.4962, -0.4962, -0.6089, -0.3047]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[1, 5, 5, 7, 7, 3, 7, 1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6,\n",
      "         7, 6, 7, 4, 4, 4],\n",
      "        [5, 5, 7, 7, 3, 7, 1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7,\n",
      "         6, 7, 4, 4, 4, 7],\n",
      "        [5, 7, 7, 3, 7, 1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6,\n",
      "         7, 4, 4, 4, 7, 8],\n",
      "        [7, 7, 3, 7, 1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7,\n",
      "         4, 4, 4, 7, 8, 7],\n",
      "        [7, 3, 7, 1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4,\n",
      "         4, 4, 7, 8, 7, 8],\n",
      "        [3, 7, 1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4,\n",
      "         4, 7, 8, 7, 8, 8],\n",
      "        [7, 1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4,\n",
      "         7, 8, 7, 8, 8, 8],\n",
      "        [1, 0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7,\n",
      "         8, 7, 8, 8, 8, 4],\n",
      "        [0, 3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8,\n",
      "         7, 8, 8, 8, 4, 7],\n",
      "        [3, 3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8, 7,\n",
      "         8, 8, 8, 4, 7, 4],\n",
      "        [3, 0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8, 7, 8,\n",
      "         8, 8, 4, 7, 4, 7],\n",
      "        [0, 3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8, 7, 8, 8,\n",
      "         8, 4, 7, 4, 7, 4],\n",
      "        [3, 2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8, 7, 8, 8, 8,\n",
      "         4, 7, 4, 7, 4, 4],\n",
      "        [2, 0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8, 7, 8, 8, 8, 4,\n",
      "         7, 4, 7, 4, 4, 4],\n",
      "        [0, 8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8, 7, 8, 8, 8, 4, 7,\n",
      "         4, 7, 4, 4, 4, 7],\n",
      "        [8, 8, 8, 6, 6, 6, 7, 6, 6, 7, 6, 7, 4, 4, 4, 7, 8, 7, 8, 8, 8, 4, 7, 4,\n",
      "         7, 4, 4, 4, 7, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.4530, -2.0930, -1.8621, -1.8613, -1.8642, -1.8558, -1.8193, -1.6774,\n",
      "         -1.6862, -1.4899, -1.4674, -1.7024, -1.3317, -1.1492, -1.3554, -1.0957,\n",
      "         -1.0957, -2.0272, -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,  0.0881,\n",
      "         -0.5107, -0.5107, -0.5107, -0.5107, -0.1468, -0.5607],\n",
      "        [-2.0930, -1.8621, -1.8613, -1.8642, -1.8558, -1.8193, -1.6774, -1.6862,\n",
      "         -1.4899, -1.4674, -1.7024, -1.3317, -1.1492, -1.3554, -1.0957, -1.0957,\n",
      "         -2.0272, -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,  0.0881, -0.5107,\n",
      "         -0.5107, -0.5107, -0.5107, -0.1468, -0.5607, -0.5107],\n",
      "        [-1.8621, -1.8613, -1.8642, -1.8558, -1.8193, -1.6774, -1.6862, -1.4899,\n",
      "         -1.4674, -1.7024, -1.3317, -1.1492, -1.3554, -1.0957, -1.0957, -2.0272,\n",
      "         -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,  0.0881, -0.5107, -0.5107,\n",
      "         -0.5107, -0.5107, -0.1468, -0.5607, -0.5107, -1.4437],\n",
      "        [-1.8613, -1.8642, -1.8558, -1.8193, -1.6774, -1.6862, -1.4899, -1.4674,\n",
      "         -1.7024, -1.3317, -1.1492, -1.3554, -1.0957, -1.0957, -2.0272, -1.0957,\n",
      "         -1.0957, -0.5107, -1.1741, -0.5107,  0.0881, -0.5107, -0.5107, -0.5107,\n",
      "         -0.5107, -0.1468, -0.5607, -0.5107, -1.4437, -0.5362],\n",
      "        [-1.8642, -1.8558, -1.8193, -1.6774, -1.6862, -1.4899, -1.4674, -1.7024,\n",
      "         -1.3317, -1.1492, -1.3554, -1.0957, -1.0957, -2.0272, -1.0957, -1.0957,\n",
      "         -0.5107, -1.1741, -0.5107,  0.0881, -0.5107, -0.5107, -0.5107, -0.5107,\n",
      "         -0.1468, -0.5607, -0.5107, -1.4437, -0.5362, -3.1724],\n",
      "        [-1.8558, -1.8193, -1.6774, -1.6862, -1.4899, -1.4674, -1.7024, -1.3317,\n",
      "         -1.1492, -1.3554, -1.0957, -1.0957, -2.0272, -1.0957, -1.0957, -0.5107,\n",
      "         -1.1741, -0.5107,  0.0881, -0.5107, -0.5107, -0.5107, -0.5107, -0.1468,\n",
      "         -0.5607, -0.5107, -1.4437, -0.5362, -3.1724, -1.0957],\n",
      "        [-1.8193, -1.6774, -1.6862, -1.4899, -1.4674, -1.7024, -1.3317, -1.1492,\n",
      "         -1.3554, -1.0957, -1.0957, -2.0272, -1.0957, -1.0957, -0.5107, -1.1741,\n",
      "         -0.5107,  0.0881, -0.5107, -0.5107, -0.5107, -0.5107, -0.1468, -0.5607,\n",
      "         -0.5107, -1.4437, -0.5362, -3.1724, -1.0957, -2.3430],\n",
      "        [-1.6774, -1.6862, -1.4899, -1.4674, -1.7024, -1.3317, -1.1492, -1.3554,\n",
      "         -1.0957, -1.0957, -2.0272, -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,\n",
      "          0.0881, -0.5107, -0.5107, -0.5107, -0.5107, -0.1468, -0.5607, -0.5107,\n",
      "         -1.4437, -0.5362, -3.1724, -1.0957, -2.3430, -1.0957],\n",
      "        [-1.6862, -1.4899, -1.4674, -1.7024, -1.3317, -1.1492, -1.3554, -1.0957,\n",
      "         -1.0957, -2.0272, -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,  0.0881,\n",
      "         -0.5107, -0.5107, -0.5107, -0.5107, -0.1468, -0.5607, -0.5107, -1.4437,\n",
      "         -0.5362, -3.1724, -1.0957, -2.3430, -1.0957, -1.0957],\n",
      "        [-1.4899, -1.4674, -1.7024, -1.3317, -1.1492, -1.3554, -1.0957, -1.0957,\n",
      "         -2.0272, -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,  0.0881, -0.5107,\n",
      "         -0.5107, -0.5107, -0.5107, -0.1468, -0.5607, -0.5107, -1.4437, -0.5362,\n",
      "         -3.1724, -1.0957, -2.3430, -1.0957, -1.0957, -1.0957],\n",
      "        [-1.4674, -1.7024, -1.3317, -1.1492, -1.3554, -1.0957, -1.0957, -2.0272,\n",
      "         -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,  0.0881, -0.5107, -0.5107,\n",
      "         -0.5107, -0.5107, -0.1468, -0.5607, -0.5107, -1.4437, -0.5362, -3.1724,\n",
      "         -1.0957, -2.3430, -1.0957, -1.0957, -1.0957, -1.3774],\n",
      "        [-1.7024, -1.3317, -1.1492, -1.3554, -1.0957, -1.0957, -2.0272, -1.0957,\n",
      "         -1.0957, -0.5107, -1.1741, -0.5107,  0.0881, -0.5107, -0.5107, -0.5107,\n",
      "         -0.5107, -0.1468, -0.5607, -0.5107, -1.4437, -0.5362, -3.1724, -1.0957,\n",
      "         -2.3430, -1.0957, -1.0957, -1.0957, -1.3774, -1.0957],\n",
      "        [-1.3317, -1.1492, -1.3554, -1.0957, -1.0957, -2.0272, -1.0957, -1.0957,\n",
      "         -0.5107, -1.1741, -0.5107,  0.0881, -0.5107, -0.5107, -0.5107, -0.5107,\n",
      "         -0.1468, -0.5607, -0.5107, -1.4437, -0.5362, -3.1724, -1.0957, -2.3430,\n",
      "         -1.0957, -1.0957, -1.0957, -1.3774, -1.0957, -1.0957],\n",
      "        [-1.1492, -1.3554, -1.0957, -1.0957, -2.0272, -1.0957, -1.0957, -0.5107,\n",
      "         -1.1741, -0.5107,  0.0881, -0.5107, -0.5107, -0.5107, -0.5107, -0.1468,\n",
      "         -0.5607, -0.5107, -1.4437, -0.5362, -3.1724, -1.0957, -2.3430, -1.0957,\n",
      "         -1.0957, -1.0957, -1.3774, -1.0957, -1.0957, -0.1643],\n",
      "        [-1.3554, -1.0957, -1.0957, -2.0272, -1.0957, -1.0957, -0.5107, -1.1741,\n",
      "         -0.5107,  0.0881, -0.5107, -0.5107, -0.5107, -0.5107, -0.1468, -0.5607,\n",
      "         -0.5107, -1.4437, -0.5362, -3.1724, -1.0957, -2.3430, -1.0957, -1.0957,\n",
      "         -1.0957, -1.3774, -1.0957, -1.0957, -0.1643, -0.5107],\n",
      "        [-1.0957, -1.0957, -2.0272, -1.0957, -1.0957, -0.5107, -1.1741, -0.5107,\n",
      "          0.0881, -0.5107, -0.5107, -0.5107, -0.5107, -0.1468, -0.5607, -0.5107,\n",
      "         -1.4437, -0.5362, -3.1724, -1.0957, -2.3430, -1.0957, -1.0957, -1.0957,\n",
      "         -1.3774, -1.0957, -1.0957, -0.1643, -0.5107, -0.9571]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[1, 0, 6, 6, 6, 6, 6, 6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5,\n",
      "         4, 4, 4, 4, 7, 7],\n",
      "        [0, 6, 6, 6, 6, 6, 6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4,\n",
      "         4, 4, 4, 7, 7, 4],\n",
      "        [6, 6, 6, 6, 6, 6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4,\n",
      "         4, 4, 7, 7, 4, 7],\n",
      "        [6, 6, 6, 6, 6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4,\n",
      "         4, 7, 7, 4, 7, 7],\n",
      "        [6, 6, 6, 6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4,\n",
      "         7, 7, 4, 7, 7, 7],\n",
      "        [6, 6, 6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7,\n",
      "         7, 4, 7, 7, 7, 8],\n",
      "        [6, 6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7,\n",
      "         4, 7, 7, 7, 8, 7],\n",
      "        [6, 1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4,\n",
      "         7, 7, 7, 8, 7, 8],\n",
      "        [1, 6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7,\n",
      "         7, 7, 8, 7, 8, 8],\n",
      "        [6, 3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7, 7,\n",
      "         7, 8, 7, 8, 8, 8],\n",
      "        [3, 0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7, 7, 7,\n",
      "         8, 7, 8, 8, 8, 7],\n",
      "        [0, 2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7, 7, 7, 8,\n",
      "         7, 8, 8, 8, 7, 8],\n",
      "        [2, 1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7, 7, 7, 8, 7,\n",
      "         8, 8, 8, 7, 8, 8],\n",
      "        [1, 2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7, 7, 7, 8, 7, 8,\n",
      "         8, 8, 7, 8, 8, 8],\n",
      "        [2, 8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7, 7, 7, 8, 7, 8, 8,\n",
      "         8, 7, 8, 8, 8, 4],\n",
      "        [8, 8, 8, 8, 8, 4, 7, 4, 5, 4, 4, 4, 4, 7, 7, 4, 7, 7, 7, 8, 7, 8, 8, 8,\n",
      "         7, 8, 8, 8, 4, 7]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.6578, -2.5323, -2.3894, -2.2379, -2.0702, -1.9295, -1.7887, -1.6464,\n",
      "         -1.4904, -1.3425, -1.1724, -1.0134, -0.8589, -0.7177, -0.6621, -1.1715,\n",
      "         -0.5773, -2.6405, -1.2346, -2.0733, -2.1517, -1.5363, -2.0344, -1.5991,\n",
      "         -1.3115, -1.1090, -0.2611, -0.5438, -0.7580, -0.5438],\n",
      "        [-2.5323, -2.3894, -2.2379, -2.0702, -1.9295, -1.7887, -1.6464, -1.4904,\n",
      "         -1.3425, -1.1724, -1.0134, -0.8589, -0.7177, -0.6621, -1.1715, -0.5773,\n",
      "         -2.6405, -1.2346, -2.0733, -2.1517, -1.5363, -2.0344, -1.5991, -1.3115,\n",
      "         -1.1090, -0.2611, -0.5438, -0.7580, -0.5438, -0.5438],\n",
      "        [-2.3894, -2.2379, -2.0702, -1.9295, -1.7887, -1.6464, -1.4904, -1.3425,\n",
      "         -1.1724, -1.0134, -0.8589, -0.7177, -0.6621, -1.1715, -0.5773, -2.6405,\n",
      "         -1.2346, -2.0733, -2.1517, -1.5363, -2.0344, -1.5991, -1.3115, -1.1090,\n",
      "         -0.2611, -0.5438, -0.7580, -0.5438, -0.5438, -0.4024],\n",
      "        [-2.2379, -2.0702, -1.9295, -1.7887, -1.6464, -1.4904, -1.3425, -1.1724,\n",
      "         -1.0134, -0.8589, -0.7177, -0.6621, -1.1715, -0.5773, -2.6405, -1.2346,\n",
      "         -2.0733, -2.1517, -1.5363, -2.0344, -1.5991, -1.3115, -1.1090, -0.2611,\n",
      "         -0.5438, -0.7580, -0.5438, -0.5438, -0.4024, -0.5438],\n",
      "        [-2.0702, -1.9295, -1.7887, -1.6464, -1.4904, -1.3425, -1.1724, -1.0134,\n",
      "         -0.8589, -0.7177, -0.6621, -1.1715, -0.5773, -2.6405, -1.2346, -2.0733,\n",
      "         -2.1517, -1.5363, -2.0344, -1.5991, -1.3115, -1.1090, -0.2611, -0.5438,\n",
      "         -0.7580, -0.5438, -0.5438, -0.4024, -0.5438, -0.5438],\n",
      "        [-1.9295, -1.7887, -1.6464, -1.4904, -1.3425, -1.1724, -1.0134, -0.8589,\n",
      "         -0.7177, -0.6621, -1.1715, -0.5773, -2.6405, -1.2346, -2.0733, -2.1517,\n",
      "         -1.5363, -2.0344, -1.5991, -1.3115, -1.1090, -0.2611, -0.5438, -0.7580,\n",
      "         -0.5438, -0.5438, -0.4024, -0.5438, -0.5438, -0.5438],\n",
      "        [-1.7887, -1.6464, -1.4904, -1.3425, -1.1724, -1.0134, -0.8589, -0.7177,\n",
      "         -0.6621, -1.1715, -0.5773, -2.6405, -1.2346, -2.0733, -2.1517, -1.5363,\n",
      "         -2.0344, -1.5991, -1.3115, -1.1090, -0.2611, -0.5438, -0.7580, -0.5438,\n",
      "         -0.5438, -0.4024, -0.5438, -0.5438, -0.5438, -0.5438],\n",
      "        [-1.6464, -1.4904, -1.3425, -1.1724, -1.0134, -0.8589, -0.7177, -0.6621,\n",
      "         -1.1715, -0.5773, -2.6405, -1.2346, -2.0733, -2.1517, -1.5363, -2.0344,\n",
      "         -1.5991, -1.3115, -1.1090, -0.2611, -0.5438, -0.7580, -0.5438, -0.5438,\n",
      "         -0.4024, -0.5438, -0.5438, -0.5438, -0.5438, -0.2611],\n",
      "        [-1.4904, -1.3425, -1.1724, -1.0134, -0.8589, -0.7177, -0.6621, -1.1715,\n",
      "         -0.5773, -2.6405, -1.2346, -2.0733, -2.1517, -1.5363, -2.0344, -1.5991,\n",
      "         -1.3115, -1.1090, -0.2611, -0.5438, -0.7580, -0.5438, -0.5438, -0.4024,\n",
      "         -0.5438, -0.5438, -0.5438, -0.5438, -0.2611, -0.5438],\n",
      "        [-1.3425, -1.1724, -1.0134, -0.8589, -0.7177, -0.6621, -1.1715, -0.5773,\n",
      "         -2.6405, -1.2346, -2.0733, -2.1517, -1.5363, -2.0344, -1.5991, -1.3115,\n",
      "         -1.1090, -0.2611, -0.5438, -0.7580, -0.5438, -0.5438, -0.4024, -0.5438,\n",
      "         -0.5438, -0.5438, -0.5438, -0.2611, -0.5438, -0.5438],\n",
      "        [-1.1724, -1.0134, -0.8589, -0.7177, -0.6621, -1.1715, -0.5773, -2.6405,\n",
      "         -1.2346, -2.0733, -2.1517, -1.5363, -2.0344, -1.5991, -1.3115, -1.1090,\n",
      "         -0.2611, -0.5438, -0.7580, -0.5438, -0.5438, -0.4024, -0.5438, -0.5438,\n",
      "         -0.5438, -0.5438, -0.2611, -0.5438, -0.5438, -1.3547],\n",
      "        [-1.0134, -0.8589, -0.7177, -0.6621, -1.1715, -0.5773, -2.6405, -1.2346,\n",
      "         -2.0733, -2.1517, -1.5363, -2.0344, -1.5991, -1.3115, -1.1090, -0.2611,\n",
      "         -0.5438, -0.7580, -0.5438, -0.5438, -0.4024, -0.5438, -0.5438, -0.5438,\n",
      "         -0.5438, -0.2611, -0.5438, -0.5438, -1.3547, -1.9072],\n",
      "        [-0.8589, -0.7177, -0.6621, -1.1715, -0.5773, -2.6405, -1.2346, -2.0733,\n",
      "         -2.1517, -1.5363, -2.0344, -1.5991, -1.3115, -1.1090, -0.2611, -0.5438,\n",
      "         -0.7580, -0.5438, -0.5438, -0.4024, -0.5438, -0.5438, -0.5438, -0.5438,\n",
      "         -0.2611, -0.5438, -0.5438, -1.3547, -1.9072, -1.9569],\n",
      "        [-0.7177, -0.6621, -1.1715, -0.5773, -2.6405, -1.2346, -2.0733, -2.1517,\n",
      "         -1.5363, -2.0344, -1.5991, -1.3115, -1.1090, -0.2611, -0.5438, -0.7580,\n",
      "         -0.5438, -0.5438, -0.4024, -0.5438, -0.5438, -0.5438, -0.5438, -0.2611,\n",
      "         -0.5438, -0.5438, -1.3547, -1.9072, -1.9569, -2.8048],\n",
      "        [-0.6621, -1.1715, -0.5773, -2.6405, -1.2346, -2.0733, -2.1517, -1.5363,\n",
      "         -2.0344, -1.5991, -1.3115, -1.1090, -0.2611, -0.5438, -0.7580, -0.5438,\n",
      "         -0.5438, -0.4024, -0.5438, -0.5438, -0.5438, -0.5438, -0.2611, -0.5438,\n",
      "         -0.5438, -1.3547, -1.9072, -1.9569, -2.8048, -1.9569],\n",
      "        [-1.1715, -0.5773, -2.6405, -1.2346, -2.0733, -2.1517, -1.5363, -2.0344,\n",
      "         -1.5991, -1.3115, -1.1090, -0.2611, -0.5438, -0.7580, -0.5438, -0.5438,\n",
      "         -0.4024, -0.5438, -0.5438, -0.5438, -0.5438, -0.2611, -0.5438, -0.5438,\n",
      "         -1.3547, -1.9072, -1.9569, -2.8048, -1.9569, -1.9569]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3,\n",
      "         1, 8, 8, 4, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1,\n",
      "         8, 8, 4, 7, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8,\n",
      "         8, 4, 7, 4, 4, 7],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4,\n",
      "         7, 4, 4, 7, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7,\n",
      "         4, 4, 7, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4,\n",
      "         4, 7, 4, 4, 4, 4],\n",
      "        [5, 5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4,\n",
      "         7, 4, 4, 4, 4, 8],\n",
      "        [5, 5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7,\n",
      "         4, 4, 4, 4, 8, 4],\n",
      "        [5, 5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7, 4,\n",
      "         4, 4, 4, 8, 4, 4],\n",
      "        [5, 5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7, 4, 4,\n",
      "         4, 4, 8, 4, 4, 7],\n",
      "        [5, 5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7, 4, 4, 4,\n",
      "         4, 8, 4, 4, 7, 7],\n",
      "        [5, 5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7, 4, 4, 4, 4,\n",
      "         8, 4, 4, 7, 7, 8],\n",
      "        [5, 6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7, 4, 4, 4, 4, 8,\n",
      "         4, 4, 7, 7, 8, 8],\n",
      "        [6, 7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7, 4, 4, 4, 4, 8, 4,\n",
      "         4, 7, 7, 8, 8, 8],\n",
      "        [7, 6, 7, 1, 3, 0, 3, 0, 3, 1, 8, 8, 4, 7, 4, 4, 7, 4, 4, 4, 4, 8, 4, 4,\n",
      "         7, 7, 8, 8, 8, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-1.9483, -2.8915, -2.2795, -3.2230, -3.1944, -2.6040, -3.0643, -2.6764,\n",
      "         -2.3659, -1.7059, -1.3845, -1.2578, -1.1528, -1.0058, -0.8659, -0.7504,\n",
      "         -0.6429, -0.5233, -0.6277, -0.5233, -0.1528, -0.5233, -0.5233, -1.5031,\n",
      "         -2.0997, -1.9735, -2.0859, -1.4014, -1.4014, -1.4014],\n",
      "        [-2.8915, -2.2795, -3.2230, -3.1944, -2.6040, -3.0643, -2.6764, -2.3659,\n",
      "         -1.7059, -1.3845, -1.2578, -1.1528, -1.0058, -0.8659, -0.7504, -0.6429,\n",
      "         -0.5233, -0.6277, -0.5233, -0.1528, -0.5233, -0.5233, -1.5031, -2.0997,\n",
      "         -1.9735, -2.0859, -1.4014, -1.4014, -1.4014, -0.7169],\n",
      "        [-2.2795, -3.2230, -3.1944, -2.6040, -3.0643, -2.6764, -2.3659, -1.7059,\n",
      "         -1.3845, -1.2578, -1.1528, -1.0058, -0.8659, -0.7504, -0.6429, -0.5233,\n",
      "         -0.6277, -0.5233, -0.1528, -0.5233, -0.5233, -1.5031, -2.0997, -1.9735,\n",
      "         -2.0859, -1.4014, -1.4014, -1.4014, -0.7169, -0.7169],\n",
      "        [-3.2230, -3.1944, -2.6040, -3.0643, -2.6764, -2.3659, -1.7059, -1.3845,\n",
      "         -1.2578, -1.1528, -1.0058, -0.8659, -0.7504, -0.6429, -0.5233, -0.6277,\n",
      "         -0.5233, -0.1528, -0.5233, -0.5233, -1.5031, -2.0997, -1.9735, -2.0859,\n",
      "         -1.4014, -1.4014, -1.4014, -0.7169, -0.7169, -0.5233],\n",
      "        [-3.1944, -2.6040, -3.0643, -2.6764, -2.3659, -1.7059, -1.3845, -1.2578,\n",
      "         -1.1528, -1.0058, -0.8659, -0.7504, -0.6429, -0.5233, -0.6277, -0.5233,\n",
      "         -0.1528, -0.5233, -0.5233, -1.5031, -2.0997, -1.9735, -2.0859, -1.4014,\n",
      "         -1.4014, -1.4014, -0.7169, -0.7169, -0.5233, -0.5233],\n",
      "        [-2.6040, -3.0643, -2.6764, -2.3659, -1.7059, -1.3845, -1.2578, -1.1528,\n",
      "         -1.0058, -0.8659, -0.7504, -0.6429, -0.5233, -0.6277, -0.5233, -0.1528,\n",
      "         -0.5233, -0.5233, -1.5031, -2.0997, -1.9735, -2.0859, -1.4014, -1.4014,\n",
      "         -1.4014, -0.7169, -0.7169, -0.5233, -0.5233, -1.0322],\n",
      "        [-3.0643, -2.6764, -2.3659, -1.7059, -1.3845, -1.2578, -1.1528, -1.0058,\n",
      "         -0.8659, -0.7504, -0.6429, -0.5233, -0.6277, -0.5233, -0.1528, -0.5233,\n",
      "         -0.5233, -1.5031, -2.0997, -1.9735, -2.0859, -1.4014, -1.4014, -1.4014,\n",
      "         -0.7169, -0.7169, -0.5233, -0.5233, -1.0322, -0.4602],\n",
      "        [-2.6764, -2.3659, -1.7059, -1.3845, -1.2578, -1.1528, -1.0058, -0.8659,\n",
      "         -0.7504, -0.6429, -0.5233, -0.6277, -0.5233, -0.1528, -0.5233, -0.5233,\n",
      "         -1.5031, -2.0997, -1.9735, -2.0859, -1.4014, -1.4014, -1.4014, -0.7169,\n",
      "         -0.7169, -0.5233, -0.5233, -1.0322, -0.4602, -0.5233],\n",
      "        [-2.3659, -1.7059, -1.3845, -1.2578, -1.1528, -1.0058, -0.8659, -0.7504,\n",
      "         -0.6429, -0.5233, -0.6277, -0.5233, -0.1528, -0.5233, -0.5233, -1.5031,\n",
      "         -2.0997, -1.9735, -2.0859, -1.4014, -1.4014, -1.4014, -0.7169, -0.7169,\n",
      "         -0.5233, -0.5233, -1.0322, -0.4602, -0.5233, -1.7904],\n",
      "        [-1.7059, -1.3845, -1.2578, -1.1528, -1.0058, -0.8659, -0.7504, -0.6429,\n",
      "         -0.5233, -0.6277, -0.5233, -0.1528, -0.5233, -0.5233, -1.5031, -2.0997,\n",
      "         -1.9735, -2.0859, -1.4014, -1.4014, -1.4014, -0.7169, -0.7169, -0.5233,\n",
      "         -0.5233, -1.0322, -0.4602, -0.5233, -1.7904, -0.5233],\n",
      "        [-1.3845, -1.2578, -1.1528, -1.0058, -0.8659, -0.7504, -0.6429, -0.5233,\n",
      "         -0.6277, -0.5233, -0.1528, -0.5233, -0.5233, -1.5031, -2.0997, -1.9735,\n",
      "         -2.0859, -1.4014, -1.4014, -1.4014, -0.7169, -0.7169, -0.5233, -0.5233,\n",
      "         -1.0322, -0.4602, -0.5233, -1.7904, -0.5233, -0.5233],\n",
      "        [-1.2578, -1.1528, -1.0058, -0.8659, -0.7504, -0.6429, -0.5233, -0.6277,\n",
      "         -0.5233, -0.1528, -0.5233, -0.5233, -1.5031, -2.0997, -1.9735, -2.0859,\n",
      "         -1.4014, -1.4014, -1.4014, -0.7169, -0.7169, -0.5233, -0.5233, -1.0322,\n",
      "         -0.4602, -0.5233, -1.7904, -0.5233, -0.5233, -0.0462],\n",
      "        [-1.1528, -1.0058, -0.8659, -0.7504, -0.6429, -0.5233, -0.6277, -0.5233,\n",
      "         -0.1528, -0.5233, -0.5233, -1.5031, -2.0997, -1.9735, -2.0859, -1.4014,\n",
      "         -1.4014, -1.4014, -0.7169, -0.7169, -0.5233, -0.5233, -1.0322, -0.4602,\n",
      "         -0.5233, -1.7904, -0.5233, -0.5233, -0.0462, -0.5233],\n",
      "        [-1.0058, -0.8659, -0.7504, -0.6429, -0.5233, -0.6277, -0.5233, -0.1528,\n",
      "         -0.5233, -0.5233, -1.5031, -2.0997, -1.9735, -2.0859, -1.4014, -1.4014,\n",
      "         -1.4014, -0.7169, -0.7169, -0.5233, -0.5233, -1.0322, -0.4602, -0.5233,\n",
      "         -1.7904, -0.5233, -0.5233, -0.0462, -0.5233, -0.5233],\n",
      "        [-0.8659, -0.7504, -0.6429, -0.5233, -0.6277, -0.5233, -0.1528, -0.5233,\n",
      "         -0.5233, -1.5031, -2.0997, -1.9735, -2.0859, -1.4014, -1.4014, -1.4014,\n",
      "         -0.7169, -0.7169, -0.5233, -0.5233, -1.0322, -0.4602, -0.5233, -1.7904,\n",
      "         -0.5233, -0.5233, -0.0462, -0.5233, -0.5233, -0.5233],\n",
      "        [-0.7504, -0.6429, -0.5233, -0.6277, -0.5233, -0.1528, -0.5233, -0.5233,\n",
      "         -1.5031, -2.0997, -1.9735, -2.0859, -1.4014, -1.4014, -1.4014, -0.7169,\n",
      "         -0.7169, -0.5233, -0.5233, -1.0322, -0.4602, -0.5233, -1.7904, -0.5233,\n",
      "         -0.5233, -0.0462, -0.5233, -0.5233, -0.5233, -0.5233]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[5, 7, 1, 3, 0, 3, 0, 3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7,\n",
      "         7, 7, 8, 8, 8, 8],\n",
      "        [7, 1, 3, 0, 3, 0, 3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [1, 3, 0, 3, 0, 3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [3, 0, 3, 0, 3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8,\n",
      "         8, 8, 8, 8, 8, 4],\n",
      "        [0, 3, 0, 3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8,\n",
      "         8, 8, 8, 8, 4, 4],\n",
      "        [3, 0, 3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8,\n",
      "         8, 8, 8, 4, 4, 7],\n",
      "        [0, 3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8,\n",
      "         8, 8, 4, 4, 7, 7],\n",
      "        [3, 1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8,\n",
      "         8, 4, 4, 7, 7, 4],\n",
      "        [1, 0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8,\n",
      "         4, 4, 7, 7, 4, 7],\n",
      "        [0, 5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4,\n",
      "         4, 7, 7, 4, 7, 4],\n",
      "        [5, 5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4, 4,\n",
      "         7, 7, 4, 7, 4, 4],\n",
      "        [5, 5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4, 4, 7,\n",
      "         7, 4, 7, 4, 4, 7],\n",
      "        [5, 5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4, 4, 7, 7,\n",
      "         4, 7, 4, 4, 7, 4],\n",
      "        [5, 6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4, 4, 7, 7, 4,\n",
      "         7, 4, 4, 7, 4, 4],\n",
      "        [6, 6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4, 4, 7, 7, 4, 7,\n",
      "         4, 4, 7, 4, 4, 4],\n",
      "        [6, 6, 4, 7, 4, 6, 4, 4, 7, 7, 7, 8, 8, 8, 8, 8, 8, 4, 4, 7, 7, 4, 7, 4,\n",
      "         4, 7, 4, 4, 4, 4]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.4209, -2.2673, -2.1196, -2.0002, -1.8775, -1.7629, -1.6430, -1.6830,\n",
      "         -2.3564, -2.3366, -2.3675, -1.7891, -2.0518, -1.7574, -1.1473, -1.1473,\n",
      "         -0.5984, -0.4943, -1.1515, -0.6169, -0.4943, -2.0073, -0.7365, -0.8737,\n",
      "         -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,  0.6041],\n",
      "        [-2.2673, -2.1196, -2.0002, -1.8775, -1.7629, -1.6430, -1.6830, -2.3564,\n",
      "         -2.3366, -2.3675, -1.7891, -2.0518, -1.7574, -1.1473, -1.1473, -0.5984,\n",
      "         -0.4943, -1.1515, -0.6169, -0.4943, -2.0073, -0.7365, -0.8737, -0.7782,\n",
      "         -0.4943, -0.4943, -0.4943, -0.4943,  0.6041, -0.4943],\n",
      "        [-2.1196, -2.0002, -1.8775, -1.7629, -1.6430, -1.6830, -2.3564, -2.3366,\n",
      "         -2.3675, -1.7891, -2.0518, -1.7574, -1.1473, -1.1473, -0.5984, -0.4943,\n",
      "         -1.1515, -0.6169, -0.4943, -2.0073, -0.7365, -0.8737, -0.7782, -0.4943,\n",
      "         -0.4943, -0.4943, -0.4943,  0.6041, -0.4943, -0.4943],\n",
      "        [-2.0002, -1.8775, -1.7629, -1.6430, -1.6830, -2.3564, -2.3366, -2.3675,\n",
      "         -1.7891, -2.0518, -1.7574, -1.1473, -1.1473, -0.5984, -0.4943, -1.1515,\n",
      "         -0.6169, -0.4943, -2.0073, -0.7365, -0.8737, -0.7782, -0.4943, -0.4943,\n",
      "         -0.4943, -0.4943,  0.6041, -0.4943, -0.4943, -0.5434],\n",
      "        [-1.8775, -1.7629, -1.6430, -1.6830, -2.3564, -2.3366, -2.3675, -1.7891,\n",
      "         -2.0518, -1.7574, -1.1473, -1.1473, -0.5984, -0.4943, -1.1515, -0.6169,\n",
      "         -0.4943, -2.0073, -0.7365, -0.8737, -0.7782, -0.4943, -0.4943, -0.4943,\n",
      "         -0.4943,  0.6041, -0.4943, -0.4943, -0.5434, -0.4943],\n",
      "        [-1.7629, -1.6430, -1.6830, -2.3564, -2.3366, -2.3675, -1.7891, -2.0518,\n",
      "         -1.7574, -1.1473, -1.1473, -0.5984, -0.4943, -1.1515, -0.6169, -0.4943,\n",
      "         -2.0073, -0.7365, -0.8737, -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,\n",
      "          0.6041, -0.4943, -0.4943, -0.5434, -0.4943, -0.4844],\n",
      "        [-1.6430, -1.6830, -2.3564, -2.3366, -2.3675, -1.7891, -2.0518, -1.7574,\n",
      "         -1.1473, -1.1473, -0.5984, -0.4943, -1.1515, -0.6169, -0.4943, -2.0073,\n",
      "         -0.7365, -0.8737, -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,  0.6041,\n",
      "         -0.4943, -0.4943, -0.5434, -0.4943, -0.4844, -1.9939],\n",
      "        [-1.6830, -2.3564, -2.3366, -2.3675, -1.7891, -2.0518, -1.7574, -1.1473,\n",
      "         -1.1473, -0.5984, -0.4943, -1.1515, -0.6169, -0.4943, -2.0073, -0.7365,\n",
      "         -0.8737, -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,  0.6041, -0.4943,\n",
      "         -0.4943, -0.5434, -0.4943, -0.4844, -1.9939, -1.5352],\n",
      "        [-2.3564, -2.3366, -2.3675, -1.7891, -2.0518, -1.7574, -1.1473, -1.1473,\n",
      "         -0.5984, -0.4943, -1.1515, -0.6169, -0.4943, -2.0073, -0.7365, -0.8737,\n",
      "         -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,  0.6041, -0.4943, -0.4943,\n",
      "         -0.5434, -0.4943, -0.4844, -1.9939, -1.5352, -0.5213],\n",
      "        [-2.3366, -2.3675, -1.7891, -2.0518, -1.7574, -1.1473, -1.1473, -0.5984,\n",
      "         -0.4943, -1.1515, -0.6169, -0.4943, -2.0073, -0.7365, -0.8737, -0.7782,\n",
      "         -0.4943, -0.4943, -0.4943, -0.4943,  0.6041, -0.4943, -0.4943, -0.5434,\n",
      "         -0.4943, -0.4844, -1.9939, -1.5352, -0.5213, -0.5373],\n",
      "        [-2.3675, -1.7891, -2.0518, -1.7574, -1.1473, -1.1473, -0.5984, -0.4943,\n",
      "         -1.1515, -0.6169, -0.4943, -2.0073, -0.7365, -0.8737, -0.7782, -0.4943,\n",
      "         -0.4943, -0.4943, -0.4943,  0.6041, -0.4943, -0.4943, -0.5434, -0.4943,\n",
      "         -0.4844, -1.9939, -1.5352, -0.5213, -0.5373, -0.5373],\n",
      "        [-1.7891, -2.0518, -1.7574, -1.1473, -1.1473, -0.5984, -0.4943, -1.1515,\n",
      "         -0.6169, -0.4943, -2.0073, -0.7365, -0.8737, -0.7782, -0.4943, -0.4943,\n",
      "         -0.4943, -0.4943,  0.6041, -0.4943, -0.4943, -0.5434, -0.4943, -0.4844,\n",
      "         -1.9939, -1.5352, -0.5213, -0.5373, -0.5373, -0.5373],\n",
      "        [-2.0518, -1.7574, -1.1473, -1.1473, -0.5984, -0.4943, -1.1515, -0.6169,\n",
      "         -0.4943, -2.0073, -0.7365, -0.8737, -0.7782, -0.4943, -0.4943, -0.4943,\n",
      "         -0.4943,  0.6041, -0.4943, -0.4943, -0.5434, -0.4943, -0.4844, -1.9939,\n",
      "         -1.5352, -0.5213, -0.5373, -0.5373, -0.5373, -1.1473],\n",
      "        [-1.7574, -1.1473, -1.1473, -0.5984, -0.4943, -1.1515, -0.6169, -0.4943,\n",
      "         -2.0073, -0.7365, -0.8737, -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,\n",
      "          0.6041, -0.4943, -0.4943, -0.5434, -0.4943, -0.4844, -1.9939, -1.5352,\n",
      "         -0.5213, -0.5373, -0.5373, -0.5373, -1.1473, -0.5373],\n",
      "        [-1.1473, -1.1473, -0.5984, -0.4943, -1.1515, -0.6169, -0.4943, -2.0073,\n",
      "         -0.7365, -0.8737, -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,  0.6041,\n",
      "         -0.4943, -0.4943, -0.5434, -0.4943, -0.4844, -1.9939, -1.5352, -0.5213,\n",
      "         -0.5373, -0.5373, -0.5373, -1.1473, -0.5373, -2.3465],\n",
      "        [-1.1473, -0.5984, -0.4943, -1.1515, -0.6169, -0.4943, -2.0073, -0.7365,\n",
      "         -0.8737, -0.7782, -0.4943, -0.4943, -0.4943, -0.4943,  0.6041, -0.4943,\n",
      "         -0.4943, -0.5434, -0.4943, -0.4844, -1.9939, -1.5352, -0.5213, -0.5373,\n",
      "         -0.5373, -0.5373, -1.1473, -0.5373, -2.3465, -1.7574]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0,\n",
      "         1, 4, 4, 4, 4, 5],\n",
      "        [6, 6, 6, 6, 6, 6, 7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1,\n",
      "         4, 4, 4, 4, 5, 4],\n",
      "        [6, 6, 6, 6, 6, 7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4,\n",
      "         4, 4, 4, 5, 4, 4],\n",
      "        [6, 6, 6, 6, 7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4,\n",
      "         4, 4, 5, 4, 4, 7],\n",
      "        [6, 6, 6, 7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4,\n",
      "         4, 5, 4, 4, 7, 4],\n",
      "        [6, 6, 7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4,\n",
      "         5, 4, 4, 7, 4, 7],\n",
      "        [6, 7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5,\n",
      "         4, 4, 7, 4, 7, 7],\n",
      "        [7, 7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4,\n",
      "         4, 7, 4, 7, 7, 7],\n",
      "        [7, 3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4,\n",
      "         7, 4, 7, 7, 7, 7],\n",
      "        [3, 8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4, 7,\n",
      "         4, 7, 7, 7, 7, 8],\n",
      "        [8, 1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4, 7, 4,\n",
      "         7, 7, 7, 7, 8, 8],\n",
      "        [1, 0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4, 7, 4, 7,\n",
      "         7, 7, 7, 8, 8, 8],\n",
      "        [0, 8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4, 7, 4, 7, 7,\n",
      "         7, 7, 8, 8, 8, 8],\n",
      "        [8, 8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4, 7, 4, 7, 7, 7,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [8, 8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4, 7, 4, 7, 7, 7, 7,\n",
      "         8, 8, 8, 8, 8, 7],\n",
      "        [8, 6, 4, 7, 3, 4, 7, 3, 0, 1, 4, 4, 4, 4, 5, 4, 4, 7, 4, 7, 7, 7, 7, 8,\n",
      "         8, 8, 8, 8, 7, 8]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-2.6710, -2.4927, -2.3277, -2.1676, -2.0089, -2.2045, -1.8897, -2.1259,\n",
      "         -2.0436, -1.5168, -1.4554, -1.3199, -1.1956, -1.0402, -0.8835, -0.7247,\n",
      "         -0.5695, -0.4952, -0.3698, -1.8266, -1.3839, -1.0495, -0.7186, -0.8616,\n",
      "         -0.5361, -0.7807, -0.4952, -2.1668, -1.3353, -1.3353],\n",
      "        [-2.4927, -2.3277, -2.1676, -2.0089, -2.2045, -1.8897, -2.1259, -2.0436,\n",
      "         -1.5168, -1.4554, -1.3199, -1.1956, -1.0402, -0.8835, -0.7247, -0.5695,\n",
      "         -0.4952, -0.3698, -1.8266, -1.3839, -1.0495, -0.7186, -0.8616, -0.5361,\n",
      "         -0.7807, -0.4952, -2.1668, -1.3353, -1.3353, -1.8898],\n",
      "        [-2.3277, -2.1676, -2.0089, -2.2045, -1.8897, -2.1259, -2.0436, -1.5168,\n",
      "         -1.4554, -1.3199, -1.1956, -1.0402, -0.8835, -0.7247, -0.5695, -0.4952,\n",
      "         -0.3698, -1.8266, -1.3839, -1.0495, -0.7186, -0.8616, -0.5361, -0.7807,\n",
      "         -0.4952, -2.1668, -1.3353, -1.3353, -1.8898, -1.3353],\n",
      "        [-2.1676, -2.0089, -2.2045, -1.8897, -2.1259, -2.0436, -1.5168, -1.4554,\n",
      "         -1.3199, -1.1956, -1.0402, -0.8835, -0.7247, -0.5695, -0.4952, -0.3698,\n",
      "         -1.8266, -1.3839, -1.0495, -0.7186, -0.8616, -0.5361, -0.7807, -0.4952,\n",
      "         -2.1668, -1.3353, -1.3353, -1.8898, -1.3353, -1.8898],\n",
      "        [-2.0089, -2.2045, -1.8897, -2.1259, -2.0436, -1.5168, -1.4554, -1.3199,\n",
      "         -1.1956, -1.0402, -0.8835, -0.7247, -0.5695, -0.4952, -0.3698, -1.8266,\n",
      "         -1.3839, -1.0495, -0.7186, -0.8616, -0.5361, -0.7807, -0.4952, -2.1668,\n",
      "         -1.3353, -1.3353, -1.8898, -1.3353, -1.8898, -1.3353],\n",
      "        [-2.2045, -1.8897, -2.1259, -2.0436, -1.5168, -1.4554, -1.3199, -1.1956,\n",
      "         -1.0402, -0.8835, -0.7247, -0.5695, -0.4952, -0.3698, -1.8266, -1.3839,\n",
      "         -1.0495, -0.7186, -0.8616, -0.5361, -0.7807, -0.4952, -2.1668, -1.3353,\n",
      "         -1.3353, -1.8898, -1.3353, -1.8898, -1.3353, -0.7807],\n",
      "        [-1.8897, -2.1259, -2.0436, -1.5168, -1.4554, -1.3199, -1.1956, -1.0402,\n",
      "         -0.8835, -0.7247, -0.5695, -0.4952, -0.3698, -1.8266, -1.3839, -1.0495,\n",
      "         -0.7186, -0.8616, -0.5361, -0.7807, -0.4952, -2.1668, -1.3353, -1.3353,\n",
      "         -1.8898, -1.3353, -1.8898, -1.3353, -0.7807, -0.7807],\n",
      "        [-2.1259, -2.0436, -1.5168, -1.4554, -1.3199, -1.1956, -1.0402, -0.8835,\n",
      "         -0.7247, -0.5695, -0.4952, -0.3698, -1.8266, -1.3839, -1.0495, -0.7186,\n",
      "         -0.8616, -0.5361, -0.7807, -0.4952, -2.1668, -1.3353, -1.3353, -1.8898,\n",
      "         -1.3353, -1.8898, -1.3353, -0.7807, -0.7807, -0.4952],\n",
      "        [-2.0436, -1.5168, -1.4554, -1.3199, -1.1956, -1.0402, -0.8835, -0.7247,\n",
      "         -0.5695, -0.4952, -0.3698, -1.8266, -1.3839, -1.0495, -0.7186, -0.8616,\n",
      "         -0.5361, -0.7807, -0.4952, -2.1668, -1.3353, -1.3353, -1.8898, -1.3353,\n",
      "         -1.8898, -1.3353, -0.7807, -0.7807, -0.4952, -0.2262],\n",
      "        [-1.5168, -1.4554, -1.3199, -1.1956, -1.0402, -0.8835, -0.7247, -0.5695,\n",
      "         -0.4952, -0.3698, -1.8266, -1.3839, -1.0495, -0.7186, -0.8616, -0.5361,\n",
      "         -0.7807, -0.4952, -2.1668, -1.3353, -1.3353, -1.8898, -1.3353, -1.8898,\n",
      "         -1.3353, -0.7807, -0.7807, -0.4952, -0.2262, -0.7807],\n",
      "        [-1.4554, -1.3199, -1.1956, -1.0402, -0.8835, -0.7247, -0.5695, -0.4952,\n",
      "         -0.3698, -1.8266, -1.3839, -1.0495, -0.7186, -0.8616, -0.5361, -0.7807,\n",
      "         -0.4952, -2.1668, -1.3353, -1.3353, -1.8898, -1.3353, -1.8898, -1.3353,\n",
      "         -0.7807, -0.7807, -0.4952, -0.2262, -0.7807, -0.7807],\n",
      "        [-1.3199, -1.1956, -1.0402, -0.8835, -0.7247, -0.5695, -0.4952, -0.3698,\n",
      "         -1.8266, -1.3839, -1.0495, -0.7186, -0.8616, -0.5361, -0.7807, -0.4952,\n",
      "         -2.1668, -1.3353, -1.3353, -1.8898, -1.3353, -1.8898, -1.3353, -0.7807,\n",
      "         -0.7807, -0.4952, -0.2262, -0.7807, -0.7807, -2.7535],\n",
      "        [-1.1956, -1.0402, -0.8835, -0.7247, -0.5695, -0.4952, -0.3698, -1.8266,\n",
      "         -1.3839, -1.0495, -0.7186, -0.8616, -0.5361, -0.7807, -0.4952, -2.1668,\n",
      "         -1.3353, -1.3353, -1.8898, -1.3353, -1.8898, -1.3353, -0.7807, -0.7807,\n",
      "         -0.4952, -0.2262, -0.7807, -0.7807, -2.7535, -2.3888],\n",
      "        [-1.0402, -0.8835, -0.7247, -0.5695, -0.4952, -0.3698, -1.8266, -1.3839,\n",
      "         -1.0495, -0.7186, -0.8616, -0.5361, -0.7807, -0.4952, -2.1668, -1.3353,\n",
      "         -1.3353, -1.8898, -1.3353, -1.8898, -1.3353, -0.7807, -0.7807, -0.4952,\n",
      "         -0.2262, -0.7807, -0.7807, -2.7535, -2.3888, -3.0626],\n",
      "        [-0.8835, -0.7247, -0.5695, -0.4952, -0.3698, -1.8266, -1.3839, -1.0495,\n",
      "         -0.7186, -0.8616, -0.5361, -0.7807, -0.4952, -2.1668, -1.3353, -1.3353,\n",
      "         -1.8898, -1.3353, -1.8898, -1.3353, -0.7807, -0.7807, -0.4952, -0.2262,\n",
      "         -0.7807, -0.7807, -2.7535, -2.3888, -3.0626, -2.8049],\n",
      "        [-0.7247, -0.5695, -0.4952, -0.3698, -1.8266, -1.3839, -1.0495, -0.7186,\n",
      "         -0.8616, -0.5361, -0.7807, -0.4952, -2.1668, -1.3353, -1.3353, -1.8898,\n",
      "         -1.3353, -1.8898, -1.3353, -0.7807, -0.7807, -0.4952, -0.2262, -0.7807,\n",
      "         -0.7807, -2.7535, -2.3888, -3.0626, -2.8049, -6.1540]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 2, 1, 0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0,\n",
      "         2, 8, 4, 7, 8, 8],\n",
      "        [6, 6, 6, 6, 2, 1, 0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2,\n",
      "         8, 4, 7, 8, 8, 8],\n",
      "        [6, 6, 6, 2, 1, 0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8,\n",
      "         4, 7, 8, 8, 8, 8],\n",
      "        [6, 6, 2, 1, 0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4,\n",
      "         7, 8, 8, 8, 8, 8],\n",
      "        [6, 2, 1, 0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [2, 1, 0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [1, 0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8,\n",
      "         8, 8, 8, 8, 8, 8],\n",
      "        [0, 1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8,\n",
      "         8, 8, 8, 8, 8, 4],\n",
      "        [1, 5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8,\n",
      "         8, 8, 8, 8, 4, 8],\n",
      "        [5, 0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8, 8,\n",
      "         8, 8, 8, 4, 8, 8],\n",
      "        [0, 5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8, 8, 8,\n",
      "         8, 8, 4, 8, 8, 8],\n",
      "        [5, 5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8, 8, 8, 8,\n",
      "         8, 4, 8, 8, 8, 7],\n",
      "        [5, 5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8,\n",
      "         4, 8, 8, 8, 7, 2],\n",
      "        [5, 5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 4,\n",
      "         8, 8, 8, 7, 2, 2],\n",
      "        [5, 6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8,\n",
      "         8, 8, 7, 2, 2, 0],\n",
      "        [6, 6, 4, 7, 7, 7, 0, 1, 0, 2, 8, 4, 7, 8, 8, 8, 8, 8, 8, 8, 8, 4, 8, 8,\n",
      "         8, 7, 2, 2, 0, 3]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-3.4887, -3.1731, -2.8691, -2.5726, -2.3231, -2.0891, -1.8935, -1.6791,\n",
      "         -1.4932, -1.3386, -1.1715, -1.0288, -0.9129, -0.7748, -1.1039, -0.5016,\n",
      "         -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,  0.1106, -0.4953, -0.4953,\n",
      "         -1.2050, -0.6796, -0.3081, -0.4953, -2.8469, -1.6944],\n",
      "        [-3.1731, -2.8691, -2.5726, -2.3231, -2.0891, -1.8935, -1.6791, -1.4932,\n",
      "         -1.3386, -1.1715, -1.0288, -0.9129, -0.7748, -1.1039, -0.5016, -1.1039,\n",
      "         -0.4953, -0.4953, -0.4953, -0.4953,  0.1106, -0.4953, -0.4953, -1.2050,\n",
      "         -0.6796, -0.3081, -0.4953, -2.8469, -1.6944, -1.4141],\n",
      "        [-2.8691, -2.5726, -2.3231, -2.0891, -1.8935, -1.6791, -1.4932, -1.3386,\n",
      "         -1.1715, -1.0288, -0.9129, -0.7748, -1.1039, -0.5016, -1.1039, -0.4953,\n",
      "         -0.4953, -0.4953, -0.4953,  0.1106, -0.4953, -0.4953, -1.2050, -0.6796,\n",
      "         -0.3081, -0.4953, -2.8469, -1.6944, -1.4141, -1.4799],\n",
      "        [-2.5726, -2.3231, -2.0891, -1.8935, -1.6791, -1.4932, -1.3386, -1.1715,\n",
      "         -1.0288, -0.9129, -0.7748, -1.1039, -0.5016, -1.1039, -0.4953, -0.4953,\n",
      "         -0.4953, -0.4953,  0.1106, -0.4953, -0.4953, -1.2050, -0.6796, -0.3081,\n",
      "         -0.4953, -2.8469, -1.6944, -1.4141, -1.4799, -1.2016],\n",
      "        [-2.3231, -2.0891, -1.8935, -1.6791, -1.4932, -1.3386, -1.1715, -1.0288,\n",
      "         -0.9129, -0.7748, -1.1039, -0.5016, -1.1039, -0.4953, -0.4953, -0.4953,\n",
      "         -0.4953,  0.1106, -0.4953, -0.4953, -1.2050, -0.6796, -0.3081, -0.4953,\n",
      "         -2.8469, -1.6944, -1.4141, -1.4799, -1.2016, -0.7714],\n",
      "        [-2.0891, -1.8935, -1.6791, -1.4932, -1.3386, -1.1715, -1.0288, -0.9129,\n",
      "         -0.7748, -1.1039, -0.5016, -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,\n",
      "          0.1106, -0.4953, -0.4953, -1.2050, -0.6796, -0.3081, -0.4953, -2.8469,\n",
      "         -1.6944, -1.4141, -1.4799, -1.2016, -0.7714, -1.3204],\n",
      "        [-1.8935, -1.6791, -1.4932, -1.3386, -1.1715, -1.0288, -0.9129, -0.7748,\n",
      "         -1.1039, -0.5016, -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,  0.1106,\n",
      "         -0.4953, -0.4953, -1.2050, -0.6796, -0.3081, -0.4953, -2.8469, -1.6944,\n",
      "         -1.4141, -1.4799, -1.2016, -0.7714, -1.3204, -1.8604],\n",
      "        [-1.6791, -1.4932, -1.3386, -1.1715, -1.0288, -0.9129, -0.7748, -1.1039,\n",
      "         -0.5016, -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,  0.1106, -0.4953,\n",
      "         -0.4953, -1.2050, -0.6796, -0.3081, -0.4953, -2.8469, -1.6944, -1.4141,\n",
      "         -1.4799, -1.2016, -0.7714, -1.3204, -1.8604, -1.8604],\n",
      "        [-1.4932, -1.3386, -1.1715, -1.0288, -0.9129, -0.7748, -1.1039, -0.5016,\n",
      "         -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,  0.1106, -0.4953, -0.4953,\n",
      "         -1.2050, -0.6796, -0.3081, -0.4953, -2.8469, -1.6944, -1.4141, -1.4799,\n",
      "         -1.2016, -0.7714, -1.3204, -1.8604, -1.8604, -1.8752],\n",
      "        [-1.3386, -1.1715, -1.0288, -0.9129, -0.7748, -1.1039, -0.5016, -1.1039,\n",
      "         -0.4953, -0.4953, -0.4953, -0.4953,  0.1106, -0.4953, -0.4953, -1.2050,\n",
      "         -0.6796, -0.3081, -0.4953, -2.8469, -1.6944, -1.4141, -1.4799, -1.2016,\n",
      "         -0.7714, -1.3204, -1.8604, -1.8604, -1.8752, -2.9738],\n",
      "        [-1.1715, -1.0288, -0.9129, -0.7748, -1.1039, -0.5016, -1.1039, -0.4953,\n",
      "         -0.4953, -0.4953, -0.4953,  0.1106, -0.4953, -0.4953, -1.2050, -0.6796,\n",
      "         -0.3081, -0.4953, -2.8469, -1.6944, -1.4141, -1.4799, -1.2016, -0.7714,\n",
      "         -1.3204, -1.8604, -1.8604, -1.8752, -2.9738, -2.3849],\n",
      "        [-1.0288, -0.9129, -0.7748, -1.1039, -0.5016, -1.1039, -0.4953, -0.4953,\n",
      "         -0.4953, -0.4953,  0.1106, -0.4953, -0.4953, -1.2050, -0.6796, -0.3081,\n",
      "         -0.4953, -2.8469, -1.6944, -1.4141, -1.4799, -1.2016, -0.7714, -1.3204,\n",
      "         -1.8604, -1.8604, -1.8752, -2.9738, -2.3849, -2.6660],\n",
      "        [-0.9129, -0.7748, -1.1039, -0.5016, -1.1039, -0.4953, -0.4953, -0.4953,\n",
      "         -0.4953,  0.1106, -0.4953, -0.4953, -1.2050, -0.6796, -0.3081, -0.4953,\n",
      "         -2.8469, -1.6944, -1.4141, -1.4799, -1.2016, -0.7714, -1.3204, -1.8604,\n",
      "         -1.8604, -1.8752, -2.9738, -2.3849, -2.6660, -3.0846],\n",
      "        [-0.7748, -1.1039, -0.5016, -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,\n",
      "          0.1106, -0.4953, -0.4953, -1.2050, -0.6796, -0.3081, -0.4953, -2.8469,\n",
      "         -1.6944, -1.4141, -1.4799, -1.2016, -0.7714, -1.3204, -1.8604, -1.8604,\n",
      "         -1.8752, -2.9738, -2.3849, -2.6660, -3.0846, -3.4679],\n",
      "        [-1.1039, -0.5016, -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,  0.1106,\n",
      "         -0.4953, -0.4953, -1.2050, -0.6796, -0.3081, -0.4953, -2.8469, -1.6944,\n",
      "         -1.4141, -1.4799, -1.2016, -0.7714, -1.3204, -1.8604, -1.8604, -1.8752,\n",
      "         -2.9738, -2.3849, -2.6660, -3.0846, -3.4679, -3.7353],\n",
      "        [-0.5016, -1.1039, -0.4953, -0.4953, -0.4953, -0.4953,  0.1106, -0.4953,\n",
      "         -0.4953, -1.2050, -0.6796, -0.3081, -0.4953, -2.8469, -1.6944, -1.4141,\n",
      "         -1.4799, -1.2016, -0.7714, -1.3204, -1.8604, -1.8604, -1.8752, -2.9738,\n",
      "         -2.3849, -2.6660, -3.0846, -3.4679, -3.7353, -3.9018]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4,\n",
      "         7, 7, 7, 4, 7, 3],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7,\n",
      "         7, 7, 4, 7, 3, 1],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7,\n",
      "         7, 4, 7, 3, 1, 1],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7,\n",
      "         4, 7, 3, 1, 1, 0],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4,\n",
      "         7, 3, 1, 1, 0, 1],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7,\n",
      "         3, 1, 1, 0, 1, 7],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3,\n",
      "         1, 1, 0, 1, 7, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1,\n",
      "         1, 0, 1, 7, 8, 8],\n",
      "        [6, 6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1,\n",
      "         0, 1, 7, 8, 8, 0],\n",
      "        [6, 6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1, 0,\n",
      "         1, 7, 8, 8, 0, 7],\n",
      "        [6, 6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1, 0, 1,\n",
      "         7, 8, 8, 0, 7, 0],\n",
      "        [6, 6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1, 0, 1, 7,\n",
      "         8, 8, 0, 7, 0, 0],\n",
      "        [6, 6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1, 0, 1, 7, 8,\n",
      "         8, 0, 7, 0, 0, 5],\n",
      "        [6, 8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1, 0, 1, 7, 8, 8,\n",
      "         0, 7, 0, 0, 5, 5],\n",
      "        [8, 6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1, 0, 1, 7, 8, 8, 0,\n",
      "         7, 0, 0, 5, 5, 5],\n",
      "        [6, 8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 3, 1, 1, 0, 1, 7, 8, 8, 0, 7,\n",
      "         0, 0, 5, 5, 5, 5]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-0.6209, -0.5025, -0.5025, -0.5025, -0.5025,  0.0845, -0.5025, -0.5025,\n",
      "         -0.9348, -0.5278, -0.2399, -0.5025, -2.2070, -0.5422, -0.5025, -0.3418,\n",
      "         -0.6209, -0.5025, -1.0243, -1.5807, -1.5807, -0.6209, -2.3053, -1.5807,\n",
      "         -1.2798, -1.6435, -1.6872, -0.7049, -0.7412, -0.8326],\n",
      "        [-0.5025, -0.5025, -0.5025, -0.5025,  0.0845, -0.5025, -0.5025, -0.9348,\n",
      "         -0.5278, -0.2399, -0.5025, -2.2070, -0.5422, -0.5025, -0.3418, -0.6209,\n",
      "         -0.5025, -1.0243, -1.5807, -1.5807, -0.6209, -2.3053, -1.5807, -1.2798,\n",
      "         -1.6435, -1.6872, -0.7049, -0.7412, -0.8326, -0.9298],\n",
      "        [-0.5025, -0.5025, -0.5025,  0.0845, -0.5025, -0.5025, -0.9348, -0.5278,\n",
      "         -0.2399, -0.5025, -2.2070, -0.5422, -0.5025, -0.3418, -0.6209, -0.5025,\n",
      "         -1.0243, -1.5807, -1.5807, -0.6209, -2.3053, -1.5807, -1.2798, -1.6435,\n",
      "         -1.6872, -0.7049, -0.7412, -0.8326, -0.9298, -1.0260],\n",
      "        [-0.5025, -0.5025,  0.0845, -0.5025, -0.5025, -0.9348, -0.5278, -0.2399,\n",
      "         -0.5025, -2.2070, -0.5422, -0.5025, -0.3418, -0.6209, -0.5025, -1.0243,\n",
      "         -1.5807, -1.5807, -0.6209, -2.3053, -1.5807, -1.2798, -1.6435, -1.6872,\n",
      "         -0.7049, -0.7412, -0.8326, -0.9298, -1.0260, -1.0975],\n",
      "        [-0.5025,  0.0845, -0.5025, -0.5025, -0.9348, -0.5278, -0.2399, -0.5025,\n",
      "         -2.2070, -0.5422, -0.5025, -0.3418, -0.6209, -0.5025, -1.0243, -1.5807,\n",
      "         -1.5807, -0.6209, -2.3053, -1.5807, -1.2798, -1.6435, -1.6872, -0.7049,\n",
      "         -0.7412, -0.8326, -0.9298, -1.0260, -1.0975, -1.1259],\n",
      "        [ 0.0845, -0.5025, -0.5025, -0.9348, -0.5278, -0.2399, -0.5025, -2.2070,\n",
      "         -0.5422, -0.5025, -0.3418, -0.6209, -0.5025, -1.0243, -1.5807, -1.5807,\n",
      "         -0.6209, -2.3053, -1.5807, -1.2798, -1.6435, -1.6872, -0.7049, -0.7412,\n",
      "         -0.8326, -0.9298, -1.0260, -1.0975, -1.1259, -1.1756],\n",
      "        [-0.5025, -0.5025, -0.9348, -0.5278, -0.2399, -0.5025, -2.2070, -0.5422,\n",
      "         -0.5025, -0.3418, -0.6209, -0.5025, -1.0243, -1.5807, -1.5807, -0.6209,\n",
      "         -2.3053, -1.5807, -1.2798, -1.6435, -1.6872, -0.7049, -0.7412, -0.8326,\n",
      "         -0.9298, -1.0260, -1.0975, -1.1259, -1.1756, -1.3862],\n",
      "        [-0.5025, -0.9348, -0.5278, -0.2399, -0.5025, -2.2070, -0.5422, -0.5025,\n",
      "         -0.3418, -0.6209, -0.5025, -1.0243, -1.5807, -1.5807, -0.6209, -2.3053,\n",
      "         -1.5807, -1.2798, -1.6435, -1.6872, -0.7049, -0.7412, -0.8326, -0.9298,\n",
      "         -1.0260, -1.0975, -1.1259, -1.1756, -1.3862, -1.4589],\n",
      "        [-0.9348, -0.5278, -0.2399, -0.5025, -2.2070, -0.5422, -0.5025, -0.3418,\n",
      "         -0.6209, -0.5025, -1.0243, -1.5807, -1.5807, -0.6209, -2.3053, -1.5807,\n",
      "         -1.2798, -1.6435, -1.6872, -0.7049, -0.7412, -0.8326, -0.9298, -1.0260,\n",
      "         -1.0975, -1.1259, -1.1756, -1.3862, -1.4589, -1.6443],\n",
      "        [-0.5278, -0.2399, -0.5025, -2.2070, -0.5422, -0.5025, -0.3418, -0.6209,\n",
      "         -0.5025, -1.0243, -1.5807, -1.5807, -0.6209, -2.3053, -1.5807, -1.2798,\n",
      "         -1.6435, -1.6872, -0.7049, -0.7412, -0.8326, -0.9298, -1.0260, -1.0975,\n",
      "         -1.1259, -1.1756, -1.3862, -1.4589, -1.6443, -1.8546],\n",
      "        [-0.2399, -0.5025, -2.2070, -0.5422, -0.5025, -0.3418, -0.6209, -0.5025,\n",
      "         -1.0243, -1.5807, -1.5807, -0.6209, -2.3053, -1.5807, -1.2798, -1.6435,\n",
      "         -1.6872, -0.7049, -0.7412, -0.8326, -0.9298, -1.0260, -1.0975, -1.1259,\n",
      "         -1.1756, -1.3862, -1.4589, -1.6443, -1.8546, -2.0316],\n",
      "        [-0.5025, -2.2070, -0.5422, -0.5025, -0.3418, -0.6209, -0.5025, -1.0243,\n",
      "         -1.5807, -1.5807, -0.6209, -2.3053, -1.5807, -1.2798, -1.6435, -1.6872,\n",
      "         -0.7049, -0.7412, -0.8326, -0.9298, -1.0260, -1.0975, -1.1259, -1.1756,\n",
      "         -1.3862, -1.4589, -1.6443, -1.8546, -2.0316, -2.2128],\n",
      "        [-2.2070, -0.5422, -0.5025, -0.3418, -0.6209, -0.5025, -1.0243, -1.5807,\n",
      "         -1.5807, -0.6209, -2.3053, -1.5807, -1.2798, -1.6435, -1.6872, -0.7049,\n",
      "         -0.7412, -0.8326, -0.9298, -1.0260, -1.0975, -1.1259, -1.1756, -1.3862,\n",
      "         -1.4589, -1.6443, -1.8546, -2.0316, -2.2128, -2.4409],\n",
      "        [-0.5422, -0.5025, -0.3418, -0.6209, -0.5025, -1.0243, -1.5807, -1.5807,\n",
      "         -0.6209, -2.3053, -1.5807, -1.2798, -1.6435, -1.6872, -0.7049, -0.7412,\n",
      "         -0.8326, -0.9298, -1.0260, -1.0975, -1.1259, -1.1756, -1.3862, -1.4589,\n",
      "         -1.6443, -1.8546, -2.0316, -2.2128, -2.4409, -2.6973],\n",
      "        [-0.5025, -0.3418, -0.6209, -0.5025, -1.0243, -1.5807, -1.5807, -0.6209,\n",
      "         -2.3053, -1.5807, -1.2798, -1.6435, -1.6872, -0.7049, -0.7412, -0.8326,\n",
      "         -0.9298, -1.0260, -1.0975, -1.1259, -1.1756, -1.3862, -1.4589, -1.6443,\n",
      "         -1.8546, -2.0316, -2.2128, -2.4409, -2.6973, -2.9501],\n",
      "        [-0.3418, -0.6209, -0.5025, -1.0243, -1.5807, -1.5807, -0.6209, -2.3053,\n",
      "         -1.5807, -1.2798, -1.6435, -1.6872, -0.7049, -0.7412, -0.8326, -0.9298,\n",
      "         -1.0260, -1.0975, -1.1259, -1.1756, -1.3862, -1.4589, -1.6443, -1.8546,\n",
      "         -2.0316, -2.2128, -2.4409, -2.6973, -2.9501, -3.1851]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[8, 4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8,\n",
      "         0, 2, 0, 0, 5, 5],\n",
      "        [4, 4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0,\n",
      "         2, 0, 0, 5, 5, 5],\n",
      "        [4, 4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2,\n",
      "         0, 0, 5, 5, 5, 6],\n",
      "        [4, 4, 7, 4, 4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0,\n",
      "         0, 5, 5, 5, 6, 6],\n",
      "        [4, 7, 4, 4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0,\n",
      "         5, 5, 5, 6, 6, 6],\n",
      "        [7, 4, 4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5,\n",
      "         5, 5, 6, 6, 6, 6],\n",
      "        [4, 4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5,\n",
      "         5, 6, 6, 6, 6, 7],\n",
      "        [4, 7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5,\n",
      "         6, 6, 6, 6, 7, 6],\n",
      "        [7, 7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6,\n",
      "         6, 6, 6, 7, 6, 6],\n",
      "        [7, 7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6, 6,\n",
      "         6, 6, 7, 6, 6, 6],\n",
      "        [7, 4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6, 6, 6,\n",
      "         6, 7, 6, 6, 6, 6],\n",
      "        [4, 7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6, 6, 6, 6,\n",
      "         7, 6, 6, 6, 6, 6],\n",
      "        [7, 7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6, 6, 6, 6, 7,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6, 6, 6, 6, 7, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [4, 7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6, 6, 6, 6, 7, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6],\n",
      "        [7, 8, 4, 7, 8, 8, 8, 7, 8, 0, 2, 0, 0, 5, 5, 5, 6, 6, 6, 6, 7, 6, 6, 6,\n",
      "         6, 6, 6, 6, 6, 6]]))\n",
      "torch.return_types.min(\n",
      "values=tensor([[-0.6990, -0.5737, -1.1586, -1.5220, -1.5220, -0.6990, -2.5010, -1.5220,\n",
      "         -1.1083, -1.2326, -1.5220, -0.6990, -0.5737, -0.5737, -0.1461, -0.6990,\n",
      "         -0.5737, -0.5737, -0.8959, -1.5378, -0.5737, -0.5737, -0.5981, -0.5737,\n",
      "         -1.6424, -1.9094, -1.5255, -1.7689, -1.2687, -1.0899],\n",
      "        [-0.5737, -1.1586, -1.5220, -1.5220, -0.6990, -2.5010, -1.5220, -1.1083,\n",
      "         -1.2326, -1.5220, -0.6990, -0.5737, -0.5737, -0.1461, -0.6990, -0.5737,\n",
      "         -0.5737, -0.8959, -1.5378, -0.5737, -0.5737, -0.5981, -0.5737, -1.6424,\n",
      "         -1.9094, -1.5255, -1.7689, -1.2687, -1.0899, -0.9408],\n",
      "        [-1.1586, -1.5220, -1.5220, -0.6990, -2.5010, -1.5220, -1.1083, -1.2326,\n",
      "         -1.5220, -0.6990, -0.5737, -0.5737, -0.1461, -0.6990, -0.5737, -0.5737,\n",
      "         -0.8959, -1.5378, -0.5737, -0.5737, -0.5981, -0.5737, -1.6424, -1.9094,\n",
      "         -1.5255, -1.7689, -1.2687, -1.0899, -0.9408, -0.9951],\n",
      "        [-1.5220, -1.5220, -0.6990, -2.5010, -1.5220, -1.1083, -1.2326, -1.5220,\n",
      "         -0.6990, -0.5737, -0.5737, -0.1461, -0.6990, -0.5737, -0.5737, -0.8959,\n",
      "         -1.5378, -0.5737, -0.5737, -0.5981, -0.5737, -1.6424, -1.9094, -1.5255,\n",
      "         -1.7689, -1.2687, -1.0899, -0.9408, -0.9951, -1.0313],\n",
      "        [-1.5220, -0.6990, -2.5010, -1.5220, -1.1083, -1.2326, -1.5220, -0.6990,\n",
      "         -0.5737, -0.5737, -0.1461, -0.6990, -0.5737, -0.5737, -0.8959, -1.5378,\n",
      "         -0.5737, -0.5737, -0.5981, -0.5737, -1.6424, -1.9094, -1.5255, -1.7689,\n",
      "         -1.2687, -1.0899, -0.9408, -0.9951, -1.0313, -1.1062],\n",
      "        [-0.6990, -2.5010, -1.5220, -1.1083, -1.2326, -1.5220, -0.6990, -0.5737,\n",
      "         -0.5737, -0.1461, -0.6990, -0.5737, -0.5737, -0.8959, -1.5378, -0.5737,\n",
      "         -0.5737, -0.5981, -0.5737, -1.6424, -1.9094, -1.5255, -1.7689, -1.2687,\n",
      "         -1.0899, -0.9408, -0.9951, -1.0313, -1.1062, -2.1406],\n",
      "        [-2.5010, -1.5220, -1.1083, -1.2326, -1.5220, -0.6990, -0.5737, -0.5737,\n",
      "         -0.1461, -0.6990, -0.5737, -0.5737, -0.8959, -1.5378, -0.5737, -0.5737,\n",
      "         -0.5981, -0.5737, -1.6424, -1.9094, -1.5255, -1.7689, -1.2687, -1.0899,\n",
      "         -0.9408, -0.9951, -1.0313, -1.1062, -2.1406, -1.3043],\n",
      "        [-1.5220, -1.1083, -1.2326, -1.5220, -0.6990, -0.5737, -0.5737, -0.1461,\n",
      "         -0.6990, -0.5737, -0.5737, -0.8959, -1.5378, -0.5737, -0.5737, -0.5981,\n",
      "         -0.5737, -1.6424, -1.9094, -1.5255, -1.7689, -1.2687, -1.0899, -0.9408,\n",
      "         -0.9951, -1.0313, -1.1062, -2.1406, -1.3043, -1.6394],\n",
      "        [-1.1083, -1.2326, -1.5220, -0.6990, -0.5737, -0.5737, -0.1461, -0.6990,\n",
      "         -0.5737, -0.5737, -0.8959, -1.5378, -0.5737, -0.5737, -0.5981, -0.5737,\n",
      "         -1.6424, -1.9094, -1.5255, -1.7689, -1.2687, -1.0899, -0.9408, -0.9951,\n",
      "         -1.0313, -1.1062, -2.1406, -1.3043, -1.6394, -1.6103],\n",
      "        [-1.2326, -1.5220, -0.6990, -0.5737, -0.5737, -0.1461, -0.6990, -0.5737,\n",
      "         -0.5737, -0.8959, -1.5378, -0.5737, -0.5737, -0.5981, -0.5737, -1.6424,\n",
      "         -1.9094, -1.5255, -1.7689, -1.2687, -1.0899, -0.9408, -0.9951, -1.0313,\n",
      "         -1.1062, -2.1406, -1.3043, -1.6394, -1.6103, -1.7865],\n",
      "        [-1.5220, -0.6990, -0.5737, -0.5737, -0.1461, -0.6990, -0.5737, -0.5737,\n",
      "         -0.8959, -1.5378, -0.5737, -0.5737, -0.5981, -0.5737, -1.6424, -1.9094,\n",
      "         -1.5255, -1.7689, -1.2687, -1.0899, -0.9408, -0.9951, -1.0313, -1.1062,\n",
      "         -2.1406, -1.3043, -1.6394, -1.6103, -1.7865, -1.9575],\n",
      "        [-0.6990, -0.5737, -0.5737, -0.1461, -0.6990, -0.5737, -0.5737, -0.8959,\n",
      "         -1.5378, -0.5737, -0.5737, -0.5981, -0.5737, -1.6424, -1.9094, -1.5255,\n",
      "         -1.7689, -1.2687, -1.0899, -0.9408, -0.9951, -1.0313, -1.1062, -2.1406,\n",
      "         -1.3043, -1.6394, -1.6103, -1.7865, -1.9575, -2.1212],\n",
      "        [-0.5737, -0.5737, -0.1461, -0.6990, -0.5737, -0.5737, -0.8959, -1.5378,\n",
      "         -0.5737, -0.5737, -0.5981, -0.5737, -1.6424, -1.9094, -1.5255, -1.7689,\n",
      "         -1.2687, -1.0899, -0.9408, -0.9951, -1.0313, -1.1062, -2.1406, -1.3043,\n",
      "         -1.6394, -1.6103, -1.7865, -1.9575, -2.1212, -2.2864],\n",
      "        [-0.5737, -0.1461, -0.6990, -0.5737, -0.5737, -0.8959, -1.5378, -0.5737,\n",
      "         -0.5737, -0.5981, -0.5737, -1.6424, -1.9094, -1.5255, -1.7689, -1.2687,\n",
      "         -1.0899, -0.9408, -0.9951, -1.0313, -1.1062, -2.1406, -1.3043, -1.6394,\n",
      "         -1.6103, -1.7865, -1.9575, -2.1212, -2.2864, -2.4921],\n",
      "        [-0.1461, -0.6990, -0.5737, -0.5737, -0.8959, -1.5378, -0.5737, -0.5737,\n",
      "         -0.5981, -0.5737, -1.6424, -1.9094, -1.5255, -1.7689, -1.2687, -1.0899,\n",
      "         -0.9408, -0.9951, -1.0313, -1.1062, -2.1406, -1.3043, -1.6394, -1.6103,\n",
      "         -1.7865, -1.9575, -2.1212, -2.2864, -2.4921, -2.6511],\n",
      "        [-0.6990, -0.5737, -0.5737, -0.8959, -1.5378, -0.5737, -0.5737, -0.5981,\n",
      "         -0.5737, -1.6424, -1.9094, -1.5255, -1.7689, -1.2687, -1.0899, -0.9408,\n",
      "         -0.9951, -1.0313, -1.1062, -2.1406, -1.3043, -1.6394, -1.6103, -1.7865,\n",
      "         -1.9575, -2.1212, -2.2864, -2.4921, -2.6511, -3.1167]],\n",
      "       dtype=torch.float64, grad_fn=<MinBackward0>),\n",
      "indices=tensor([[8, 4, 7, 8, 8, 8, 7, 8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4,\n",
      "         7, 0, 1, 1, 8, 1],\n",
      "        [4, 7, 8, 8, 8, 7, 8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7,\n",
      "         0, 1, 1, 8, 1, 5],\n",
      "        [7, 8, 8, 8, 7, 8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0,\n",
      "         1, 1, 8, 1, 5, 5],\n",
      "        [8, 8, 8, 7, 8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1,\n",
      "         1, 8, 1, 5, 5, 5],\n",
      "        [8, 8, 7, 8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1,\n",
      "         8, 1, 5, 5, 5, 6],\n",
      "        [8, 7, 8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8,\n",
      "         1, 5, 5, 5, 6, 7],\n",
      "        [7, 8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1,\n",
      "         5, 5, 5, 6, 7, 6],\n",
      "        [8, 7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5,\n",
      "         5, 5, 6, 7, 6, 7],\n",
      "        [7, 2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5,\n",
      "         5, 6, 7, 6, 7, 6],\n",
      "        [2, 8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5, 5,\n",
      "         6, 7, 6, 7, 6, 6],\n",
      "        [8, 8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5, 5, 6,\n",
      "         7, 6, 7, 6, 6, 6],\n",
      "        [8, 4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5, 5, 6, 7,\n",
      "         6, 7, 6, 6, 6, 6],\n",
      "        [4, 4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5, 5, 6, 7, 6,\n",
      "         7, 6, 6, 6, 6, 6],\n",
      "        [4, 7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5, 5, 6, 7, 6, 7,\n",
      "         6, 6, 6, 6, 6, 3],\n",
      "        [7, 8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5, 5, 6, 7, 6, 7, 6,\n",
      "         6, 6, 6, 6, 3, 6],\n",
      "        [8, 4, 4, 7, 7, 4, 4, 0, 4, 7, 0, 1, 1, 8, 1, 5, 5, 5, 6, 7, 6, 7, 6, 6,\n",
      "         6, 6, 6, 3, 6, 3]]))\n",
      "Epoch: 1, Loss: 60018.633343240246\n"
     ]
    }
   ],
   "source": [
    "trn.train(model, outputs, train_loader, list(range(0,9)), 1, optimizer, loss_fn, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Training\n",
    "Here we will train a model with 9 channels on EURUSD dataset, then on NASDAQ (with Volume dropped) and finally we will evaluate its performance.\n",
    "\n",
    "Hyperparameters were set manually with some experimentation. Feel free to adjust them yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.pytorch import PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"model\",\n",
    "                    role=role,\n",
    "                    framework_version='1.2.0',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p2.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 20,\n",
    "                        'batch-size': 256,\n",
    "                        'input-size': 30,\n",
    "                        'input-channels': 9,\n",
    "                        'c-filters': 4,\n",
    "                        'lstm-hidden': 10,\n",
    "                        'lstm-layers': 3,\n",
    "                        'output-size': 10,\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-29 17:01:21 Starting - Starting the training job...\n",
      "2020-01-29 17:01:23 Starting - Launching requested ML instances......\n",
      "2020-01-29 17:02:28 Starting - Preparing the instances for training......\n",
      "2020-01-29 17:03:48 Downloading - Downloading input data......\n",
      "2020-01-29 17:04:40 Training - Downloading the training image............\n",
      "2020-01-29 17:06:53 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:54,253 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:54,279 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:54,280 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:54,571 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:54,571 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:54,571 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:54,571 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m pip install . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Building wheel for train (setup.py): started\n",
      "  Building wheel for train (setup.py): finished with status 'done'\n",
      "  Created wheel for train: filename=train-1.0.0-py2.py3-none-any.whl size=20292 sha256=547def6d63b0c84a2b293a9c0d69cbe04711cbff3abb1263f4d842d395cde5f3\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-3zt6tv91/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mWARNING: You are using pip version 19.3; however, version 20.0.2 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2020-01-29 17:06:56,648 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"input-size\": 30,\n",
      "        \"lstm-layers\": 3,\n",
      "        \"input-channels\": 9,\n",
      "        \"c-filters\": 4,\n",
      "        \"batch-size\": 256,\n",
      "        \"lstm-hidden\": 10,\n",
      "        \"output-size\": 10,\n",
      "        \"epochs\": 20\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pytorch-training-2020-01-29-17-01-21-129\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-236375122127/pytorch-training-2020-01-29-17-01-21-129/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"batch-size\":256,\"c-filters\":4,\"epochs\":20,\"input-channels\":9,\"input-size\":30,\"lstm-hidden\":10,\"lstm-layers\":3,\"output-size\":10}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-236375122127/pytorch-training-2020-01-29-17-01-21-129/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":256,\"c-filters\":4,\"epochs\":20,\"input-channels\":9,\"input-size\":30,\"lstm-hidden\":10,\"lstm-layers\":3,\"output-size\":10},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pytorch-training-2020-01-29-17-01-21-129\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-236375122127/pytorch-training-2020-01-29-17-01-21-129/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--batch-size\",\"256\",\"--c-filters\",\"4\",\"--epochs\",\"20\",\"--input-channels\",\"9\",\"--input-size\",\"30\",\"--lstm-hidden\",\"10\",\"--lstm-layers\",\"3\",\"--output-size\",\"10\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT-SIZE=30\u001b[0m\n",
      "\u001b[34mSM_HP_LSTM-LAYERS=3\u001b[0m\n",
      "\u001b[34mSM_HP_INPUT-CHANNELS=9\u001b[0m\n",
      "\u001b[34mSM_HP_C-FILTERS=4\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=256\u001b[0m\n",
      "\u001b[34mSM_HP_LSTM-HIDDEN=10\u001b[0m\n",
      "\u001b[34mSM_HP_OUTPUT-SIZE=10\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=20\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/conda/bin:/opt/conda/lib/python36.zip:/opt/conda/lib/python3.6:/opt/conda/lib/python3.6/lib-dynload:/opt/conda/lib/python3.6/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python -m train --batch-size 256 --c-filters 4 --epochs 20 --input-channels 9 --input-size 30 --lstm-hidden 10 --lstm-layers 3 --output-size 10\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mUsing device cuda.\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.02620354851886084\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.018606591723929488\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.016665383322876325\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.015264249988723944\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.01434700921218772\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.013572534222507208\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.013072544976051292\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.012664255956926093\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.012331278429846406\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.012044722973093516\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.011841557894035713\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.01170521150713719\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.011622762640597894\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.011530771863862714\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.011466145461275787\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.011368005306418277\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.011293341734503708\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.01123893446445755\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.011193025963307882\u001b[0m\n",
      "\n",
      "2020-01-29 17:10:20 Uploading - Uploading generated training model\u001b[34mEpoch: 20, Loss: 0.011106626973069517\u001b[0m\n",
      "\u001b[34m2020-01-29 17:10:15,661 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2020-01-29 17:10:27 Completed - Training job completed\n",
      "Training seconds: 399\n",
      "Billable seconds: 399\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({'training': in_data['eurusd_export']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model S3 Location\n",
    "For our web application deployment we will use S3 location of our estimator:\n",
    "\n",
    "**Copy result of the cell below - it is required in the next notebook!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-236375122127/pytorch-training-2020-01-29-17-01-21-129/output/model.tar.gz'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating\n",
    "Here we deploy our estimator, test how does it perform on both NASDAQ and EURUSD. After everything runs without errors, we will compare the result against our benchmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------------------------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(instance_type='ml.p2.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_eurusd = SlidingWindowDataset(eurusd_test.values, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_nasdaq = SlidingWindowDataset(nasdaq_test.values, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b5a176e47948>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mds_eurusd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSlidingWindowDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meurusd_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpredictor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mds_eurusd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_eurusd\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictor' is not defined"
     ]
    }
   ],
   "source": [
    "predictor.predict(np.array([ds_eurusd[0][:30], ds_eurusd[1][:30]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80893191, 0.80945195, 0.80995133, 0.8105491 , 0.80922292,\n",
       "        0.80793295, 0.80868434, 0.80872074, 0.80921673, 0.81001494],\n",
       "       [0.83240737, 0.83358723, 0.83477446, 0.83621585, 0.83573888,\n",
       "        0.83522236, 0.83655151, 0.83700724, 0.83769249, 0.83921076]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.predict(np.array([ds_nasdaq[0][:30], ds_nasdaq[1][:30]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark vs LSTM Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in = np.array([ds_nasdaq[0][:30], ds_eurusd[0][:30]])\n",
    "test_y = test_in[:,:,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "ma_y = benchmark.predict(test_in, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_y = None\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    model_y = model(torch.from_numpy(test_in))\n",
    "#model_y = predictor.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x432 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "for i in [0,1]:\n",
    "    plt.subplot(121+i)\n",
    "    x = np.arange(len(test_y[i]))\n",
    "    plt.plot(x, test_y[i])\n",
    "    plt.plot(x[-1:], ma_y[i], 'gx')\n",
    "    plt.plot(x[-1:], test_y[i][-2] + model_y[i], 'rx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean-up\n",
    "We will not need this endpoint anymore, so let's remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "Model is ready to deploy. Final deployment steps will be performed in the `WebApp.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
